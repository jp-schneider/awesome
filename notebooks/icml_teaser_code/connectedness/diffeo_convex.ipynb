{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Literal, Union, Dict, Any\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_uniform(activation: str = 'relu'):\n",
    "    if not isinstance(activation, str):\n",
    "        raise ValueError('activation must be a string')\n",
    "    def _weights_init_uniform(m: torch.nn.Module):\n",
    "        nonlocal activation\n",
    "        with torch.no_grad():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity=activation)\n",
    "                gain = nn.init.calculate_gain(activation, 0)\n",
    "                fan = nn.init._calculate_correct_fan(m.weight, 'fan_in')\n",
    "                std = gain / math.sqrt(fan)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.uniform_(-std, std)\n",
    "    return _weights_init_uniform\n",
    "\n",
    "def weights_init_normal(activation: str = 'relu'):\n",
    "    if not isinstance(activation, str):\n",
    "        raise ValueError('activation must be a string')\n",
    "    def _weights_init_normal(m: torch.nn.Module):\n",
    "        nonlocal activation\n",
    "        with torch.no_grad():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity=activation)\n",
    "                gain = nn.init.calculate_gain(activation, 0)\n",
    "                fan = nn.init._calculate_correct_fan(m.weight, 'fan_in')\n",
    "                std = gain / math.sqrt(fan)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.uniform_(-std, std)\n",
    "    return _weights_init_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int = 130,\n",
    "                 out_features: int = 130,\n",
    "                 in_skip_features: int = 2,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.ln = nn.Linear(in_features, out_features)\n",
    "        self.skp = nn.Linear(in_skip_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_input: torch.Tensor):\n",
    "        return F.relu(self.ln(x) + self.skp(x_input))\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.ln.apply(weights_init_uniform('relu'))\n",
    "        self.skp.apply(weights_init_uniform('relu'))\n",
    "\n",
    "    def enforce_convexity(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            self.ln.weight.data = F.relu(self.ln.weight.data)\n",
    "\n",
    "\n",
    "class OutBlock(SkipBlock):\n",
    "    def __init__(self,\n",
    "                 in_features: int = 130,\n",
    "                 out_features: int = 1,\n",
    "                 in_skip_features: int = 2,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            in_features=in_features, \n",
    "            out_features=out_features, \n",
    "            in_skip_features=in_skip_features\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_input: torch.Tensor):\n",
    "        return self.ln(x) + self.skp(x_input)\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.ln.apply(weights_init_uniform('linear'))\n",
    "        self.skp.apply(weights_init_uniform('linear'))\n",
    "\n",
    "class ConvexNextNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 130,\n",
    "                 in_features: int = 2,\n",
    "                 out_features: int = 1,\n",
    "                 n_hidden_layers: int = 1,\n",
    "                 ** kwargs):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "\n",
    "        # define network layers\n",
    "        self.input = nn.Linear(in_features, n_hidden)\n",
    "        self.skip = nn.ModuleList([\n",
    "                        SkipBlock(in_features=n_hidden, \n",
    "                                  out_features=n_hidden, \n",
    "                                  in_skip_features=in_features) for _ in range(n_hidden_layers)])\n",
    "        self.out = OutBlock(\n",
    "            in_features=n_hidden, \n",
    "            out_features=out_features, \n",
    "            in_skip_features=in_features)\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.input.apply(weights_init_uniform('linear'))\n",
    "        for i in range(len(self.skip)):\n",
    "            self.skip[i].reset_parameters()\n",
    "        self.out.reset_parameters()\n",
    "        return True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        # Input of shape (batch_size, 2)\n",
    "        x_input = x\n",
    "        x = F.relu(self.input(x))\n",
    "        for i in range(len(self.skip)):\n",
    "            x = self.skip[i](x, x_input=x_input)\n",
    "        x = self.out(x, x_input=x_input)\n",
    "        return x\n",
    "\n",
    "    def enforce_convexity(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.skip)):\n",
    "                self.skip[i].enforce_convexity()\n",
    "            self.out.enforce_convexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResnet(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels: int = 2,\n",
    "                 mid_channels: int = 128, \n",
    "                 out_channels: int = 2,\n",
    "                 num_blocks: int = 1, \n",
    "                 double_after_norm: bool = False\n",
    "                 ):\n",
    "        \"\"\"1D ResNet for scale and translate factors in 1D Real NVP.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels : int, optional\n",
    "            Number of input channels, by default 2\n",
    "        mid_channels : int, optional\n",
    "            Number if intermediate channels, by default 128\n",
    "        out_channels : int, optional\n",
    "            Number of output channels, by default 2\n",
    "        num_blocks : int, optional\n",
    "            Number of residual blocks, by default 2\n",
    "        double_after_norm : bool, optional\n",
    "            If the channel values should be doubled after norming the input, by default False\n",
    "        \"\"\"\n",
    "        super(SimpleResnet, self).__init__()\n",
    "        self.in_norm = nn.BatchNorm1d(in_channels, track_running_stats=False)\n",
    "        self.double_after_norm = double_after_norm\n",
    "        self.in_linear = WNLinear(2 * in_channels, mid_channels, bias=True)\n",
    "        self.in_skip = WNLinear(mid_channels, mid_channels, bias=True)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock1D(mid_channels, mid_channels)\n",
    "                                     for _ in range(num_blocks)])\n",
    "        self.skips = nn.ModuleList([WNLinear(mid_channels, mid_channels, bias=True)\n",
    "                                    for _ in range(num_blocks)])\n",
    "        self.out_norm = nn.BatchNorm1d(mid_channels, track_running_stats=False)\n",
    "        self.out_linear = WNLinear(mid_channels, out_channels, bias=True)\n",
    "        \n",
    "        self.in_linear.apply(weights_init_normal('relu'))\n",
    "        self.in_skip.apply(weights_init_normal('relu'))\n",
    "        self.skips.apply(weights_init_normal('relu'))\n",
    "        self.out_linear.apply(weights_init_normal('tanh'))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.in_norm(x)\n",
    "        if self.double_after_norm:\n",
    "            x *= 2.\n",
    "        x = torch.cat((x, -x), dim=1)\n",
    "        x = F.relu(x)\n",
    "        x = self.in_linear(x)\n",
    "        x_skip = self.in_skip(x)\n",
    "\n",
    "        for block, skip in zip(self.blocks, self.skips):\n",
    "            x = block(x)\n",
    "            x_skip += skip(x)\n",
    "\n",
    "        x = self.out_norm(x_skip)\n",
    "        x = F.relu(x)\n",
    "        x = self.out_linear(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    \"\"\"ResNet basic block with weight norm.\"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int = 1,\n",
    "                 out_channels:int = 1,\n",
    "                 **kwargs\n",
    "                   ):\n",
    "        super(ResidualBlock1D, self).__init__()\n",
    "\n",
    "        self.in_norm = nn.BatchNorm1d(in_channels, track_running_stats=False)\n",
    "        self.in_linear = WNLinear(in_channels, out_channels, bias=False)\n",
    "\n",
    "        self.out_norm = nn.BatchNorm1d(out_channels, track_running_stats=False)\n",
    "        self.out_linear = WNLinear(out_channels, out_channels,  bias=True)\n",
    "        self.in_linear.apply(weights_init_normal('relu'))\n",
    "        self.out_linear.apply(weights_init_normal('relu'))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "\n",
    "        x = self.in_norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.in_linear(x)\n",
    "\n",
    "        x = self.out_norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out_linear(x)\n",
    "\n",
    "        x = x + skip\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"1D ResNet for scale and translate factors in 1D Real NVP.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels: int = 2,\n",
    "                 mid_channels: int = 128, \n",
    "                 out_channels: int = 2,\n",
    "                 num_blocks: int = 2, \n",
    "                 double_after_norm: bool = False\n",
    "                 ):\n",
    "        \"\"\"1D ResNet for scale and translate factors in 1D Real NVP.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels : int, optional\n",
    "            Number of input channels, by default 2\n",
    "        mid_channels : int, optional\n",
    "            Number if intermediate channels, by default 128\n",
    "        out_channels : int, optional\n",
    "            Number of output channels, by default 2\n",
    "        num_blocks : int, optional\n",
    "            Number of residual blocks, by default 2\n",
    "        double_after_norm : bool, optional\n",
    "            If the channel values should be doubled after norming the input, by default False\n",
    "        \"\"\"\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.in_norm = nn.BatchNorm1d(in_channels, track_running_stats=False)\n",
    "        self.double_after_norm = double_after_norm\n",
    "        self.in_linear = WNLinear(2 * in_channels, mid_channels, bias=True)\n",
    "        self.in_skip = WNLinear(mid_channels, mid_channels, bias=True)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock1D(mid_channels, mid_channels)\n",
    "                                     for _ in range(num_blocks)])\n",
    "        self.skips = nn.ModuleList([WNLinear(mid_channels, mid_channels, bias=True)\n",
    "                                    for _ in range(num_blocks)])\n",
    "        self.out_norm = nn.BatchNorm1d(mid_channels, track_running_stats=False)\n",
    "        self.out_linear = WNLinear(mid_channels, out_channels, bias=True)\n",
    "        \n",
    "        self.in_linear.apply(weights_init_normal('relu'))\n",
    "        self.in_skip.apply(weights_init_normal('relu'))\n",
    "        self.skips.apply(weights_init_normal('relu'))\n",
    "        self.out_linear.apply(weights_init_normal('linear'))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_norm(x)\n",
    "        if self.double_after_norm:\n",
    "            x *= 2.\n",
    "        x = torch.cat((x, -x), dim=1)\n",
    "        x = F.relu(x)\n",
    "        x = self.in_linear(x)\n",
    "        x_skip = self.in_skip(x)\n",
    "\n",
    "        for block, skip in zip(self.blocks, self.skips):\n",
    "            x = block(x)\n",
    "            x_skip += skip(x)\n",
    "\n",
    "        x = self.out_norm(x_skip)\n",
    "        x = F.relu(x)\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "\n",
    "class WNLinear(nn.Module):\n",
    "    \"\"\"Weight-normalized linear layer.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels: int = 1, \n",
    "                 out_channels: int = 1, \n",
    "                 bias=True,\n",
    "                 **kwargs):\n",
    "        super(WNLinear, self).__init__()\n",
    "        self.linear = nn.utils.weight_norm(nn.Linear(in_channels, out_channels, bias=bias), dim=None)\n",
    "\n",
    "    def reset_parameters(self, activation: str = 'relu'):\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight_g.data.fill_(1)\n",
    "            gain = nn.init.calculate_gain(activation, 0)\n",
    "            fan = nn.init._calculate_correct_fan(self.linear.weight_v, 'fan_in')\n",
    "            std = gain / math.sqrt(fan)\n",
    "            nn.init.kaiming_uniform_(self.linear.weight_v, mode='fan_in', nonlinearity=activation)\n",
    "            if self.linear.bias is not None:\n",
    "                self.linear.bias.data.uniform_(-std, std)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class SimpleBackbone(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 2,\n",
    "                 network_width: int = 10,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = WNLinear(in_channels, network_width)\n",
    "        self.linear2 = WNLinear(network_width, in_channels)\n",
    "        #self.linear1.apply(weights_init_normal('relu'))\n",
    "        #self.linear2.apply(weights_init_normal('linear'))\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.linear1.apply(weights_init_uniform('relu'))\n",
    "        self.linear2.apply(weights_init_uniform('tanh'))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "    \n",
    "class NormalBlock(nn.Module):\n",
    "    \"\"\"Basic block with weight norm.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels: int = 1,\n",
    "                 mid_channels: int = 128,\n",
    "                 out_channels:int = 1,\n",
    "                 **kwargs\n",
    "                   ):\n",
    "        super(NormalBlock, self).__init__()\n",
    "        self.in_linear = WNLinear(in_channels, mid_channels, bias=True)\n",
    "        self.out_linear = WNLinear(mid_channels, out_channels,  bias=True)\n",
    "\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.in_linear.apply(weights_init_uniform('leaky_relu'))\n",
    "        self.out_linear.apply(weights_init_uniform('tanh'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_linear(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.out_linear(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "class WNScale(nn.Module):\n",
    "\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, dim: int = 1, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.scale = nn.utils.weight_norm(nn.Linear(dim, dim))\n",
    "        self.weights_init_normal(self.scale)\n",
    "        self.weight = nn.Parameter(torch.tensor(\n",
    "            [1.0 + 0.01 * torch.randn((1, ))]))\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.weights_init_normal(self.scale)\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = torch.tensor([1.0 + 0.01 * torch.randn((1, ))], \n",
    "                                                dtype=self.weight.dtype, \n",
    "                                                device=self.weight.device)\n",
    "            \n",
    "    def forward(self, *args, **kwargs) -> torch.Tensor:\n",
    "        return self.scale(self.weight)\n",
    "\n",
    "    def weights_init_normal(self, m):\n",
    "        y = m.in_features\n",
    "        m.weight.data.normal_(0.0, 1/np.sqrt(y))\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class NormalizingFlow1D(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_coupling: int = 4,\n",
    "                 width: int = 130,\n",
    "                 num_blocks: int = 1,\n",
    "                 in_features: int = 2,\n",
    "                 backbone: Literal['default', 'residual_block', 'resnet'] = 'default',\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super(NormalizingFlow1D, self).__init__()\n",
    "        self.num_coupling = num_coupling\n",
    "        if self.num_coupling % in_features != 0:\n",
    "            raise ValueError(\n",
    "                f'Number of coupling layers should be divisible by in_features ({in_features})')\n",
    "        \n",
    "        _backbone: Union[SimpleBackbone, ResNet1D] = None\n",
    "        args = dict(in_channels=1)\n",
    "        if backbone == 'default':\n",
    "            _backbone = SimpleBackbone\n",
    "            args['network_width'] = width\n",
    "        elif backbone == 'resnet':\n",
    "            _backbone = SimpleResnet\n",
    "            args['mid_channels'] = width\n",
    "            args['out_channels'] = args['in_channels']\n",
    "            args['num_blocks'] = num_blocks\n",
    "        elif backbone == 'residual_block' or backbone == 'normal_block':\n",
    "            _backbone = NormalBlock\n",
    "            args['mid_channels'] = width\n",
    "            args['out_channels'] = args['in_channels']\n",
    "            #args['num_blocks'] = num_blocks\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Unknown backbone: {backbone}')\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.s = nn.ModuleList([_backbone(**args)\n",
    "                               for x in range(num_coupling)])\n",
    "        self.t = nn.ModuleList([_backbone(**args)\n",
    "                               for x in range(num_coupling)])\n",
    "        # Learnable scaling parameters for outputs of S\n",
    "        self.scale = nn.ModuleList([WNScale(dim=1)\n",
    "                                   for x in range(num_coupling)])\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        for s, t, scale in zip(self.s, self.t, self.scale):\n",
    "            s.reset_parameters()\n",
    "            t.reset_parameters()\n",
    "            scale.reset_parameters()\n",
    "        return True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # s_vals = []\n",
    "        x1, x2 = x[:, :1], x[:, 1:]\n",
    "        for i in range(self.num_coupling):\n",
    "            # Alternating which var gets transformed\n",
    "            if i % 2 == 0:\n",
    "                s = self.scale[i]() * self.s[i](x1)\n",
    "                x2 = torch.exp(s) * x2 + self.t[i](x1)\n",
    "            else:\n",
    "                s = self.scale[i]() * self.s[i](x2)\n",
    "                x1 = torch.exp(s) * x1 + self.t[i](x2)\n",
    "            # s_vals.append(s)\n",
    "\n",
    "        # Return outputs and vars needed for determinant\n",
    "        return torch.cat([x1, x2], 1)  # , torch.cat(s_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvexDiffeomorphismNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 130,\n",
    "                 n_hidden_layers: int = 1,\n",
    "                 nf_layers: int = 4,\n",
    "                 nf_hidden: int = 70,\n",
    "                 in_features: int = 2,\n",
    "                 diffeo_args: Dict[str, Any] = None,\n",
    "                 **kwargs):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "\n",
    "        self.convex_net = ConvexNextNet(\n",
    "            n_hidden=n_hidden,\n",
    "            in_features=in_features,\n",
    "            n_hidden_layers=n_hidden_layers)\n",
    "        if diffeo_args is None:\n",
    "            diffeo_args = dict()\n",
    "        self.in_features = in_features\n",
    "        # self.diffeo_net = DiffeomorphismNet()\n",
    "        if \"num_coupling\" not in diffeo_args:\n",
    "            diffeo_args[\"num_coupling\"] = nf_layers\n",
    "        if \"width\" not in diffeo_args:\n",
    "            diffeo_args[\"width\"] = nf_hidden\n",
    "        if \"in_features\" not in diffeo_args:\n",
    "            diffeo_args[\"in_features\"] = in_features\n",
    "\n",
    "        self.diffeo_net = NormalizingFlow1D(**diffeo_args)\n",
    "        self.linear = nn.Linear(in_features, in_features)\n",
    "        self.linear.apply(self.weights_init_normal)\n",
    "\n",
    "    def weights_init_normal(self, m):\n",
    "        classname = type(m).__name__\n",
    "        if classname.find('Linear') != -1:\n",
    "            y = m.in_features\n",
    "            m.weight.data.normal_(0.0, 1/np.sqrt(y))\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        self.convex_net.reset_parameters()\n",
    "        self.diffeo_net.reset_parameters()\n",
    "        self.linear.apply(self.weights_init_normal)\n",
    "        return True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        xd = self.diffeo_net(x)\n",
    "        xc = self.convex_net(xd)\n",
    "        return xc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformationFromLikelihood(likelihood, mask):\n",
    "    indices = torch.nonzero(mask)\n",
    "    N_fore = indices.shape[0]\n",
    "    print(N_fore)\n",
    "    pixel_info = torch.zeros((N_fore,2)) # store x,y values of all pixels the user marked as foreground\n",
    "\n",
    "    labels = torch.zeros(N_fore)\n",
    "    pixel_info[:,0] = indices[:,0] / nx -0.5\n",
    "    pixel_info[:,1] = indices[:,1] / ny -0.5\n",
    "    labels = likelihood[mask]\n",
    "    return pixel_info, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=\"cat_scribbled.jpg\"\n",
    "img_pil=Image.open(img_dir)\n",
    "width, height = img_pil.size \n",
    "newsize = (int(width/2), int(height/2))\n",
    "img_pil = img_pil.resize(newsize)\n",
    "\n",
    "img= np.array(img_pil, dtype='float')/255.0\n",
    "img = img[:,:,0:3]\n",
    "nx,ny,nc = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig_dir=\"cat.jpg\"\n",
    "img_orig_pil=Image.open(img_orig_dir)\n",
    "width, height = img_orig_pil.size \n",
    "newsize = (int(width), int(height))\n",
    "img_orig_pil = img_orig_pil.resize(newsize)\n",
    "\n",
    "img_orig= np.array(img_orig_pil, dtype='float')/255.0\n",
    "img_orig = img_orig[:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = torch.tensor((img[:,:,0]-img[:,:,1])>0.7).float()\n",
    "\n",
    "like = Image.fromarray(255*(likelihood.detach().numpy()).astype('uint8'))\n",
    "like.save(\"likelihood.png\")\n",
    "\n",
    "plt.imshow(likelihood)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(img[20:21,0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, criterion,  convexdiff, pix_fore, labels_fore, pix_back, labels_back, num_epochs, number):\n",
    "    # Train the model\n",
    "    loss_full = []\n",
    "    print(pix_back.size())\n",
    "    print(pix_fore.size())\n",
    "    for epoch in range(num_epochs):\n",
    "        # if epoch >= 500:\n",
    "        perm = torch.randperm(pix_back.size(0))\n",
    "        idx = perm[:number]\n",
    "        random_pix_back = pix_back[idx,:]\n",
    "        pix_back_labels = labels_back[idx]\n",
    "        \n",
    "        perm = torch.randperm(pix_fore.size(0))\n",
    "        idx = perm[:number]\n",
    "        random_pix_fore = pix_fore[idx,:]\n",
    "        pix_fore_labels = labels_fore[idx]\n",
    "        \n",
    "\n",
    "        outputs_back = torch.sigmoid(convexdiff(random_pix_back)).squeeze()\n",
    "        outputs_fore = torch.sigmoid(convexdiff(random_pix_fore)).squeeze()\n",
    "\n",
    "        loss = 2*criterion(outputs_back, pix_back_labels) + 1*criterion(outputs_fore, pix_fore_labels)\n",
    "\n",
    "\n",
    "        \n",
    "        loss_full.append(loss)\n",
    "            \n",
    "            \n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}],  Loss: {:.4f}' \n",
    "                .format(epoch+1, num_epochs, loss.item()))\n",
    "            \n",
    "    return convexdiff, loss_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convexdiff = ConvexDiffeomorphismNet()\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(convexdiff.parameters(), lr=1e-3)  \n",
    "num_epochs = 2000\n",
    "pix_back,labels_back = extractInformationFromLikelihood(likelihood,  likelihood<0.5)\n",
    "pix_fore,labels_fore = extractInformationFromLikelihood(likelihood, likelihood>0.5)\n",
    "\n",
    "number = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convexdiff, loss_full = train(optimizer, criterion, convexdiff, pix_fore, labels_fore, pix_back, labels_back, num_epochs, number)\n",
    "\n",
    "allPixels,temp = extractInformationFromLikelihood(likelihood,  likelihood>-0.5)\n",
    "\n",
    "inferenceResult = convexdiff(allPixels)\n",
    "inferenceResult = inferenceResult.detach().numpy().reshape((nx,ny))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot Loss  \n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(np.array([x.detach().cpu().numpy() for x in loss_full]))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot Segmentation Image\n",
    "_, axs = plt.subplots(1,3,figsize=(20,4))\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(likelihood.detach().numpy())\n",
    "axs[1].set_title('Likelihood')\n",
    "axs[2].imshow(img)\n",
    "axs[2].imshow(inferenceResult<0.5, cmap='binary', alpha=0.7)\n",
    "axs[2].set_title('Segmented Area')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img)\n",
    "plt.contour(inferenceResult, levels=[0.0], colors='purple',linewidths=3)\n",
    "#plt.imshow(inferenceResult<0.5, cmap='binary', alpha=0.7)\n",
    "#plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.savefig('connected.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img)\n",
    "plt.contour(likelihood, levels=[0.5], colors='purple',linewidths=3)\n",
    "plt.axis('off')\n",
    "plt.savefig('connected_naive.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img_orig_pil)\n",
    "plt.axis('off')\n",
    "plt.savefig('cat_re.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from awesome.run.functions import *\n",
    "\n",
    "img_orig_dir=\"cat.jpg\"\n",
    "img_orig_pil=np.array(Image.open(img_orig_dir))\n",
    "\n",
    "mask_path = './original/pc_prior_mask_rescale.png'\n",
    "orig_mask = load_mask_single_channel(mask_path) / 255\n",
    "\n",
    "like_path = './original/likelihood_rescaled.png'\n",
    "likelihood = load_mask_single_channel(like_path) / 255\n",
    "\n",
    "img = img_orig_pil\n",
    "crop_y = slice(11, img.shape[0] - 12)\n",
    "crop_x = slice(11, img.shape[1] - 24)\n",
    "\n",
    "constraint_name = \"pc\"\n",
    "image_name = \"cat\"\n",
    "path = \"./new/\"\n",
    "target_px = 1024\n",
    "target_py = 768\n",
    "actual_px = (crop_x.stop - crop_x.start)\n",
    "actual_py = (crop_y.stop - crop_y.start)\n",
    "# Recalculate crop start to get same aspect ratio as target_px and target_py\n",
    "aspect = target_px / target_py\n",
    "new_start = int(max(crop_x.start + ((actual_px - actual_py * aspect) / 2), 0))\n",
    "crop_x = slice(int(new_start), int(actual_px * aspect + new_start))\n",
    "actual_px = (crop_x.stop - crop_x.start)\n",
    "\n",
    "naive = likelihood[crop_y, crop_x]\n",
    "constraint = orig_mask[crop_y, crop_x]\n",
    "pimg = img[crop_y, crop_x]\n",
    "size = target_px / actual_px\n",
    "\n",
    "def resize_img(path, target_px, target_py):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((target_px, target_py))\n",
    "    img.save(path)\n",
    "\n",
    "color = plt.get_cmap('tab10')(0)\n",
    "save_path = path + f\"{image_name}_{constraint_name}_naive.png\"\n",
    "plot_mask(pimg, naive, contour_linewidths=1, size=size, color=color, tight=True, save=True, override=True, path=save_path, auto_close=True, display=True)\n",
    "resize_img(save_path, target_px, target_py)\n",
    "\n",
    "color = plt.get_cmap('tab10')(1)\n",
    "save_path = path + f\"{image_name}_{constraint_name}.png\"\n",
    "plot_mask(pimg, constraint, size=size, color=color, tight=True, save=True, override=True, path=save_path, auto_close=True, display=True)\n",
    "resize_img(save_path, target_px, target_py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

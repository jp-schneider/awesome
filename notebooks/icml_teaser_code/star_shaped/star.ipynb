{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from awesome.run.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=\"starfish.jpg\"\n",
    "img_pil=Image.open(img_dir)\n",
    "width, height = img_pil.size \n",
    "newsize = (int(width/2), int(height/2))\n",
    "img_pil = img_pil.resize(newsize)\n",
    "\n",
    "img= np.array(img_pil, dtype='float')/255.0\n",
    "img = img[:,:,0:3]\n",
    "\n",
    "nx,ny,nc = img.shape\n",
    "\n",
    "likelihood = img[:,:,0]-np.mean(img[:,:,0:2], axis=2) \n",
    "likelihood = torch.from_numpy(likelihood>0.1).float()\n",
    "\n",
    "plt.imshow(likelihood)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5766d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class myNet(nn.Module):\n",
    "    def __init__(self,n_hidden):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        \n",
    "        # define network layers\n",
    "        self.offset = torch.nn.Parameter(torch.zeros(1,2))\n",
    "        self.offset.requires_grad = False\n",
    "        self.W0 = nn.Linear(2, n_hidden)\n",
    "        self.W1 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.W2 = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.W1_r = nn.Linear(1, n_hidden)\n",
    "        self.W2_r = nn.Linear(n_hidden,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        x = x+self.offset\n",
    "        r = torch.sqrt(torch.sum(x**2,dim=1, keepdim=True))\n",
    "        x = x/(0.01+r)\n",
    "        \n",
    "        x_old = F.relu(self.W0(x))\n",
    "        r_aug = F.relu(self.W1(x_old)+self.W1_r(r))\n",
    "        x = r*(self.W2(x_old) + self.W2_r(r_aug))-1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_indices(img_shape):\n",
    "    ny, nx = img_shape\n",
    "    x = torch.linspace(-0.5, 0.5, nx)\n",
    "    y = torch.linspace(-0.5, 0.5, ny)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack((X.flatten(), Y.flatten()), dim=1)\n",
    "    return xy\n",
    "\n",
    "def extractInformationFromLikelihood(likelihood, mask):\n",
    "    indices = torch.nonzero(mask)\n",
    "    N_fore = indices.shape[0]\n",
    "    print(N_fore)\n",
    "    pixel_info = torch.zeros((N_fore,2)) # store x,y values of all pixels the user marked as foreground\n",
    "\n",
    "    labels = torch.zeros(N_fore)\n",
    "    pixel_info[:,0] = indices[:,0] / (nx-1) -0.5\n",
    "    pixel_info[:,1] = indices[:,1] / (ny-1) -0.5\n",
    "    labels = 1-likelihood[mask]\n",
    "    return pixel_info, labels\n",
    "\n",
    "net = myNet(150)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)  \n",
    "\n",
    "num_epochs = 10000\n",
    "pix_back,labels_back = extractInformationFromLikelihood(likelihood,  likelihood<0.5)\n",
    "pix_fore,labels_fore = extractInformationFromLikelihood(likelihood, likelihood>0.5)\n",
    "\n",
    "number = 500\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    perm = torch.randperm(pix_back.size(0))\n",
    "    idx = perm[:number]\n",
    "    random_pix_back = pix_back[idx,:]\n",
    "    pix_back_labels = labels_back[idx]\n",
    "    \n",
    "    perm = torch.randperm(pix_fore.size(0))\n",
    "    idx = perm[:number]\n",
    "    random_pix_fore = pix_fore[idx,:]\n",
    "    pix_fore_labels = labels_fore[idx]\n",
    "    \n",
    "    random_pix = torch.concat((random_pix_back, random_pix_fore), axis=0)\n",
    "    pix_labels = torch.concat((pix_back_labels, pix_fore_labels), axis=0)\n",
    "    \n",
    "    \n",
    "    outputs = torch.sigmoid(net(random_pix)).squeeze()\n",
    "    \n",
    "    loss = criterion(outputs, pix_labels) \n",
    "    if epoch ==1000:\n",
    "        net.offset.requires_grad = True\n",
    "    #    loss += 0.1*torch.sum(torch.sigmoid(net(net.offset.data)))\n",
    "    \n",
    "    #print(torch.sigmoid(net(net.offset.data)))\n",
    "        \n",
    "    # Backprpagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        net.W2_r.weight.data = F.relu(net.W2_r.weight.data)\n",
    "\n",
    "    if (epoch+1) % 400 == 0:\n",
    "        print ('Epoch [{}/{}],  Loss: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02463e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPixels,temp = extractInformationFromLikelihood(likelihood,  likelihood>-0.5)\n",
    "\n",
    "inferenceResult = net(allPixels) # torch tensor of size nx*ny\n",
    "inferenceResult = inferenceResult.detach().numpy().reshape((nx,ny))\n",
    "\n",
    "im = Image.fromarray(255*(inferenceResult<0.5).astype('uint8'))\n",
    "im.save(\"mask.png\")\n",
    "\n",
    "if False:\n",
    "    img[0:2,:,:]=0.0\n",
    "    img[:,0:2,:]=0.0\n",
    "    img[:,-2:,:]=0.0\n",
    "    img[-2:,:,:]=0.0\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.contour(likelihood, levels=[0.5], colors='purple')\n",
    "#plt.imshow(inferenceResult<0.5, cmap='binary', alpha=0.7)\n",
    "#plt.plot((-net.offset.data.detach().numpy()[0,1]+0.5)*ny, (-net.offset.data.detach().numpy()[0,0]+0.5)*nx,'x', color='purple')\n",
    "#plt.plot((0.5)*ny, (0.5)*nx,'x', color='green')\n",
    "plt.axis('off')\n",
    "#plt.colorbar()\n",
    "plt.savefig('result_naive.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-0.5, 0.5, nx)\n",
    "y = torch.linspace(-0.5, 0.5, ny)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "xy = torch.stack((Y.flatten(), X.flatten()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-0.5, 0.5, nx)\n",
    "y = torch.linspace(-0.5, 0.5, ny)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "xy = torch.stack((X.flatten(), Y.flatten()), dim=1)\n",
    "\n",
    "\n",
    "def prepare_indices(img_shape):\n",
    "    ny, nx = img_shape\n",
    "    x = torch.linspace(-0.5, 0.5, nx)\n",
    "    y = torch.linspace(-0.5, 0.5, ny)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack((X.flatten(), Y.flatten()), dim=1)\n",
    "    return xy\n",
    "\n",
    "nx, ny = img.shape[:2]\n",
    "with torch.no_grad():\n",
    "    pred_logits = net(prepare_indices((ny, nx))).detach().reshape(nx, ny)\n",
    "    pred = torch.sigmoid(pred_logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape[:2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c395d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import *\n",
    "\n",
    "\n",
    "mask_path = './original/mask.png'\n",
    "orig_mask = load_mask_single_channel(mask_path) / 255\n",
    "\n",
    "\n",
    "crop_y = slice(0, img.shape[0])\n",
    "crop_x = slice(0, img.shape[1])\n",
    "\n",
    "constraint_name = \"starconvex\"\n",
    "image_name = \"starfish\"\n",
    "path = \"./new/\"\n",
    "target_px = 1024\n",
    "target_py = 768\n",
    "actual_px = (crop_x.stop - crop_x.start)\n",
    "actual_py = (crop_y.stop - crop_y.start)\n",
    "# Recalculate crop start to get same aspect ratio as target_px and target_py\n",
    "aspect = target_px / target_py\n",
    "new_start = int(max(round(crop_x.start + ((actual_px - actual_py * aspect)) // 2), 0))\n",
    "crop_x = slice(int(new_start), int(actual_py * aspect + new_start))\n",
    "\n",
    "actual_px = (crop_x.stop - crop_x.start)\n",
    "\n",
    "naive = likelihood[crop_y, crop_x]\n",
    "constraint = orig_mask[crop_y, crop_x]\n",
    "pimg = img[crop_y, crop_x]\n",
    "\n",
    "size = target_px / actual_px\n",
    "\n",
    "\n",
    "def resize_img(path, target_px, target_py):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((target_px, target_py))\n",
    "    img.save(path)\n",
    "\n",
    "\n",
    "color = plt.get_cmap('tab10')(0)\n",
    "save_path = path + f\"{image_name}_{constraint_name}_naive.png\"\n",
    "plot_mask(pimg, naive, contour_linewidths=1, size=size, color=color, tight=True, save=True, override=True, path=save_path, auto_close=True)\n",
    "resize_img(save_path, target_px, target_py)\n",
    "\n",
    "color = plt.get_cmap('tab10')(1)\n",
    "save_path = path + f\"{image_name}_{constraint_name}.png\"\n",
    "plot_mask(pimg, constraint, size=size, color=color, tight=True, save=True, override=True, path=save_path, auto_close=True)\n",
    "resize_img(save_path, target_px, target_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_px / actual_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "((actual_px - actual_py * aspect) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_px - actual_py * aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(pimg.shape[:2]) * size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d521cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import *\n",
    "plot_mask_multi_channel(img, np.stack([likelihood > 0.5, 1 - (pred > 0.5)], axis=2), size=5, tight=True, save=True, override=True, path='./starfish_naive_and_cvx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ebe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_subsample(img: torch.Tensor, factor: int = 6, mode: Literal[\"grid_sample\", \"slicing\"] = \"grid_sample\"):\n",
    "    if mode == \"grid_sample\":\n",
    "        x = torch.arange(-1, 1, (2 * factor) / img.shape[-2])\n",
    "        y = torch.arange(-1, 1, (2 * factor) / img.shape[-1])\n",
    "        xx, yy = torch.meshgrid(x, y)\n",
    "        flowgrid = torch.stack((yy, xx), dim=-1).float()[None,...]\n",
    "        return F.grid_sample(img[None,...], flowgrid, align_corners=True)[0, ...]\n",
    "    elif mode == \"slicing\":\n",
    "        return img[..., ::factor, ::factor]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode\")\n",
    "\n",
    "factor = 1\n",
    "\n",
    "img_sub = image_subsample(torch.tensor(img).permute(2,0,1).float(), factor)\n",
    "res_hull_sub =  image_subsample(pred_logits.unsqueeze(0), factor)\n",
    "\n",
    "mask_like_sub = image_subsample(likelihood.unsqueeze(0), factor) > 0.5\n",
    "mask_pred_sub = res_hull_sub > 0.5\n",
    "\n",
    "\n",
    "fig = plot_surface_logits(img_sub, res_hull_sub, \n",
    "    foreground_scribble_mask=torch.zeros(img_sub.shape[1:3]), \n",
    "    background_scribble_mask=torch.zeros(img_sub.shape[1:3]),\n",
    "    image_subsampling=1,\n",
    "    surface_log=True,\n",
    "    surface_log_eps=1e-2,\n",
    "    elevation=60,\n",
    "    azimuth=-90,\n",
    "    zoom=1.3,\n",
    "    transparent=True,\n",
    "    save=True, \n",
    "    path=\"./starfish_naive_and_cvx_surface\", ext=[\"png\", \"pdf\"], override=True)\n",
    "\n",
    "fig = plot_mask_multi_channel(img, np.stack([likelihood > 0.5, 1 - (pred > 0.5)], axis=2), size=3.2, tight=True, darkening_background=0.)\n",
    "inpainted_img = torch.tensor(figure_to_numpy(fig, dpi=fig.dpi, transparent=False)[:, :, :3].astype(np.float32) / 255.0).permute(2,0,1).float()\n",
    "inpainted_img_sub = image_subsample(inpainted_img, factor)\n",
    "\n",
    "fig = plot_surface_logits(inpainted_img_sub, res_hull_sub, \n",
    "    foreground_scribble_mask=torch.zeros(img_sub.shape[1:3]), \n",
    "    background_scribble_mask=torch.zeros(img_sub.shape[1:3]),\n",
    "    image_subsampling=1,\n",
    "    surface_log=True,\n",
    "    surface_log_eps=1e-2,\n",
    "    elevation=60,\n",
    "    azimuth=-90,\n",
    "    zoom=1.3,\n",
    "    transparent=True,\n",
    "    save=True, \n",
    "    path=\"./starfish_naive_and_cvx_surface_mask\", ext=[\"png\", \"pdf\"], override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpainted_img.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface_logits(inpainted_img, likelihood.unsqueeze(0), \n",
    "    foreground_scribble_mask=torch.zeros(inpainted_img.shape[1:3]), \n",
    "    background_scribble_mask=torch.zeros(inpainted_img.shape[1:3]),\n",
    "    image_subsampling=1,\n",
    "    surface_log=True,\n",
    "    surface_log_eps=1e-2,\n",
    "    elevation=60,\n",
    "    azimuth=-90,\n",
    "    zoom=1.3,\n",
    "    transparent=True,\n",
    "    save=True, \n",
    "    path=\"./starfish_naive_and_cvx_surface_hr\", ext=[\"png\"], override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d19e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpainted_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f16f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_mask_multi_channel(img, np.stack([likelihood > 0.5, 1 - (pred > 0.5)], axis=2), size=3.2, tight=True)\n",
    "inpainted_img = figure_to_numpy(fig, dpi=fig.dpi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbad1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = figure_to_numpy(fig, dpi=fig.dpi)\n",
    "plot_as_image(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(img).permute(2,0,1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_as_image(pred_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05737cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_indices(img_shape):\n",
    "    ny, nx = img_shape\n",
    "    x = torch.linspace(-0.5, 0.5, nx)\n",
    "    y = torch.linspace(-0.5, 0.5, ny)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack((Y, X), dim=0)\n",
    "    return xy.reshape(2, -1).T\n",
    "pxy = prepare_indices(img.shape[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_img(path, lng_px):\n",
    "    path = os.path.abspath(path)\n",
    "    dirname = os.path.dirname(path)\n",
    "    basename, ext = os.path.splitext(os.path.basename(path))\n",
    "    rn_path = os.path.join(dirname, f\"{basename}_resized{ext}\")\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    py, px = img.size\n",
    "    ratio = py / px\n",
    "    target_px = lng_px\n",
    "    target_py = lng_px\n",
    "\n",
    "    if ratio > 1:\n",
    "        target_py = int(lng_px / ratio)\n",
    "    else:\n",
    "        target_px = int(lng_px * ratio)    \n",
    "    img = img.resize((target_px, target_py))\n",
    "    img.save(rn_path)\n",
    "resize_img(\"./temp/cars3_joined_axes_40_60.png\", 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b75f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img(\"./temp/cars3_joined_axes_40_60.png\", 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

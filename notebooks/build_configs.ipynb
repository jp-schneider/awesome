{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from awesome.run.awesome_config import AwesomeConfig\n",
    "from awesome.run.awesome_runner import AwesomeRunner\n",
    "from awesome.util.reflection import class_name\n",
    "import os\n",
    "import torch\n",
    "from typing import List, Tuple, Union, Dict, Literal, Optional\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.dataset.convexity_segmentation_dataset import ConvexitySegmentationDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "from awesome.model.net import Net\n",
    "import awesome\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "import copy\n",
    "\n",
    "os.chdir(get_project_root_path()) # Beeing in the root directory of the project is important for the relative paths to work consistently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Run Configurations for the different scenarios and models\n",
    "\n",
    "This Notebook is used to generate all the configs in the [config](../config) folder which are used to run the different scenarios and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models from Hannah Dröge's Paper \n",
    "Dröge, Hannah; Moeller, Michael (2021): Learning or Modelling? An Analysis of Single Image Segmentation Based on Scribble Information. In : 2021 IEEE International Conference on Image Processing (ICIP). IEEE, pp. 2274–2278."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. FCNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FCNET with serveral feat combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET xy\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "xytypes = [\"xy\", \"featxy\", \"feat\"]\n",
    "\n",
    "for xytype in xytypes:\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"FCNET_benchmark+{xytype}\",\n",
    "        dataset_type=class_name(SISBOSIDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": SISBOSIConvexityDataset(\n",
    "                    dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                    transform=False, # Using augmentations\n",
    "                    semantic=False\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "            \"bs\" : None,\n",
    "            \"dimension\": \"2d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(FCNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=False,\n",
    "        prior_model_args=None,\n",
    "        prior_model_type=None,\n",
    "        loss_type=class_name(RegularizerLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"tau\": 0.,\n",
    "            \"regularizer\": TV(),\n",
    "        },\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs\",\n",
    "        use_progress_bar=False,\n",
    "    )\n",
    "    cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FCNET with ConvexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "xytypes = [\"xy\", \"featxy\", \"feat\"]\n",
    "seeds = [47, 131]\n",
    "\n",
    "for xytype in xytypes:\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"FCNET_benchmark+{xytype}+convex\",\n",
    "        dataset_type=class_name(SISBOSIDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": SISBOSIConvexityDataset(\n",
    "                    dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                    transform=False, # Using augmentations\n",
    "                    semantic=False\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "            \"bs\" : None,\n",
    "            \"dimension\": \"2d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(FCNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeLoss),\n",
    "        loss_args={\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"tau\": 0.,\n",
    "                \"regularizer\": TV(),\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs\",\n",
    "        use_progress_bar=False,\n",
    "    )\n",
    "    cfg.save_to_file(f\"./config/rerun_unireps/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)\n",
    "    for seed in seeds:\n",
    "        c = copy.deepcopy(cfg)\n",
    "        c.seed = seed\n",
    "        c.name_experiment = cfg.name_experiment + f\"+seed{seed}\"\n",
    "        c.save_to_file(f\"./config/rerun_unireps/{c.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCNET with ConvexNet Joint Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_loss_joint import AwesomeLossJoint\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "xytypes = [\"xy\", \"featxy\", \"feat\"]\n",
    "seeds = [47, 131]\n",
    "for xytype in xytypes:\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"FCNET_benchmark+{xytype}+convex+joint\",\n",
    "        dataset_type=class_name(SISBOSIDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": SISBOSIConvexityDataset(\n",
    "                    dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                    transform=False, # Using augmentations\n",
    "                    semantic=False\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "            \"bs\" : None,\n",
    "            \"dimension\": \"2d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(FCNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeLossJoint),\n",
    "        loss_args={\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"tau\": 0.,\n",
    "                \"regularizer\": TV(),\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_reduce_lr_in_extra_penalty_hook=True,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs\",\n",
    "        use_progress_bar=False,\n",
    "    )\n",
    "    cfg.save_to_file(f\"./config/benchmarks/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)\n",
    "    for seed in seeds:\n",
    "        c = copy.deepcopy(cfg)\n",
    "        c.seed = seed\n",
    "        c.name_experiment = cfg.name_experiment + f\"+seed{seed}\"\n",
    "        c.save_to_file(f\"./config/benchmarks_seeds/{c.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FCNET with Diffeomophism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET Using xy and diffeo\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"FCNET_benchmark+xy+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"xy\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"2d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(FCNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeLoss),\n",
    "    loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"tau\": 0.,\n",
    "            \"regularizer\": TV(),\n",
    "            \"name\": \"BCE\",\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET Using featxy and diffeo\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"FCNET_benchmark+featxy+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"featxy\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"2d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(FCNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeLoss),\n",
    "    loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"tau\": 0.,\n",
    "            \"regularizer\": TV(),\n",
    "            \"name\": \"BCE\",\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FCNET Using feat and diffeo\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.measures.tv import TV\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"FCNET_benchmark+feat+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"feat\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"2d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": False, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(FCNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeLoss),\n",
    "    loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"tau\": 0.,\n",
    "            \"regularizer\": TV(),\n",
    "            \"name\": \"BCE\",\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CNNet with ConvexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "xytypes = [\"xy\", \"featxy\", \"feat\"]\n",
    "seeds = [47, 131]\n",
    "\n",
    "for xytype in xytypes:\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_benchmark+{xytype}+convex\",\n",
    "        dataset_type=class_name(SISBOSIDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": SISBOSIConvexityDataset(\n",
    "                    dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                    transform=False, # Using augmentations\n",
    "                    semantic=False\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "            \"bs\" : None,\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeImageLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.01,\n",
    "                \"rgbgrad\" : 0.01,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,})\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs\",\n",
    "        use_progress_bar=False,\n",
    "    )\n",
    "    cfg.save_to_file(f\"./config/rerun_unireps/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)\n",
    "    for seed in seeds:\n",
    "        c = copy.deepcopy(cfg)\n",
    "        c.seed = seed\n",
    "        c.name_experiment = cfg.name_experiment + f\"+seed{seed}\"\n",
    "        c.save_to_file(f\"./config/rerun_unireps/{c.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet Joint Training\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "xytypes = [\"xy\", \"featxy\", \"feat\"]\n",
    "seeds = [47, 131]\n",
    "for xytype in xytypes:\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_benchmark+{xytype}+convex+joint\",\n",
    "        dataset_type=class_name(SISBOSIDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": SISBOSIConvexityDataset(\n",
    "                    dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                    transform=False, # Using augmentations\n",
    "                    semantic=False\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "            \"bs\" : None,\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeImageLossJoint),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.01,\n",
    "                \"rgbgrad\" : 0.01,\n",
    "                \"featgrad\" : 0,\n",
    "                \"xytype\" : xytype,\n",
    "                })\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_reduce_lr_in_extra_penalty_hook=True,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs\",\n",
    "        use_progress_bar=False,\n",
    "    )\n",
    "    cfg.save_to_file(f\"./config/benchmarks/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)\n",
    "    for seed in seeds:\n",
    "        c = copy.deepcopy(cfg)\n",
    "        c.seed = seed\n",
    "        c.name_experiment = cfg.name_experiment + f\"+seed{seed}\"\n",
    "        c.save_to_file(f\"./config/benchmarks_seeds/{c.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNNET with Diffeomophism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet Using feat and diffeo net\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"CNNET_benchmark+feat+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"feat\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"3d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(CNNNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 2,\n",
    "        'kernel_size': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeImageLoss),\n",
    "    loss_args={\n",
    "        \"criterion\": GradientPenaltyLoss(**{\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"apply_gradient_penalty\": True,\n",
    "            \"noneclass\" : 2.,\n",
    "            \"xygrad\" : 0.01,\n",
    "            \"rgbgrad\" : 0.01,\n",
    "            \"name\": \"BCE+GradientPenalty\",})\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet Using featxy and diffeo net\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"CNNET_benchmark+featxy+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"featxy\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"3d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(CNNNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 2,\n",
    "        'kernel_size': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeImageLoss),\n",
    "    loss_args={\n",
    "        \"criterion\": GradientPenaltyLoss(**{\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"apply_gradient_penalty\": True,\n",
    "            \"noneclass\" : 2.,\n",
    "            \"xygrad\" : 0.01,\n",
    "            \"rgbgrad\" : 0.01,\n",
    "            \"name\": \"BCE+GradientPenalty\",})\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet Using xy and diffeo net\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"CNNET_benchmark+xy+diffeo\",\n",
    "    dataset_type=class_name(SISBOSIDataset),\n",
    "    dataset_args={\n",
    "        \"dataset\": SISBOSIConvexityDataset(\n",
    "                dataset_path=\"./data/datasets/convexity_dataset\",\n",
    "                transform=False, # Using augmentations\n",
    "                semantic=False\n",
    "            ),\n",
    "        \"xytransform\": \"xy\",\n",
    "        \"xytype\": \"xy\",\n",
    "        \"mode\": \"scribbles\",\n",
    "        \"feature_dir\": \"./data/datasets/convexity_dataset/Feat\",\n",
    "        \"bs\" : None,\n",
    "        \"dimension\": \"3d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    segmentation_model_type=class_name(CNNNet),\n",
    "    segmentation_model_args={\n",
    "        'width': 16,\n",
    "        'depth': 2,\n",
    "        'kernel_size': 3,\n",
    "        'input': 'rgbxy',\n",
    "    },\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeImageLoss),\n",
    "    loss_args={\n",
    "        \"criterion\": GradientPenaltyLoss(**{\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"apply_gradient_penalty\": True,\n",
    "            \"noneclass\" : 2.,\n",
    "            \"xygrad\" : 0.01,\n",
    "            \"rgbgrad\" : 0.01,\n",
    "            \"name\": \"BCE+GradientPenalty\",})\n",
    "        },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Pixel-wise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net without Prior\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.dataset.convexity_segmentation_dataset import ConvexitySegmentationDataset\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.model.net import Net\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"NET_benchmark\",\n",
    "    dataset_type=class_name(ConvexitySegmentationDataset),\n",
    "    dataset_args={\n",
    "        \"dataset_path\": \"./data/datasets/convexity_dataset\",\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1.,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    scribble_percentage=1.,\n",
    "    segmentation_model_type=class_name(Net),\n",
    "    segmentation_model_args=dict(),\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=False,\n",
    "    prior_model_args=None,\n",
    "    prior_model_type=None,\n",
    "    loss_type=class_name(torch.nn.BCELoss),\n",
    "    loss_args={},\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net with convex prior\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.dataset.convexity_segmentation_dataset import ConvexitySegmentationDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.model.net import Net\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"NET_benchmark+convex\",\n",
    "    dataset_type=class_name(ConvexitySegmentationDataset),\n",
    "    dataset_args={\n",
    "        \"dataset_path\": \"./data/datasets/convexity_dataset\",\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1.,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    scribble_percentage=0.8,\n",
    "    segmentation_model_type=class_name(Net),\n",
    "    segmentation_model_args=dict(n_hidden=130),\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(n_hidden=130),\n",
    "    prior_model_type=class_name(ConvexNet),\n",
    "    loss_type=class_name(AwesomeLoss),\n",
    "    loss_args={\n",
    "        \"criterion\": torch.nn.BCELoss(),\n",
    "        \"alpha\": 1.,\n",
    "        \"name\": \"BCE\",\n",
    "    },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net with convex prior\n",
    "\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.dataset.convexity_segmentation_dataset import ConvexitySegmentationDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.fc_net import FCNet\n",
    "from awesome.model.net import Net\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "    name_experiment=\"NET_benchmark+diffeo\",\n",
    "    dataset_type=class_name(ConvexitySegmentationDataset),\n",
    "    dataset_args={\n",
    "        \"dataset_path\": \"./data/datasets/convexity_dataset\",\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1.,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "    },\n",
    "    scribble_percentage=0.8,\n",
    "    segmentation_model_type=class_name(Net),\n",
    "    segmentation_model_args=dict(n_hidden=130),\n",
    "    segmentation_training_mode='single',\n",
    "    use_prior_model=True,\n",
    "    prior_model_args=dict(n_hidden=130),\n",
    "    prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "    loss_type=class_name(AwesomeLoss),\n",
    "    loss_args={\n",
    "        \"criterion\": torch.nn.BCELoss(),\n",
    "        \"alpha\": 1.,\n",
    "        \"name\": \"BCE\",\n",
    "    },\n",
    "    use_binary_classification=True, \n",
    "    num_epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    dtype=str(torch.float32),\n",
    "    runs_path=\"./runs\",\n",
    "    use_progress_bar=False,\n",
    ")\n",
    "cfg.save_to_file(f\"./config/{cfg.name_experiment}.yaml\", no_uuid=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBMS Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBMS CNNet Convex Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "xytypes = [\"featxy\", \"feat\"]\n",
    "datasets = [\n",
    "'camel01',\n",
    " 'cars1',\n",
    " 'cars10',\n",
    " 'cars4',\n",
    " 'cars5',\n",
    " 'cats01',\n",
    " 'cats03',\n",
    " 'cats06',\n",
    " 'dogs01',\n",
    " 'dogs02',\n",
    " 'farm01',\n",
    " 'giraffes01',\n",
    " 'goats01',\n",
    " 'horses02',\n",
    " 'horses04',\n",
    " 'horses05',\n",
    " 'lion01',\n",
    " 'marple12',\n",
    " 'marple2',\n",
    " 'marple4',\n",
    " 'marple6',\n",
    " 'marple7',\n",
    " 'marple9',\n",
    " 'people03',\n",
    " 'people1',\n",
    " 'people2',\n",
    " 'rabbits02',\n",
    " 'rabbits03',\n",
    " 'rabbits04',\n",
    " 'tennis']\n",
    "\n",
    "it = product(xytypes, datasets)\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    print(xytype, dataset)\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_+{dataset}+{xytype}+convex\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=f\"./data/local_datasets/FBMS-59/test/{dataset}\"\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": f\"./data/local_datasets/FBMS-59/test/{dataset}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeImageLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.001,\n",
    "                \"rgbgrad\" : 0.001,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 1.0,\n",
    "            \"beta\": 1.0,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms\",\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3]\n",
    "    )\n",
    "    path = f\"./config/fbms/{dataset}/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBMS CNNNet Joint Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# xytypes = [\"featxy\", \"feat\"]\n",
    "# datasets = [\n",
    "# 'camel01',\n",
    "#  'cars1',\n",
    "#  'cars10',\n",
    "#  'cars4',\n",
    "#  'cars5',\n",
    "#  'cats01',\n",
    "#  'cats03',\n",
    "#  'cats06',\n",
    "#  'dogs01',\n",
    "#  'dogs02',\n",
    "#  'farm01',\n",
    "#  'giraffes01',\n",
    "#  'goats01',\n",
    "#  'horses02',\n",
    "#  'horses04',\n",
    "#  'horses05',\n",
    "#  'lion01',\n",
    "#  'marple12',\n",
    "#  'marple2',\n",
    "#  'marple4',\n",
    "#  'marple6',\n",
    "#  'marple7',\n",
    "#  'marple9',\n",
    "#  'people03',\n",
    "#  'people1',\n",
    "#  'people2',\n",
    "#  'rabbits02',\n",
    "#  'rabbits03',\n",
    "#  'rabbits04',\n",
    "#  'tennis']\n",
    "\n",
    "# it = product(xytypes, datasets)\n",
    "\n",
    "datasets = ['cars1', 'cars1', 'marple9', 'cars5', 'people2', 'marple2', 'tennis', 'marple4', 'cars10']\n",
    "features = ['feat', 'featxy', 'feat', 'featxy', 'feat', 'feat', 'feat', 'featxy', 'featxy']\n",
    "\n",
    "it = zip(features, datasets)\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    print(xytype, dataset)\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_+{dataset}+{xytype}+convex+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=f\"./data/local_datasets/FBMS-59/test/{dataset}\"\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": f\"./data/local_datasets/FBMS-59/test/{dataset}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(),\n",
    "        prior_model_type=class_name(ConvexNet),\n",
    "        loss_type=class_name(AwesomeImageLossJoint),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.001,\n",
    "                \"rgbgrad\" : 0.001,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 1.0,\n",
    "            \"beta\": 1.0,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_reduce_lr_in_extra_penalty_hook=True,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=3000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms\",\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3]\n",
    "    )\n",
    "    path = f\"./config/fbms/joint/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBMS CNNet Diffeo Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from itertools import product\n",
    "\n",
    "xytypes = [\"xy\"]#, \"featxy\", \"feat\"]\n",
    "datasets = [\n",
    "'camel01',\n",
    " 'cars1',\n",
    " 'cars10',\n",
    " 'cars4',\n",
    " 'cars5',\n",
    " 'cats01',\n",
    " 'cats03',\n",
    " 'cats06',\n",
    " 'dogs01',\n",
    " 'dogs02',\n",
    " 'farm01',\n",
    " 'giraffes01',\n",
    " 'goats01',\n",
    " 'horses02',\n",
    " 'horses04',\n",
    " 'horses05',\n",
    " 'lion01',\n",
    " 'marple12',\n",
    " 'marple2',\n",
    " 'marple4',\n",
    " 'marple6',\n",
    " 'marple7',\n",
    " 'marple9',\n",
    " 'people03',\n",
    " 'people1',\n",
    " 'people2',\n",
    " 'rabbits02',\n",
    " 'rabbits03',\n",
    " 'rabbits04',\n",
    " 'tennis']\n",
    "\n",
    "it = product(xytypes, datasets)\n",
    "\n",
    "# datasets = ['cars1', 'cars1', 'marple9', 'cars5', 'people2', 'marple2', 'tennis', 'marple4', 'cars10']\n",
    "# features = ['feat', 'featxy', 'feat', 'featxy', 'feat', 'feat', 'feat', 'featxy', 'featxy']\n",
    "\n",
    "# it = zip(features, datasets)\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    print(xytype, dataset)\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_+{dataset}+{xytype}+diffeo\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=f\"./data/local_datasets/FBMS-59/test/{dataset}\"\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": f\"./data/local_datasets/FBMS-59/test/{dataset}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            nf_layers=3,\n",
    "            nf_hidden=70\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(AwesomeImageLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.001,\n",
    "                \"rgbgrad\" : 0.001,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 1.0,\n",
    "            \"beta\": 1.0,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/slurm_monitor/fbms\",\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3]\n",
    "    )\n",
    "    path = f\"./config/fbms_diffeo/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBMS CNNNet Joint Diffeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from itertools import product\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "\n",
    "# xytypes = [\"featxy\", \"feat\"]\n",
    "# datasets = [\n",
    "# 'camel01',\n",
    "#  'cars1',\n",
    "#  'cars10',\n",
    "#  'cars4',\n",
    "#  'cars5',\n",
    "#  'cats01',\n",
    "#  'cats03',\n",
    "#  'cats06',\n",
    "#  'dogs01',\n",
    "#  'dogs02',\n",
    "#  'farm01',\n",
    "#  'giraffes01',\n",
    "#  'goats01',\n",
    "#  'horses02',\n",
    "#  'horses04',\n",
    "#  'horses05',\n",
    "#  'lion01',\n",
    "#  'marple12',\n",
    "#  'marple2',\n",
    "#  'marple4',\n",
    "#  'marple6',\n",
    "#  'marple7',\n",
    "#  'marple9',\n",
    "#  'people03',\n",
    "#  'people1',\n",
    "#  'people2',\n",
    "#  'rabbits02',\n",
    "#  'rabbits03',\n",
    "#  'rabbits04',\n",
    "#  'tennis']\n",
    "\n",
    "# it = product(xytypes, datasets)\n",
    "\n",
    "datasets = ['cars1', 'cars1', 'marple9', 'cars5', 'people2', 'marple2', 'tennis', 'marple4', 'cars10']\n",
    "features = ['feat', 'featxy', 'feat', 'featxy', 'feat', 'feat', 'feat', 'featxy', 'featxy']\n",
    "\n",
    "it = zip(features, datasets)\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    print(xytype, dataset)\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_+{dataset}+{xytype}+diffeo+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=f\"./data/local_datasets/FBMS-59/test/{dataset}\"\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": f\"./data/local_datasets/FBMS-59/test/{dataset}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            nf_layers=3,\n",
    "            nf_hidden=70\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(AwesomeImageLossJoint),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.001,\n",
    "                \"rgbgrad\" : 0.001,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 1.0,\n",
    "            \"beta\": 1.0,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        use_reduce_lr_in_extra_penalty_hook=True,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/slurm_monitor/fbms\",\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3]\n",
    "    )\n",
    "    path = f\"./config/fbms_diffeo_joint/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet Amir with Weighting Sequentialy Training => Equivalent what amir does in his paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = ['bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   'cars9',\n",
    "   'cats02',\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   'cats07',\n",
    "   'ducks01',\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   'horses06',\n",
    "   'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   'marple13',\n",
    "   'marple3',\n",
    "   'marple5',\n",
    "   'marple8',\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   'people05',\n",
    "   'rabbits01',\n",
    "   'rabbits05']\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "            name_experiment=f\"UNET+{dataset}+{xytype}+diffeo\",\n",
    "            dataset_type=class_name(AwesomeDataset),\n",
    "            dataset_args={\n",
    "                \"dataset\": FBMSSequenceDataset(\n",
    "                        dataset_path=data_path,\n",
    "                        weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                        processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                        confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                        do_weak_label_preprocessing=True,\n",
    "                        do_uncertainty_label_flip=True,\n",
    "                        all_frames=False\n",
    "                    ),\n",
    "                \"xytype\": xytype,\n",
    "                \"feature_dir\": f\"{data_path}/Feat\",\n",
    "                \"dimension\": \"3d\", # 2d for fcnet\n",
    "                \"mode\": \"model_input\",\n",
    "                \"model_input_requires_grad\": False,\n",
    "                \"batch_size\": 1,\n",
    "                \"split_ratio\": 1,\n",
    "                \"shuffle_in_dataloader\": False,\n",
    "                \"image_channel_format\": \"bgr\",\n",
    "                \"do_image_blurring\": True\n",
    "            },\n",
    "            segmentation_model_type=class_name(UNet),\n",
    "            segmentation_model_args={\n",
    "                'in_chn': 4,\n",
    "            },\n",
    "            segmentation_training_mode='single',\n",
    "            segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "            use_segmentation_output_inversion=True,\n",
    "            use_prior_model=True,\n",
    "            prior_model_args=dict(\n",
    "                nf_layers=3,\n",
    "                nf_hidden=70\n",
    "            ),\n",
    "            prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "            loss_type=class_name(AwesomeImageLoss),\n",
    "            loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                    \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                    \"apply_gradient_penalty\": False,\n",
    "                    \"noneclass\" : 2.,\n",
    "                    \"xygrad\" : 0.0,\n",
    "                    \"rgbgrad\" : 0.0,\n",
    "                    \"featgrad\" : 0.0,\n",
    "                    \"xytype\" : xytype}),\n",
    "                \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                    \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                    \"apply_gradient_penalty\": False,\n",
    "                    \"noneclass\" : 2.,}),\n",
    "                \"gamma\": 0.5,\n",
    "                \"beta\": 0.5,\n",
    "                },\n",
    "            use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "            extra_penalty_after_n_epochs=800,\n",
    "            use_reduce_lr_in_extra_penalty_hook=False,\n",
    "            use_lr_on_plateau_scheduler=False,\n",
    "            use_binary_classification=True, \n",
    "            num_epochs=4000,\n",
    "            device=\"cuda\",\n",
    "            dtype=str(torch.float32),\n",
    "            runs_path=\"./runs/fbms_local/unet/\",\n",
    "            optimizer_args={\n",
    "                \"lr\": 0.01,\n",
    "                \"betas\": (0.9, 0.999),\n",
    "                \"eps\": 1e-08,\n",
    "                \"weight_decay\": 0,\n",
    "                \"amsgrad\": False\n",
    "            },\n",
    "            use_progress_bar=True,\n",
    "            semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "            semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "            plot_indices_during_training_nth_epoch=20,\n",
    "            plot_indices_during_training=[0, 1, 2, 3],\n",
    "        )\n",
    "    path = f\"./config/fbms_unet_diffeo/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Amir with Weighting Jointly Training => Equivalent what amir does in his paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = ['bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   'cars9',\n",
    "   'cats02',\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   'cats07',\n",
    "   'ducks01',\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   'horses06',\n",
    "   'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   'marple13',\n",
    "   'marple3',\n",
    "   'marple5',\n",
    "   'marple8',\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   'people05',\n",
    "   'rabbits01',\n",
    "   'rabbits05']\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=False\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            nf_layers=3,\n",
    "            nf_hidden=70\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(AwesomeImageLossJoint),\n",
    "        loss_args={\n",
    "           \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.0,\n",
    "                \"rgbgrad\" : 0.0,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 0.5,\n",
    "            \"beta\": 0.5,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        extra_penalty_after_n_epochs=800,\n",
    "        use_reduce_lr_in_extra_penalty_hook=True,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Fitting Prior to amirs model without changing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fa4035a0314863912b97afb81ecd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef95cf8d0dee421da45797b230954569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\projects\\AWESOME\\awesome\\dataset\\fbms_sequence_dataset.py:666: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  bg_flip_coords = flip_probability[torch.argwhere(bg_flip_mask).squeeze(), :2].int().T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58561d6e43d4414fbed41936a6fbb49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc73df880bc348b4a15952bf05f2ad8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75e5a8d3505445680f0d950e927f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ea744e37f7443390ea16268b2f1bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f745daca2f46404cbe3aaa93010c82d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6d86fb0f864d1a8898a2024878035d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2e27c8c0cd46aca383216367b1d251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 79! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample cats04:79!\n",
      "WARNING:root:Error in getting weak label in frame 97! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample cats04:97!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0483dfa67947b89efdf807a0d174e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 86! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample cats05:86!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9b962e383f49e1b475311a710f5e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c51d68ef4094eaea17deb75d7f478d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfc31c71a974691a3bbe6707b04e770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e660d77619240538f41e3f965967677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 139! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:139!\n",
      "WARNING:root:Error in getting weak label in frame 159! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:159!\n",
      "WARNING:root:Error in getting weak label in frame 179! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:179!\n",
      "WARNING:root:Error in getting weak label in frame 199! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:199!\n",
      "WARNING:root:Error in getting weak label in frame 219! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:219!\n",
      "WARNING:root:Error in getting weak label in frame 239! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:239!\n",
      "WARNING:root:Error in getting weak label in frame 259! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:259!\n",
      "WARNING:root:Error in getting weak label in frame 415! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample lion02:415!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17be77ab79d546b0aaf18680b9464dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaba6be57674303bf628ce015fda888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 399! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple10:399!\n",
      "WARNING:root:Error in getting weak label in frame 449! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple10:449!\n",
      "WARNING:root:Error in getting weak label in frame 459! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple10:459!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5aee6c4d6a4f4ba59363dba8fa3969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 0! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple11:0!\n",
      "WARNING:root:Error in getting weak label in frame 9! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple11:9!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b262d0de5d447548542003c36a3e494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a59af5538545d48024fac5e50a3e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error in getting weak label in frame 39! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple8:39!\n",
      "WARNING:root:Error in getting weak label in frame 49! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple8:49!\n",
      "WARNING:root:Error in getting weak label in frame 71! Excluding frame! \n",
      " Could not find a foreground weak label object id for sample marple8:71!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce5731cb41b43d0abb4894d2985d441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35739567c794ea283b16860e0237c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721bb9eb7834eec974fd6527d9f6251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+only_prior\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=False\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='none',\n",
    "        segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=1,\n",
    "            nf_layers=4,\n",
    "            nf_hidden=130,\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(AwesomeImageLoss),\n",
    "        loss_args={\n",
    "           \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.0,\n",
    "                \"rgbgrad\" : 0.0,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\"),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 0.5,\n",
    "            \"beta\": 0.5,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        extra_penalty_after_n_epochs=800,\n",
    "        use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "            do_pretraining=True, \n",
    "            pretrain_only=True, # Do Fitting in pretrain mode only\n",
    "            force_pretrain=True, \n",
    "            pretrain_args=dict(\n",
    "                lr=0.003,\n",
    "                use_logger=True,\n",
    "                reuse_state=True,\n",
    "                num_epochs=2000,\n",
    "                reuse_state_epochs=200\n",
    "                )\n",
    "        )\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_only_prior/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Only Prior to amirs model, and retrained + xy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\projects\\AWESOME\\notebooks\\build_configs.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./config/fbms_unet_diffeo_only_prior/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m.yaml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m cfg\u001b[39m.\u001b[39msave_to_file(path, override\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, no_uuid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32md:\\projects\\AWESOME\\notebooks\\build_configs.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./config/fbms_unet_diffeo_only_prior/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mname_experiment\u001b[39m}\u001b[39;00m\u001b[39m.yaml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/projects/AWESOME/notebooks/build_configs.ipynb#X65sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m cfg\u001b[39m.\u001b[39msave_to_file(path, override\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, no_uuid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Schneider\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\awesome-dC4phDSK-py3.9\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Schneider\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\awesome-dC4phDSK-py3.9\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.ae import AE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "\n",
    "xytypes = [(\"edge\", \"original\"), (\"edge\", \"retrain\"), (\"edgexy\", \"retrain_xy\")]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = []\n",
    "for dataset in datasets:\n",
    "    for xytype in xytypes:\n",
    "        it.append((xytype, dataset, 'train'))\n",
    "\n",
    "prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "\n",
    "for vals in it:\n",
    "    xytype, segmentation_model_switch = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = \"train\"\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    test_weak_label_integrity=False\n",
    "                )\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+only_prior{'+REFIT' if segmentation_model_switch != 'original' else ''}\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='none',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path,\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=2,\n",
    "            diffeo_args=dict(\n",
    "                num_coupling=6,\n",
    "                width=130,\n",
    "                backbone=\"normal_block\"\n",
    "            ),\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "           \n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=800,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=200,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/prior_only/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        agent_args=dict(\n",
    "            do_pretraining=True, \n",
    "            pretrain_only=True, # Do Fitting in pretrain mode only\n",
    "            force_pretrain=True, \n",
    "            pretrain_state_path=f\"./data/checkpoints/pretrain_states/23-11-13/model_{dataset}_unet_{xytype}_{segmentation_model_switch}_{prior_criterion.get_name()}.pth\",\n",
    "            pretrain_args=dict(\n",
    "                pretrain_checkpoint_dir=f\"./data/checkpoints/pretrain_states/23-11-13/model_{dataset}_unet_{xytype}_{segmentation_model_switch}_{prior_criterion.get_name()}\",\n",
    "                lr=0.001,\n",
    "                use_logger=True,\n",
    "                use_step_logger=False,\n",
    "                num_epochs=2000,\n",
    "                proper_prior_fit_retrys=1,\n",
    "                criterion=prior_criterion,\n",
    "                do_pretrain_checkpoints=True,\n",
    "                use_pretrain_checkpoints=True,\n",
    "        \n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    path = f\"./config/fbms_unet_diffeo_only_prior/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTune Prior Only Including all Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+only_prior+all_frames+deeper\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='none',\n",
    "        segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=2,\n",
    "            diffeo_args=dict(\n",
    "                num_coupling=6,\n",
    "                width=130,\n",
    "                backbone=\"residual_block\"\n",
    "            ),\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        extra_penalty_after_n_epochs=800,\n",
    "        use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "            do_pretraining=True, \n",
    "            pretrain_only=True, # Do Fitting in pretrain mode only\n",
    "            force_pretrain=True, \n",
    "            pretrain_args=dict(\n",
    "                lr=0.003,\n",
    "                use_logger=True,\n",
    "                reuse_state=True,\n",
    "                num_epochs=2000,\n",
    "                reuse_state_epochs=200\n",
    "                )\n",
    "        )\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_only_prior_all_frames_deeper/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Prior to the models \n",
    "1. Version with realnvp (11.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.zoo import Zoo\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "prior_epochs = 4000\n",
    "prior_refit_epochs = 400\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_modevl_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "    pretrain_state_path = f\"./data/checkpoints/pretrain_states/2024-01-11/model_{dataset}_unet_spatial_realnvp_{prior_epochs}_{prior_refit_epochs}\"\n",
    "\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                )\n",
    "    real_dataset.test_weak_label_integrity = True\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+{segmentation_model_switch}+ep{prior_epochs}+refit{prior_refit_epochs}+realnvp\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            channels=2,\n",
    "            hidden_units=32,\n",
    "            flow_n_flows=12,\n",
    "            flow_output_fn=\"tanh\",\n",
    "            norm=\"minmax\",\n",
    "            convex_net_hidden_units=130,\n",
    "            convex_net_hidden_layers=2,\n",
    "        ),\n",
    "        prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"penalty_criterion\": prior_criterion.criterion,\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=0,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/prior_training\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.003,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        save_images_after_pretraining=True,\n",
    "        include_unaries_when_saving=True,\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True,\n",
    "             pretrain_only=True, \n",
    "             force_pretrain=True,\n",
    "             pretrain_state_path=pretrain_state_path + \".pth\",\n",
    "             pretrain_args=dict(\n",
    "                 use_pretrain_checkpoints=True,\n",
    "                 do_pretrain_checkpoints=True,\n",
    "                 pretrain_checkpoint_dir=pretrain_state_path,\n",
    "                 lr=0.001,\n",
    "                 use_logger=True,\n",
    "                 use_step_logger=True,\n",
    "                 num_epochs=4000,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 reuse_state_epochs=400,\n",
    "                 # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                 prefit_flow_net_identity=True,\n",
    "                 prefit_flow_net_identity_lr=1e-2,\n",
    "                 prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                 prefit_flow_net_identity_num_epochs=100,\n",
    "                 # Prefit convex net, to start with a convex thing\n",
    "                 prefit_convex_net=True,\n",
    "                 prefit_convex_net_lr=1e-3,\n",
    "                 prefit_convex_net_weight_decay=0,\n",
    "                 prefit_convex_net_num_epochs=200,\n",
    "                 zoo=Zoo()\n",
    "             )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    path = f\"./config/fbms_unet_prior_realnvp/2024_01_11/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Version with realnvp (11.01) and longer training for refit images (15.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.zoo import Zoo\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "prior_epochs = 4000\n",
    "prior_refit_epochs = 1000\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_modevl_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "    pretrain_state_path = f\"./data/checkpoints/pretrain_states/2024-01-15/model_{dataset}_unet_spatial_realnvp_{prior_epochs}_{prior_refit_epochs}\"\n",
    "\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                )\n",
    "    real_dataset.test_weak_label_integrity = True\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+{segmentation_model_switch}+ep{prior_epochs}+refit{prior_refit_epochs}+realnvp\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            channels=2,\n",
    "            hidden_units=32,\n",
    "            flow_n_flows=12,\n",
    "            flow_output_fn=\"tanh\",\n",
    "            norm=\"minmax\",\n",
    "            convex_net_hidden_units=130,\n",
    "            convex_net_hidden_layers=2,\n",
    "        ),\n",
    "        prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"penalty_criterion\": prior_criterion.criterion,\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=0,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/prior_training\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.003,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        save_images_after_pretraining=True,\n",
    "        include_unaries_when_saving=True,\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True,\n",
    "             pretrain_only=True, \n",
    "             force_pretrain=True,\n",
    "             pretrain_state_path=pretrain_state_path + \".pth\",\n",
    "             pretrain_args=dict(\n",
    "                 use_pretrain_checkpoints=True,\n",
    "                 do_pretrain_checkpoints=True,\n",
    "                 pretrain_checkpoint_dir=pretrain_state_path,\n",
    "                 lr=0.001,\n",
    "                 use_logger=True,\n",
    "                 use_step_logger=True,\n",
    "                 num_epochs=prior_epochs,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 reuse_state_epochs=prior_refit_epochs,\n",
    "                 # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                 prefit_flow_net_identity=True,\n",
    "                 prefit_flow_net_identity_lr=1e-2,\n",
    "                 prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                 prefit_flow_net_identity_num_epochs=100,\n",
    "                 # Prefit convex net, to start with a convex thing\n",
    "                 prefit_convex_net=True,\n",
    "                 prefit_convex_net_lr=1e-3,\n",
    "                 prefit_convex_net_weight_decay=0,\n",
    "                 prefit_convex_net_num_epochs=200,\n",
    "                 zoo=Zoo()\n",
    "             )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    path = f\"./config/fbms_unet_prior_realnvp/2024_01_15/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jointly Train Unet With prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=1,\n",
    "            nf_layers=4,\n",
    "            nf_hidden=130,\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "            \n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=200,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.003,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True, \n",
    "             pretrain_state_path=f\"./data/checkpoints/pretrain_states/model_{dataset}_joint_unet.pth\",\n",
    "             pretrain_args=dict(\n",
    "                 lr=0.003,\n",
    "                 use_logger=False\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=5e-5,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_joint/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+joint+deeper\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\", # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=2,\n",
    "            diffeo_args=dict(\n",
    "                num_coupling=6,\n",
    "                width=130,\n",
    "                backbone=\"residual_block\"\n",
    "            ),\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "            \n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=200,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.003,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=20,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True, \n",
    "             pretrain_state_path=f\"./data/checkpoints/pretrain_states/model_{dataset}_joint_unet_deeper.pth\",\n",
    "             pretrain_args=dict(\n",
    "                 lr=0.003,\n",
    "                 use_logger=False\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=5e-5,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_joint_deeper/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jointly train with spatial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750f1faa387241ec8b9160d33e8f85a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243050673f1e430c90e7aa00949304f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72004cb012214fb2b5fb3302182d0bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c2f9ce033b43a1ba17eb2e24569754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67d53428afc41f99f60f89a7acfaaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading frames...:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "\n",
    "xytypes = [\"edgexy\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   #'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   #'cars7',\n",
    "   #'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   ##'cats04',\n",
    "   ##'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   ##'horses01',\n",
    "   ##'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   ##'marple1',\n",
    "   ##'marple10',\n",
    "   ##'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   #'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   ##'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   ##'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"retrain_xy\"\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "\n",
    "\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=False,\n",
    "                    all_frames=True,\n",
    "                )\n",
    "\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+joint+deeper+REFIT\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 6,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            n_hidden=130,\n",
    "            n_hidden_layers=2,\n",
    "            diffeo_args=dict(\n",
    "                num_coupling=6,\n",
    "                width=130,\n",
    "                backbone=\"residual_block\"\n",
    "            ),\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.0001,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True, \n",
    "             pretrain_state_path=f\"./data/checkpoints/pretrain_states/model_{dataset}_unet_{xytype}_{segmentation_model_switch}.pth\",\n",
    "             pretrain_args=dict(\n",
    "                 lr=0.003,\n",
    "                 use_logger=True,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 criterion=UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=5e-5,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_quick/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Training of Unet and Prior with CRF (Used Config)\n",
    "Version 11.01.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "from awesome.model.zoo import Zoo\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "prior_epochs = 4000\n",
    "prior_refit_epochs = 400\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    pretrain_state_path = f\"./data/checkpoints/pretrain_states/2024-01-11/model_{dataset}_unet_spatial_realnvp_{prior_epochs}_{prior_refit_epochs}\"\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True,\n",
    "                )\n",
    "\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+{segmentation_model_switch}+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            channels=2,\n",
    "            hidden_units=32,\n",
    "            flow_n_flows=12,\n",
    "            flow_output_fn=\"tanh\",\n",
    "            norm=\"minmax\",\n",
    "            convex_net_hidden_units=130,\n",
    "            convex_net_hidden_layers=2,\n",
    "        ),\n",
    "        prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"penalty_criterion\": prior_criterion.criterion,\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.0001,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "\n",
    "        compute_crf_with_metrics=True,\n",
    "        compute_crf_after_training=True,\n",
    "        compute_crf_after_pretraining=True,\n",
    "        save_images_after_pretraining=True,\n",
    "        include_unaries_when_saving=True,\n",
    "\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True,\n",
    "             pretrain_only=False, \n",
    "             force_pretrain=False,\n",
    "             pretrain_state_path=pretrain_state_path + \".pth\",\n",
    "             pretrain_args=dict(\n",
    "                 use_pretrain_checkpoints=True,\n",
    "                 do_pretrain_checkpoints=True,\n",
    "                 pretrain_checkpoint_dir=pretrain_state_path,\n",
    "                 lr=0.001,\n",
    "                 use_logger=True,\n",
    "                 use_step_logger=True,\n",
    "                 num_epochs=prior_epochs,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 reuse_state_epochs=prior_refit_epochs,\n",
    "                 # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                 prefit_flow_net_identity=True,\n",
    "                 prefit_flow_net_identity_lr=1e-2,\n",
    "                 prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                 prefit_flow_net_identity_num_epochs=100,\n",
    "                 # Prefit convex net, to start with a convex thing\n",
    "                 prefit_convex_net=True,\n",
    "                 prefit_convex_net_lr=1e-3,\n",
    "                 prefit_convex_net_weight_decay=0,\n",
    "                 prefit_convex_net_num_epochs=200,\n",
    "                 zoo=Zoo()\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=0,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_joint/2024_01_11/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Training of Unet and Prior with CRF (Used Config) and Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\projects\\AWESOME\\awesome\\dataset\\fbms_sequence_dataset.py:756: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  bg_flip_coords = flip_probability[torch.argwhere(bg_flip_mask).squeeze(), :2].int().T\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "from awesome.model.zoo import Zoo\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "seeds = [47, 131]\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "prior_epochs = 4000\n",
    "prior_refit_epochs = 400\n",
    "\n",
    "it = itertools.product(seeds, it)\n",
    "\n",
    "for seed, vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    pretrain_state_path = f\"./data/checkpoints/pretrain_states/2024-01-11/model_{dataset}_unet_spatial_realnvp_{prior_epochs}_{prior_refit_epochs}_seed{seed}\"\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True,\n",
    "                )\n",
    "\n",
    "    cfg = AwesomeConfig(\n",
    "        seed=seed,\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+{segmentation_model_switch}+joint+seed{seed}\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            channels=2,\n",
    "            hidden_units=32,\n",
    "            flow_n_flows=12,\n",
    "            flow_output_fn=\"tanh\",\n",
    "            norm=\"minmax\",\n",
    "            convex_net_hidden_units=130,\n",
    "            convex_net_hidden_layers=2,\n",
    "        ),\n",
    "        prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"penalty_criterion\": prior_criterion.criterion,\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.0001,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "\n",
    "        compute_crf_with_metrics=True,\n",
    "        compute_crf_after_training=True,\n",
    "        compute_crf_after_pretraining=True,\n",
    "        save_images_after_pretraining=True,\n",
    "        include_unaries_when_saving=True,\n",
    "\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True,\n",
    "             pretrain_only=False, \n",
    "             force_pretrain=False,\n",
    "             pretrain_state_path=pretrain_state_path + \".pth\",\n",
    "             pretrain_args=dict(\n",
    "                 use_pretrain_checkpoints=True,\n",
    "                 do_pretrain_checkpoints=True,\n",
    "                 pretrain_checkpoint_dir=pretrain_state_path,\n",
    "                 lr=0.001,\n",
    "                 use_logger=True,\n",
    "                 use_step_logger=True,\n",
    "                 num_epochs=prior_epochs,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 reuse_state_epochs=prior_refit_epochs,\n",
    "                 # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                 prefit_flow_net_identity=True,\n",
    "                 prefit_flow_net_identity_lr=1e-2,\n",
    "                 prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                 prefit_flow_net_identity_num_epochs=100,\n",
    "                 # Prefit convex net, to start with a convex thing\n",
    "                 prefit_convex_net=True,\n",
    "                 prefit_convex_net_lr=1e-3,\n",
    "                 prefit_convex_net_weight_decay=0,\n",
    "                 prefit_convex_net_num_epochs=200,\n",
    "                 zoo=Zoo()\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=0,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_joint/2024_01_11/seed/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Version 15.01.2024 realnvp longer fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "from awesome.model.zoo import Zoo\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "prior_epochs = 4000\n",
    "prior_refit_epochs = 1000\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "\n",
    "    segmentation_model_state_dict_path = None\n",
    "    if segmentation_model_switch == \"original\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    elif segmentation_model_switch == \"retrain_xy\":\n",
    "        segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "    image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "    input_channels = 4 if xytype == \"edge\" else 6\n",
    "\n",
    "    prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    pretrain_state_path = f\"./data/checkpoints/pretrain_states/2024-01-15/model_{dataset}_unet_spatial_realnvp_{prior_epochs}_{prior_refit_epochs}\"\n",
    "\n",
    "    real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=False,\n",
    "                    all_frames=True,\n",
    "                )\n",
    "\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+{segmentation_model_switch}+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": real_dataset,\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": image_channel_format,\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': input_channels,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            channels=2,\n",
    "            hidden_units=32,\n",
    "            flow_n_flows=12,\n",
    "            flow_output_fn=\"tanh\",\n",
    "            norm=\"minmax\",\n",
    "            convex_net_hidden_units=130,\n",
    "            convex_net_hidden_layers=2,\n",
    "        ),\n",
    "        prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "        loss_type=class_name(FBMSJointLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "            \"penalty_criterion\": prior_criterion.criterion,\n",
    "            \"alpha\": 1,\n",
    "            \"beta\": 1,\n",
    "        },\n",
    "        use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "        #extra_penalty_after_n_epochs=1,\n",
    "        #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/unet/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.0001,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=False,\n",
    "\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "\n",
    "        compute_crf_with_metrics=True,\n",
    "        compute_crf_after_training=True,\n",
    "        compute_crf_after_pretraining=True,\n",
    "        save_images_after_pretraining=True,\n",
    "        include_unaries_when_saving=True,\n",
    "\n",
    "        plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "        agent_args=dict(\n",
    "             do_pretraining=True,\n",
    "             pretrain_only=False, \n",
    "             force_pretrain=False,\n",
    "             pretrain_state_path=pretrain_state_path + \".pth\",\n",
    "             pretrain_args=dict(\n",
    "                 use_pretrain_checkpoints=True,\n",
    "                 do_pretrain_checkpoints=True,\n",
    "                 pretrain_checkpoint_dir=pretrain_state_path,\n",
    "                 lr=0.001,\n",
    "                 use_logger=True,\n",
    "                 use_step_logger=True,\n",
    "                 num_epochs=prior_epochs,\n",
    "                 proper_prior_fit_retrys=1,\n",
    "                 reuse_state_epochs=prior_refit_epochs,\n",
    "                 # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                 prefit_flow_net_identity=True,\n",
    "                 prefit_flow_net_identity_lr=1e-2,\n",
    "                 prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                 prefit_flow_net_identity_num_epochs=100,\n",
    "                 # Prefit convex net, to start with a convex thing\n",
    "                 prefit_convex_net=True,\n",
    "                 prefit_convex_net_lr=1e-3,\n",
    "                 prefit_convex_net_weight_decay=0,\n",
    "                 prefit_convex_net_num_epochs=200,\n",
    "                 zoo=Zoo()\n",
    "             )\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=0,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_diffeo_joint/2024_01_15/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio Temporal with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\projects\\AWESOME\\awesome\\dataset\\fbms_sequence_dataset.py:755: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  fg_flip_coords = flip_probability[torch.argwhere(fg_flip_mask).squeeze(), :2].int().T\n"
     ]
    }
   ],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.model.noisy_path_connected_net import NoisyPathConnectedNet\n",
    "from awesome.model.zoo import Zoo\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.model.net_factory import real_nvp_path_connected_net\n",
    "import itertools\n",
    "\n",
    "xytype = \"edge\"\n",
    "dataset_kind = \"train\"\n",
    "dataset = \"cars3\"\n",
    "all_frames = True\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "\n",
    "segmentation_model_state_dict_path = None\n",
    "if segmentation_model_switch == \"original\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "elif segmentation_model_switch == \"retrain\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "elif segmentation_model_switch == \"retrain_xy\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "input_channels = 4 if xytype == \"edge\" else 6\n",
    "prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "\n",
    "data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=False,\n",
    "                    all_frames=True,\n",
    "                )\n",
    "data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "batch_size = 2\n",
    "prior_epochs = 1000\n",
    "prior_reuse_state_epochs = 400\n",
    "prefit_flow_grid_epochs = 30\n",
    "prefit_convex_net_epochs = 400\n",
    "noisy_percentages = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "seeds = [42, 47, 131]\n",
    "ops = itertools.product(noisy_percentages, seeds)\n",
    "\n",
    "for noisy_percentage, seed in ops:\n",
    "    cfg = AwesomeConfig(\n",
    "            seed=seed,\n",
    "            name_experiment=f\"UNET+{dataset}+{xytype}+diffeo+only_prior+realnvp+spatio-temporal+noisy+seed{seed}+np{str(noisy_percentage).replace('.', '_')}\",\n",
    "            dataset_type=class_name(AwesomeDataset),\n",
    "            dataset_args={\n",
    "                \"dataset\": real_dataset,\n",
    "                \"xytype\": xytype,\n",
    "                \"feature_dir\": f\"{data_path}/Feat\",\n",
    "                \"dimension\": \"3d\", # 2d for fcnet\n",
    "                \"mode\": \"model_input\",\n",
    "                \"model_input_requires_grad\": False,\n",
    "                \"batch_size\": 1,\n",
    "                \"split_ratio\": 1,\n",
    "                \"shuffle_in_dataloader\": False,\n",
    "                \"image_channel_format\": image_channel_format,\n",
    "                \"do_image_blurring\": True,\n",
    "                \"spatio_temporal\": True\n",
    "            },\n",
    "            segmentation_model_type=class_name(UNet),\n",
    "            segmentation_model_args={\n",
    "                'in_chn': input_channels,\n",
    "            },\n",
    "            segmentation_training_mode='multi',\n",
    "            segmentation_model_state_dict_path=segmentation_model_state_dict_path, # Path to the pretrained model\n",
    "            use_segmentation_output_inversion=True,\n",
    "            use_prior_model=True,\n",
    "            prior_model_args=dict(\n",
    "                channels=3,\n",
    "                hidden_units=32,\n",
    "                flow_n_flows=12,\n",
    "                flow_output_fn=\"tanh\",\n",
    "                norm=\"minmax\",\n",
    "                convex_net_hidden_units=130,\n",
    "                convex_net_hidden_layers=2,\n",
    "                network_type=NoisyPathConnectedNet,\n",
    "                \n",
    "            ),\n",
    "            prior_model_type=class_name(real_nvp_path_connected_net),\n",
    "            loss_type=class_name(FBMSJointLoss),\n",
    "            loss_args={\n",
    "                \"criterion\": WeightedLoss(torch.nn.BCELoss(), mode=\"sssdms\", noneclass=2),\n",
    "                \"alpha\": 1,\n",
    "                \"beta\": 1,\n",
    "            },\n",
    "            use_extra_penalty_hook=False, # Panalty hook for the panalty term that models output should match\n",
    "            #extra_penalty_after_n_epochs=1,\n",
    "            #use_reduce_lr_in_extra_penalty_hook=False,\n",
    "            use_lr_on_plateau_scheduler=False,\n",
    "            use_binary_classification=True, \n",
    "            num_epochs=100,\n",
    "            device=\"cuda\",\n",
    "            dtype=str(torch.float32),\n",
    "            runs_path=\"./runs/fbms_local/unet/noisy_spatio_temporal\",\n",
    "            optimizer_args={\n",
    "                \"lr\": 0.003,\n",
    "                \"betas\": (0.9, 0.999),\n",
    "                \"eps\": 1e-08,\n",
    "                \"amsgrad\": False\n",
    "            },\n",
    "            use_progress_bar=True,\n",
    "            plot_indices_during_training_nth_epoch=5,\n",
    "            plot_indices_during_training=real_dataset.get_ground_truth_indices(),\n",
    "            save_images_after_pretraining=True,\n",
    "            include_unaries_when_saving=True,\n",
    "            agent_args=dict(\n",
    "                do_pretraining=True,\n",
    "                pretrain_only=True, \n",
    "                force_pretrain=True,\n",
    "                pretrain_args=dict(\n",
    "                    use_pretrain_checkpoints=False,\n",
    "                    do_pretrain_checkpoints=False,\n",
    "                    lr=0.001,\n",
    "                    use_logger=True,\n",
    "                    use_step_logger=True,\n",
    "                    num_epochs=prior_epochs,\n",
    "                    proper_prior_fit_retrys=1,\n",
    "                    reuse_state_epochs=prior_reuse_state_epochs,\n",
    "                    # Prefit flow net identity => Flow will be identity(-like) at the beginning\n",
    "                    prefit_flow_net_identity=True,\n",
    "                    prefit_flow_net_identity_lr=1e-2,\n",
    "                    prefit_flow_net_identity_weight_decay=1e-5,\n",
    "                    prefit_flow_net_identity_num_epochs=prefit_flow_grid_epochs,\n",
    "                    # Prefit convex net, to start with a convex thing\n",
    "                    prefit_convex_net=True,\n",
    "                    prefit_convex_net_lr=1e-3,\n",
    "                    prefit_convex_net_weight_decay=0,\n",
    "                    prefit_convex_net_num_epochs=prefit_convex_net_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    noisy_percentage=noisy_percentage,\n",
    "                    zoo=Zoo()\n",
    "                )\n",
    "            ),\n",
    "            #output_folder=\"./runs/fbms_local/unet/TestUnet/\",\n",
    "        )\n",
    "    cfg.save_to_file(f\"./config/fbms_noisy_spatio_temporal/{cfg.name_experiment}.yaml\", \n",
    "                    override=True, \n",
    "                    make_dirs=True,\n",
    "                    no_uuid=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refitting amirs models with my code to test if they are approximately the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "\n",
    "xytypes = [\"edge\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+REFIT\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": True,\n",
    "            \"image_channel_format\": \"rgb\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 4,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=False,\n",
    "        loss_type=class_name(WeightedLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"mode\": \"sssdms\",\n",
    "            \"noneclass\": 2,\n",
    "        },\n",
    "        use_step_lr_scheduler=True,\n",
    "        step_lr_scheduler_args={\n",
    "            \"gamma\": 0.1,\n",
    "            \"step_size\": 5,\n",
    "        },\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/refit/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "             do_pretraining=False,\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=0,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_refit/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refitting with Additional spacial Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "\n",
    "xytypes = [\"edgexy\"]\n",
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   #'cars9', # Multi output Model\n",
    "   #'cats02', # Multi output Model\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   #'cats07',  # Multi output Model\n",
    "   #'ducks01', # Multi output Model\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   #'horses06', # Multi output Model\n",
    "   #'lion02',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   #'marple13', # Multi output Model\n",
    "   #'marple3', # Multi output Model\n",
    "   'marple5',\n",
    "   #'marple8', # Multi output Model\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   #'people05', # Multi output Model\n",
    "   'rabbits01',\n",
    "   #'rabbits05' # Multi output Model\n",
    "   ]\n",
    "\n",
    "\n",
    "it = zip(xytypes * len(datasets), datasets, ['train'] * len(datasets))\n",
    "\n",
    "for vals in it:\n",
    "    xytype = vals[0]\n",
    "    dataset = vals[1]\n",
    "    dataset_kind = vals[2]\n",
    "\n",
    "    \n",
    "    data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "    cfg = AwesomeConfig(\n",
    "        name_experiment=f\"UNET+{dataset}+{xytype}+REFIT\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    all_frames=True,\n",
    "                    _no_indexing=True\n",
    "                ),\n",
    "            \"xytype\": xytype,\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": True,\n",
    "            \"image_channel_format\": \"rgb\",\n",
    "            \"do_image_blurring\": True\n",
    "        },\n",
    "        segmentation_model_type=class_name(UNet),\n",
    "        segmentation_model_args={\n",
    "            'in_chn': 6,\n",
    "        },\n",
    "        segmentation_training_mode='multi',\n",
    "        use_segmentation_output_inversion=True,\n",
    "        use_prior_model=False,\n",
    "        loss_type=class_name(WeightedLoss),\n",
    "        loss_args={\n",
    "            \"criterion\": torch.nn.BCELoss(),\n",
    "            \"mode\": \"sssdms\",\n",
    "            \"noneclass\": 2,\n",
    "        },\n",
    "        use_step_lr_scheduler=True,\n",
    "        step_lr_scheduler_args={\n",
    "            \"gamma\": 0.1,\n",
    "            \"step_size\": 5,\n",
    "        },\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=15,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local/refit/\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.01,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=5,\n",
    "        compute_metrics_during_training_nth_epoch=5,\n",
    "        plot_indices_during_training=[0, 1, 2, 3],\n",
    "        agent_args=dict(\n",
    "             do_pretraining=False,\n",
    "        ),\n",
    "        weight_decay_on_weight_norm_modules=0,\n",
    "    )\n",
    "    path = f\"./config/fbms_unet_refit_spatial/{cfg.name_experiment}.yaml\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cfg.save_to_file(path, override=True, no_uuid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util: Run all configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.multi_config_config import MultiConfigConfig\n",
    "\n",
    "cfg = MultiConfigConfig(\n",
    "    runner_type=class_name(AwesomeRunner),\n",
    "    create_job_file=True,\n",
    "    mode=\"scan_dir\",\n",
    "    scan_config_directory=\"./config/benchmarks\",\n",
    "    runs_path=\"./runs\",\n",
    "    runner_script_path=\"./scripts/run.py\",\n",
    "    config_directory=\"./scripts/slurm/config/\",\n",
    "    job_file_path=\"./scripts/slurm/job_files/\",\n",
    "    name_experiment=\"Run_Benchmark_Configs\",\n",
    ")\n",
    "os.makedirs(cfg.runs_path, exist_ok=True)\n",
    "os.makedirs(cfg.job_file_path, exist_ok=True)\n",
    "os.makedirs(cfg.config_directory, exist_ok=True)\n",
    "\n",
    "cfg.save_to_file(f\"./config/multi_config/{cfg.name_experiment}.yaml\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNet\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "\n",
    "xytype = \"xy\"\n",
    "\n",
    "dataset = \"marple2\"\n",
    "\n",
    "cfg = AwesomeConfig(\n",
    "        name_experiment=f\"CNNET_+{dataset}+{xytype}+diffeo+joint\",\n",
    "        dataset_type=class_name(AwesomeDataset),\n",
    "        dataset_args={\n",
    "            \"dataset\": FBMSSequenceDataset(\n",
    "                    dataset_path=f\"./data/local_datasets/FBMS-59/test/{dataset}\"\n",
    "                ),\n",
    "            \"xytransform\": \"xy\",\n",
    "            \"xytype\": xytype,\n",
    "            \"mode\": \"scribbles\",\n",
    "            \"feature_dir\": f\"./data/local_datasets/FBMS-59/test/{dataset}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": True, # Can be used for 3d nets\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"subset\": 1\n",
    "        },\n",
    "        segmentation_model_type=class_name(CNNNet),\n",
    "        segmentation_model_args={\n",
    "            'width': 16,\n",
    "            'depth': 2,\n",
    "            'kernel_size': 3,\n",
    "            'input': 'rgbxy',\n",
    "        },\n",
    "        segmentation_training_mode='single',\n",
    "        use_prior_model=True,\n",
    "        prior_model_args=dict(\n",
    "            nf_layers=3,\n",
    "            nf_hidden=70\n",
    "        ),\n",
    "        prior_model_type=class_name(ConvexDiffeomorphismNet),\n",
    "        loss_type=class_name(AwesomeImageLossJoint),\n",
    "        loss_args={\n",
    "            \"criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": True,\n",
    "                \"noneclass\" : 2.,\n",
    "                \"xygrad\" : 0.001,\n",
    "                \"rgbgrad\" : 0.001,\n",
    "                \"featgrad\" : 0.0,\n",
    "                \"xytype\" : xytype,}),\n",
    "            \"prior_criterion\": GradientPenaltyLoss(**{\n",
    "                \"criterion\": torch.nn.BCELoss(),\n",
    "                \"apply_gradient_penalty\": False,\n",
    "                \"noneclass\" : 2.,}),\n",
    "            \"gamma\": 0.5,\n",
    "            \"beta\": 0.5,\n",
    "            },\n",
    "        use_extra_penalty_hook=True, # Panalty hook for the panalty term that models output should match\n",
    "        extra_penalty_after_n_epochs=800,\n",
    "        use_reduce_lr_in_extra_penalty_hook=False,\n",
    "        use_lr_on_plateau_scheduler=False,\n",
    "        use_binary_classification=True, \n",
    "        num_epochs=4000,\n",
    "        device=\"cuda\",\n",
    "        dtype=str(torch.float32),\n",
    "        runs_path=\"./runs/fbms_local\",\n",
    "        optimizer_args={\n",
    "            \"lr\": 0.02,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-08,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        use_progress_bar=True,\n",
    "        semantic_soft_segmentation_code_dir=\"../siggraph/\",\n",
    "        semantic_soft_segmentation_model_checkpoint_dir=\"./data/sss_checkpoint/model\",\n",
    "        plot_indices_during_training_nth_epoch=50,\n",
    "        plot_indices_during_training=[0],\n",
    "        tf_use_gpu=True,\n",
    "    )\n",
    "#cfg.save_to_file(\"./config/Test_FBMS_CNNET.yaml\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [ \"gpu-node\" + \"{:03d}\".format(x) for x in range(1, 11)]\n",
    "user = \"js267086\"\n",
    "address = \"omni.zimt.uni-siegen.de\"\n",
    "\n",
    "for node in nodes:\n",
    "    cfg = f\"\"\"\n",
    "Host {node}\n",
    "    User {user}\n",
    "    ProxyCommand ssh -t -W %h:%p -q {user}@{address}\n",
    "\"\"\"\n",
    "    print(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome-dC4phDSK-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

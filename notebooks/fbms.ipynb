{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "import os\n",
    "import torch\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(get_project_root_path()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.measures.miou import MIOU\n",
    "\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset, FBMSSequenceSample\n",
    "\n",
    "dataset_name = \"marple10\"\n",
    "\n",
    "data_path = f\"./data/local_datasets/FBMS-59/train/{dataset_name}/\"\n",
    "dataset = FBMSSequenceDataset(\n",
    "    data_path, \n",
    "    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\", # Be sure that when this contains files, they corresond to the processing settings\n",
    "    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "    do_weak_label_preprocessing=True,\n",
    "    do_uncertainty_label_flip=True,\n",
    "    test_weak_label_integrity=True,\n",
    "    all_frames=True)\n",
    "dataset.get_ground_truth_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import plot_as_image, prepare_input_eval\n",
    "data_path = f\"./data/local_datasets/FBMS-59/train/{dataset_name}\"\n",
    "awds = AwesomeDataset(**{\n",
    "            \"dataset\": dataset,\n",
    "            \"xytype\": \"edge\",\n",
    "            \"feature_dir\": f\"{data_path}/Feat\",\n",
    "            \"dimension\": \"3d\", # 2d for fcnet\n",
    "            \"mode\": \"model_input\",\n",
    "            \"model_input_requires_grad\": False,\n",
    "            \"batch_size\": 1,\n",
    "            \"split_ratio\": 1,\n",
    "            \"shuffle_in_dataloader\": False,\n",
    "            \"image_channel_format\": \"bgr\",\n",
    "            \"do_image_blurring\": True\n",
    "        })\n",
    "image, ground_truth, _input, targets, fg, bg, prior_state = prepare_input_eval(awds, None, 349)\n",
    "display(plot_as_image(ground_truth))\n",
    "display(plot_as_image(torch.where(targets == 0, 1, 0), size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name: str, with_check: bool = True):\n",
    "    dataset_name = name\n",
    "    data_path = f\"./data/local_datasets/FBMS-59/train/{dataset_name}/\"\n",
    "    dataset = FBMSSequenceDataset(\n",
    "        data_path, \n",
    "        weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "        processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\", # Be sure that when this contains files, they corresond to the processing settings\n",
    "        confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "        do_weak_label_preprocessing=True,\n",
    "        do_uncertainty_label_flip=True,\n",
    "        test_weak_label_integrity=with_check,\n",
    "        all_frames=True)\n",
    "    \n",
    "    return dataset\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "   'bear01',\n",
    "   'bear02',\n",
    "   'cars2',\n",
    "   'cars3',\n",
    "   'cars6',\n",
    "   'cars7',\n",
    "   'cars8',\n",
    "   'cats04',\n",
    "   'cats05',\n",
    "   'horses01',\n",
    "   'horses03',\n",
    "   'marple1',\n",
    "   'marple10',\n",
    "   'marple11',\n",
    "   'marple5',\n",
    "   'meerkats01',\n",
    "   'people04',\n",
    "   'rabbits01',\n",
    "   ]\n",
    "path = \"output/dataset_check/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    dataset = get_dataset(dataset_name)\n",
    "    p = os.path.join(path, dataset_name + \"_after\" + \".png\")\n",
    "    fig = dataset.plot_ground_truth_mask_images(save=True, path=p, override=True)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = get_dataset(\"marple10\")\n",
    "fig = dataset.plot_ground_truth_mask_images()\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from awesome.run.functions import get_mpl_figure, plot_mask\n",
    "from awesome.run.functions import value_mask_to_channel_masks\n",
    "#sample = dataset[149]\n",
    "\n",
    "#sample.trajectory_mask.shape\n",
    "\n",
    "def add_label_info(_id, sample, mode: Literal[\"weak\", \"gt\"]) -> str:\n",
    "    if isinstance(_id, torch.Tensor):\n",
    "        _id = _id.item()\n",
    "    if mode == \"weak\":\n",
    "        if _id == sample.foreground_weak_label_object_id:\n",
    "            return str(_id) + \" FG\"\n",
    "        elif _id == sample.background_weak_label_object_id:\n",
    "            return str(_id) + \" BG\"\n",
    "        else:\n",
    "            return str(_id)\n",
    "    elif mode == \"gt\":\n",
    "        gt_fg = sample.weak_label_id_ground_truth_object_id_mapping.get(sample.foreground_weak_label_object_id, None)\n",
    "        gt_bg = sample.weak_label_id_ground_truth_object_id_mapping.get(sample.background_weak_label_object_id, None)\n",
    "        \n",
    "        if _id == gt_fg:\n",
    "            return str(_id) + \" FG\"\n",
    "        elif _id == gt_bg:\n",
    "            return str(_id) + \" BG\"\n",
    "        else:\n",
    "            return str(_id)\n",
    "\n",
    "indices = dataset.get_ground_truth_indices()\n",
    "\n",
    "rows = len(indices)\n",
    "fig, axs = get_mpl_figure(rows=rows, cols=3, size=5, tight=False, ratio_or_img=dataset[0].image, ax_mode=\"2d\")\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "\n",
    "    sample = dataset[index]\n",
    "\n",
    "    row_axs = axs[i]\n",
    "    fig = plot_mask(sample.image, sample.trajectory_mask, ax=row_axs[0], labels=[add_label_info(x, sample, \"weak\") for x in sample.trajectory_mask_object_ids])\n",
    "    row_axs[0].set_title(\"Weak Label: \" + str(index))\n",
    "\n",
    "    try:\n",
    "        fig = plot_mask(sample.image, sample.ground_truth_mask, ax=row_axs[1], labels=[add_label_info(x, sample, \"gt\") for x in sample.ground_truth_object_ids])\n",
    "        row_axs[1].set_title(\"GT: \" + str(index))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        fig = plot_mask(sample.image, 1 - sample.label, ax=row_axs[2])\n",
    "        row_axs[2].set_title(\"GT Selected: \" + str(index))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "# try:\n",
    "#     fig = plot_mask(sample.image, value_mask_to_channel_masks(sample.weak_label, ignore_value=2)[0], size=15)\n",
    "#     display(fig)\n",
    "#     plt.close(fig)\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     pass\n",
    "\n",
    "\n",
    "display(sample.foreground_weak_label_object_id)\n",
    "display(sample.background_weak_label_object_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.trajectory_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.trajectory_mask_object_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.weak_label_id_ground_truth_object_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(sample.weak_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample.trajectory_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(sample.weak_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(sample.trajectory_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(sample.image, sample.trajectory_mask, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.trajectory_mask_object_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import value_mask_to_channel_masks\n",
    "\n",
    "value_mask_to_channel_masks(sample.weak_label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[97]\n",
    "sample.weak_label_id_ground_truth_object_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(160, 170):\n",
    "    sample = dataset[i]\n",
    "    path = f\"temp/{sample['feat_name']}_{i}.png\"\n",
    "    sample.plot_weak_labels(size=10, path=path, save=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.measures.miou import MIOU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    index = i\n",
    "    sample = dataset[index]\n",
    "    display(sample.plot())\n",
    "    display(sample.plot_weak_labels())\n",
    "    display(sample.plot_selected_weak_labels())\n",
    "    display(sample.plot_selected())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample.plot_weak_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "for i in range(10):\n",
    "    masks.append(sample.weak_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.stack(masks, dim=0)\n",
    "\n",
    "m[m == 2] = 0\n",
    "\n",
    "m = m.sum(dim=0)\n",
    "\n",
    "from awesome.run.functions import plot_as_image\n",
    "\n",
    "plot_as_image(m, size=10, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = dataset[index]\n",
    "\n",
    "\n",
    "sample.blur_image = True\n",
    "display(sample.plot_selected())\n",
    "display(sample.plot_selected_weak_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_path = \"../Self-supervised-Sparse-to-Dense-Motion-Segmentation/FBMS59-train-masks-with-confidence-flownet2-based/temp/test_pth/10_cars2.pth\"\n",
    "\n",
    "_cmp = torch.load(compare_path)\n",
    "compare_input, compare_mask, compare_confidence, compare_image_path = _cmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "\n",
    "awesome_dataset = AwesomeDataset(\n",
    "    dataset, \n",
    "    xytype=\"edge\",\n",
    "    feature_dir = os.path.join(data_path, \"Feat\"), \n",
    "    edge_dir = os.path.join(data_path, \"edge\"),\n",
    "    dimension = \"3d\",\n",
    "    model_input_requires_grad=False,\n",
    "    batch_size = 1,\n",
    "    split_ratio = 1,\n",
    "    shuffle_in_dataloader = False,\n",
    "    image_channel_format = \"bgr\",\n",
    "    do_image_blurring = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = awesome_dataset[1]\n",
    "(img, feature_encoding, xy_clean, args), target = ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_bgr, compare_edgemap = compare_input[:3, ...], compare_input[3, ...]\n",
    "\n",
    "# Get the target mask in our format\n",
    "cmp_m = compare_mask + 3\n",
    "cmp_m[compare_mask == 1] = 0\n",
    "cmp_m[compare_mask == 0] = 1\n",
    "\n",
    "def amir_to_our_mask_format(compare_mask: torch.Tensor) -> torch.Tensor:\n",
    "    cmp_m = compare_mask + 3\n",
    "    cmp_m[compare_mask == 1] = 0\n",
    "    cmp_m[compare_mask == 0] = 1\n",
    "    return cmp_m\n",
    "\n",
    "print(\"Image equal: \", torch.allclose(img, torch.tensor(compare_bgr)))\n",
    "print(\"Edgemap equal: \", torch.allclose(feature_encoding, torch.tensor(compare_edgemap)))\n",
    "print(\"Target equal: \", torch.allclose(target, torch.tensor(cmp_m,dtype=torch.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_m = compare_mask + 3\n",
    "cmp_m[compare_mask == 1] = 0\n",
    "cmp_m[compare_mask == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.abs(img.numpy() - compare_bgr).sum()\n",
    "np.abs(target.numpy() - compare_mask).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import plot_as_image\n",
    "\n",
    "display(plot_as_image(img - compare_bgr, title=\"img - compare_bgr\", open=True, colorbar=True))\n",
    "display(plot_as_image(target - cmp_m, title=\"target - cmp_m\", size=10, open=True, colorbar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import plot_as_image\n",
    "\n",
    "display(plot_as_image(img))\n",
    "display(plot_as_image(feature_encoding, title=\"feature_encoding\"))\n",
    "display(plot_as_image(target, title=\"target\", open=Tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.weak_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "sample = dataset[index]\n",
    "\n",
    "\n",
    "u_id = dataset.unique_weak_label_object_ids\n",
    "\n",
    "sample.plot_weak_labels(all_object_ids=u_id, cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.ground_truth_object_id_weak_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #assert False, \"Save the images\"\n",
    "# from tqdm.autonotebook import tqdm\n",
    "\n",
    "# name = os.path.basename(dataset.dataset_path)\n",
    "# max_len = 5 * 24 #len(dataset)\n",
    "# paths = []\n",
    "# for index in tqdm(range(min(len(dataset), max_len))):\n",
    "#     sample = dataset[index]\n",
    "#     path = f\"output/gif/Traj_{name}_{index:03d}_.png\"\n",
    "#     paths.append(path)\n",
    "#     fig = sample.plot_weak_labels(all_object_ids=u_id, size=5, save=True, path=path, override=True, cmap=\"tab10\")\n",
    "#     plt.close(fig)\n",
    "\n",
    "# from awesome.util.gif_writer_images import GifWriterImages\n",
    "\n",
    "\n",
    "# writer = GifWriterImages(f\"{name}_traj.gif\", paths, \"output/gif\")\n",
    "# writer(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving multicut tracks in data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Stop here\"\n",
    "# Code for extracting the trajectories into the dataset folder\n",
    "tracks_path = \"data/local_datasets/FBMS-59/tracks\"\n",
    "dataset_dirs = \"data/local_datasets/FBMS-59/test/\"\n",
    "\n",
    "import shutil\n",
    "\n",
    "for folder in os.listdir(tracks_path):\n",
    "    inner_path = \"MulticutResults/pfldof0.5000004\"\n",
    "    complete_track_path = os.path.join(tracks_path, folder, inner_path)\n",
    "    tracks_file = list(os.listdir(complete_track_path))[0]\n",
    "    tracks_file_path = os.path.join(complete_track_path, tracks_file)\n",
    "\n",
    "    target_path = os.path.join(dataset_dirs, folder, \"tracks\", \"multicut\")\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    target_file_path = os.path.join(target_path, tracks_file)\n",
    "    shutil.copy(tracks_file_path, target_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving hdf5 files\n",
    "\n",
    "Moves the content of hdf5 files into the directory of the corresponding sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert False, \"Stop here\"\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import h5py\n",
    "from awesome.run.functions import save_mask\n",
    "# Code for extracting the trajectories into the dataset folder\n",
    "tracks_path = \"data/local_datasets/FBMS-59/labels_with_uncertainty_flownet2_based\"\n",
    "dataset_dirs = \"data/local_datasets/FBMS-59/train/\"\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "algo_name = \"labels_with_uncertainty_flownet2_based_new\"\n",
    "\n",
    "it = tqdm(os.listdir(tracks_path), desc=\"Processing folders\")\n",
    "\n",
    "\n",
    "for folder in it:\n",
    "    it.set_description(f\"Processing {folder}\")\n",
    "    complete_track_path = os.path.join(tracks_path, folder)\n",
    "    h5_files = list(os.listdir(complete_track_path))\n",
    "\n",
    "    target_path = os.path.join(dataset_dirs, folder, \"weak_labels\", algo_name)\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    confidence = None\n",
    "\n",
    "    h5it = tqdm(h5_files, desc=\"Processing h5 files\")\n",
    "    for h5_file in h5it:\n",
    "        if '.h5' not in h5_file:\n",
    "            continue\n",
    "        path = os.path.join(complete_track_path, h5_file)\n",
    "        name = h5_file.split(\".\")[0]\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            # 0 = background, 1 = foreground, -1 = no label\n",
    "            weak_label = np.asarray(f[\"img\"]).T\n",
    "            confidence = np.asarray(f[\"confidence\"]).T\n",
    "        \n",
    "        mask = np.zeros_like(weak_label, dtype=np.uint8)\n",
    "\n",
    "        # Reset labels indices\n",
    "        vals = np.unique(weak_label)\n",
    "        if len(vals) == 3:\n",
    "            # Single object case\n",
    "            if (0 in vals) and (1 in vals):\n",
    "\n",
    "                mask[weak_label == 0] = 255\n",
    "                mask[weak_label == 1] = 1\n",
    "            else:\n",
    "                mask[...] = weak_label[...] + 1\n",
    "\n",
    "        else:\n",
    "            mask[...] = weak_label[...] + 1\n",
    "\n",
    "        save_mask(mask, os.path.join(target_path, f\"{name}.png\"))\n",
    "        \n",
    "        with h5py.File(os.path.join(target_path, f\"{name}_confidence.h5\"), \"w\") as f:\n",
    "            f['confidence'] = confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack model checkpoints and just extract the state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"data/modelsUncertFbms/FBMS59-train-masks-with-confidence-flownet2-based/with-voting/checkpoint\"\n",
    "checkpoint_target_dir = \"data/checkpoints/labels_with_uncertainty_flownet2_based\"\n",
    "\n",
    "if not os.path.exists(checkpoint_target_dir):\n",
    "    os.makedirs(checkpoint_target_dir)\n",
    "\n",
    "for file in os.listdir(checkpoint_dir):\n",
    "    if \".pth\" not in file:\n",
    "        continue\n",
    "    name = file.split(\".\")[0] + \"_unet\"\n",
    "    state_dict = torch.load(os.path.join(checkpoint_dir, file), map_location=torch.device('cpu')).get('state_dict')\n",
    "    if state_dict is None:\n",
    "        print(f\"Could not load {file}\")\n",
    "        continue\n",
    "    torch.save(state_dict, os.path.join(checkpoint_target_dir, name + \".pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "checkpoint_dir = \"data/modelsUncertFbms/FBMS59-train-masks-with-confidence-flownet2-based/with-voting/checkpoint\"\n",
    "checkpoint_target_dir = \"data/checkpoints/labels_with_uncertainty_flownet2_based\"\n",
    "\n",
    "if not os.path.exists(checkpoint_target_dir):\n",
    "    os.makedirs(checkpoint_target_dir)\n",
    "\n",
    "for file in os.listdir(checkpoint_dir):\n",
    "    if \".pth\" not in file:\n",
    "        continue\n",
    "    name = file.split(\".\")[0] + \"_unet\"\n",
    "    state_dict = torch.load(os.path.join(checkpoint_dir, file), map_location=torch.device('cpu')).get('state_dict')\n",
    "    if state_dict is None:\n",
    "        print(f\"Could not load {file}\")\n",
    "        continue\n",
    "    torch.save(state_dict, os.path.join(checkpoint_target_dir, name + \".pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome-dC4phDSK-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

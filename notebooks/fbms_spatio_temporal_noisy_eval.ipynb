{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from awesome.run.awesome_config import AwesomeConfig\n",
    "from awesome.run.awesome_runner import AwesomeRunner\n",
    "from awesome.util.reflection import class_name\n",
    "import os\n",
    "import torch\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.dataset.convexity_segmentation_dataset import ConvexitySegmentationDataset\n",
    "from awesome.measures.awesome_loss import AwesomeLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.convex_diffeomorphism_net import ConvexDiffeomorphismNet\n",
    "from awesome.model.net import Net\n",
    "import awesome\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "from awesome.util.logging import basic_config\n",
    "import matplotlib.pyplot as plt\n",
    "from awesome.analytics.result_model import ResultModel\n",
    "from awesome.analytics.noisy_unaries_result_model import NoisyUnariesResultModel\n",
    "from awesome.run.functions import get_result, split_model_result, plot_image_scribbles, plot_mask_labels\n",
    "from awesome.util.temporary_property import TemporaryProperty\n",
    "from awesome.run.functions import get_result, split_model_result,register_alpha_map, plot_image_scribbles, plot_mask_labels, plot_mask\n",
    "import numpy as np\n",
    "from matplotlib.colors import to_hex, to_rgb\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from awesome.run.functions import get_mpl_figure\n",
    "from typing import Literal\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.dataset.sisbosi_dataset import SISBOSIDataset, ConvexityDataset as SISBOSIConvexityDataset\n",
    "from awesome.measures.awesome_image_loss_joint import AwesomeImageLossJoint\n",
    "from awesome.measures.awesome_image_loss import AwesomeImageLoss\n",
    "from awesome.measures.gradient_penalty_loss import GradientPenaltyLoss\n",
    "from awesome.measures.fbms_joint_loss import FBMSJointLoss\n",
    "from awesome.measures.regularizer_loss import RegularizerLoss\n",
    "from awesome.model.cnn_net import CNNNet\n",
    "from awesome.measures.tv import TV\n",
    "from awesome.model.convex_net import ConvexNet\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.measures.weighted_loss import WeightedLoss\n",
    "from awesome.measures.se import SE\n",
    "from awesome.measures.ae import AE\n",
    "from awesome.measures.unaries_conversion_loss import UnariesConversionLoss\n",
    "from awesome.model.wrapper_module import WrapperModule\n",
    "#load_ext matplotlib\n",
    "#matplotlib tk\n",
    "import normflows as nf\n",
    "basic_config()\n",
    "\n",
    "os.chdir(get_project_root_path()) # Beeing in the root directory of the project is important for the relative paths to work consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.analytics.result_comparison import ResultComparison\n",
    "\n",
    "paths = [\n",
    "          \"./runs/fbms_local/eval/unet/noisy_spatio_temporal\"\n",
    "         ]\n",
    "models = []\n",
    "\n",
    "for path in paths:\n",
    "    for folder in os.listdir(path):\n",
    "        if folder.startswith(\"old\") or folder.startswith(\"log\"):\n",
    "            continue\n",
    "        model = NoisyUnariesResultModel.from_path(os.path.join(path, folder))\n",
    "        models.append(model)\n",
    "\n",
    "import re\n",
    "p = r\"#?(?P<cfg_num>\\d+)?_?(?P<net>[A-z0-9]+)_?(?P<feat>[\\w\\+\\-]*)\\_(?P<date>\\d{2}_\\d{2}_\\d{2})\\_(?P<time>\\d{2}_\\d{2}_\\d{2})\"\n",
    "pattern = re.compile(p)\n",
    "\n",
    "for model in models:\n",
    "    match = pattern.fullmatch(model.name)\n",
    "    model_name = None\n",
    "    feat = []\n",
    "    if match:\n",
    "        model_name = match.group('net').strip(\"_\")\n",
    "        features = match.group('feat')\n",
    "        if features is not None and features != \"\":\n",
    "            feat = features.strip(\"+\").split(\"+\")\n",
    "            if not any([\"seed\" in x for x in feat]):\n",
    "                feat.append(\"seed42\")\n",
    "    else:\n",
    "        print('No match for', model.name)\n",
    "    model_name = model_name.replace(\"NET\", \"Net\")\n",
    "    model.display_name = model_name + \" \" + \" \".join(feat)\n",
    "    model.features = list(feat)\n",
    "    model.config.result_directory = \"final_mask\"\n",
    "    model.save_config()\n",
    "\n",
    "\n",
    "# Resort the models by name to get a meaningful table order\n",
    "\n",
    "_order = []\n",
    "\n",
    "models = sorted(models, key=lambda m: _order.index(m.name) if m.name in _order else 0)\n",
    "\n",
    "comparison = ResultComparison(models)\n",
    "comparison.assign_numbers(force=True)\n",
    "\n",
    "os.environ['PLOT_OUTPUT_DIR'] = comparison.output_folder\n",
    "\n",
    "save_args = dict(transparent=False, save=True, dpi=300, ext=[\"png\", \"pdf\"])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple\n",
    "import pandas as pd\n",
    "metrics = [\n",
    "    \"eval/epoch/MeanForegroundBinaryMIOU\" ,\n",
    "    \"eval/epoch/MeanPriorForegroundBinaryMIOU\",\n",
    "    \"eval/epoch/MeanPixelAccuracy\",\n",
    "    \"eval/epoch/MeanPriorPixelAccuracy\",\n",
    "]\n",
    "\n",
    "col_mapping = {\n",
    "    \"eval/epoch/MeanForegroundBinaryMIOU\": \"IoU\",\n",
    "    \"eval/epoch/MeanPixelAccuracy\": \"Acc.\",\n",
    "    \"eval/epoch/MeanPriorPixelAccuracy\" : \"Prior Acc.\",\n",
    "    \"eval/epoch/MeanPriorForegroundBinaryMIOU\": \"Prior IoU\" \n",
    "}\n",
    "\n",
    "index_mapping = {\n",
    "    0: \"Baseline\"\n",
    "}\n",
    "\n",
    "new_colmapping = {}\n",
    "for k, v in dict(col_mapping).items():\n",
    "    for k_i, v_i in dict(index_mapping).items():\n",
    "        new_colmapping[k + \"_\" + str(k_i)] = v + \" \" + v_i\n",
    "\n",
    "col_mapping = new_colmapping\n",
    "\n",
    "def extract_features(model: ResultModel) -> Dict[str, Any]:\n",
    "    res = dict()\n",
    "    \n",
    "    res['joint'] = \"joint\" in model.features\n",
    "    \n",
    "    res['model_name'] = model.config.name.split(\" \")[0]\n",
    "    model_features = list(model.features)\n",
    "    \n",
    "    if res['joint']:\n",
    "        model_features.remove(\"joint\")\n",
    "    \n",
    "    seed = next((x for x in model_features if \"seed\" in x), None)\n",
    "    if seed is None:\n",
    "        seed = model.run_config.seed\n",
    "        res['seed'] = seed\n",
    "    else:\n",
    "        model_features.remove(seed)\n",
    "        res['seed'] = int(seed.replace(\"seed\", \"\"))\n",
    "\n",
    "    noise_percentage = next((x for x in model_features if \"np\" in x), None)\n",
    "    model_features.remove(noise_percentage)\n",
    "    res['noise_percentage'] = float(noise_percentage.replace(\"np\", \"\").replace(\"_\", \".\"))\n",
    "\n",
    "    if \"REFIT\" in model_features:\n",
    "        model_features.remove(\"REFIT\")\n",
    "        res['prior'] = \"refit\"\n",
    "\n",
    "    if \"original\" in model_features:\n",
    "        model_features.remove(\"original\")\n",
    "        res['prior'] = \"original\"\n",
    "    if \"retrain\" in model_features:\n",
    "        model_features.remove(\"retrain\")\n",
    "        res['prior'] = \"refit\"\n",
    "    if \"retrain_xy\" in model_features:\n",
    "        model_features.remove(\"retrain_xy\")\n",
    "        res['prior'] = \"refit\"\n",
    "\n",
    "    elif \"convex\" in model_features:\n",
    "        model_features.remove(\"convex\")\n",
    "        res['prior'] = \"convex\"\n",
    "    elif \"diffeo\" in model_features:\n",
    "        model_features.remove(\"diffeo\")\n",
    "        res['prior'] = \"diffeo\"\n",
    "    else:\n",
    "        res['prior'] = \"none\"\n",
    "\n",
    "    if \"only_prior\" in model_features:\n",
    "        model_features.remove(\"only_prior\")\n",
    "        res['prior'] = res['prior'] + \"+only_prior\"\n",
    "\n",
    "    if \"all_frames\" in model_features:\n",
    "        model_features.remove(\"all_frames\")\n",
    "        res['prior'] = res['prior'] + \"+all_frames\"\n",
    "\n",
    "    if \"deeper\" in model_features:\n",
    "        model_features.remove(\"deeper\")\n",
    "        res['prior'] = res['prior'] + \"+deeper\"\n",
    "    if \"spatio-temporal\" in model_features:\n",
    "        model_features.remove(\"spatio-temporal\")\n",
    "        res['prior'] = res['prior'] + \"+spatio-temporal\"\n",
    "    if \"noisy\" in model_features:\n",
    "        model_features.remove(\"noisy\")\n",
    "        res['prior'] = res['prior'] + \"+noisy\"\n",
    "    if \"realnvp\" in model_features:\n",
    "        model_features.remove(\"realnvp\")\n",
    "        res['prior'] = res['prior'] + \"+realnvp\"\n",
    "\n",
    "\n",
    "    dataset_name = model_features.pop(0)\n",
    "    res['dataset_name'] = dataset_name\n",
    "\n",
    "    assert len(model_features) == 1, f\"Multiple features {model_features} in model {model.output_path}\"\n",
    "    res['feature_type'] = model_features[0]\n",
    "\n",
    "    return res\n",
    "\n",
    "df = comparison.metric_table(metrics, \n",
    "                             ref=\"all\", \n",
    "                             mode=\"max\",\n",
    "                        formatting=False)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "def extract_ft_row(row: pd.Series) -> Tuple[str, bool, str, int]:\n",
    "    name = row['index']\n",
    "    model = [m for m in models if m.name == name][0]\n",
    "    res = extract_features(model)\n",
    "    return (res['model_name'], res['joint'], res['feature_type'], res['seed'], res['dataset_name'], res['noise_percentage'], res['prior'])\n",
    "\n",
    "df[['model_name', 'joint', 'feature_type', 'seed', 'dataset_name', 'noise_percentage', \"prior\"]] = df.apply(extract_ft_row, axis=1, result_type=\"expand\")\n",
    "\n",
    "df = df[['index', 'model_name', 'dataset_name'] + list(col_mapping.keys()) + ['joint', 'feature_type', 'seed', 'noise_percentage', \"prior\"]]\n",
    "\n",
    "grouped = df.groupby(['model_name', 'joint', 'feature_type'])\n",
    "\n",
    "display_df = df.rename(columns=col_mapping)\n",
    "display(display_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from awesome.measures.miou import MIOU\n",
    "miou = MIOU()\n",
    "def compute_overlap_iou_for_model(result_model: NoisyUnariesResultModel, \n",
    "                                  df: pd.DataFrame, indices_tqdm: Optional[tqdm] = None, \n",
    "                                  map_location: Optional[torch.device] = None):\n",
    "    runner = result_model.get_runner(0)\n",
    "    model = runner.agent._get_model()\n",
    "    dataloader = runner.agent.training_dataset\n",
    "    model_gets_targets = runner.agent.model_gets_targets\n",
    "    indices = list(range(len(dataloader)))\n",
    "    noisy_unaries_dict = result_model.get_noisy_unaries_dict(map_location=map_location)\n",
    "\n",
    "    if 'noisy_unaries_length' not in df.columns:\n",
    "        df['noisy_unaries_length'] = -1\n",
    "\n",
    "    if 'noisy_unaries_index' not in df.columns:\n",
    "        df['noisy_unaries_index'] = None\n",
    "        df['noisy_unaries_index'] = df['noisy_unaries_index'].astype(object)\n",
    "\n",
    "    if 'noisy_unaries_overlap_ious' not in df.columns:\n",
    "        df['noisy_unaries_overlap_ious'] = None\n",
    "        df['noisy_unaries_overlap_ious'] = df['noisy_unaries_overlap_ious'].astype(object)\n",
    "\n",
    "    if 'noisy_unaries_index_was_noise' not in df.columns:\n",
    "        df['noisy_unaries_index_was_noise'] = None\n",
    "        df['noisy_unaries_index_was_noise'] = df['noisy_unaries_index_was_noise'].astype(object)\n",
    "\n",
    "    if 'noisy_unaries_overlap_mean_iou' not in df.columns:\n",
    "        df['noisy_unaries_overlap_mean_iou'] = -1\n",
    "\n",
    "    miou = MIOU(invert=True)\n",
    "\n",
    "    match_idx = np.argwhere((df['index'] == result_model.name).values)[0][0]\n",
    "\n",
    "    df.at[match_idx, \"noisy_unaries_length\"] = len(noisy_unaries_dict)\n",
    "    df.at[match_idx, \"noisy_unaries_index\"] = list(noisy_unaries_dict.keys())\n",
    "\n",
    "    ious = torch.zeros(len(indices))\n",
    "    was_noise = torch.zeros(len(indices), dtype=torch.bool)\n",
    "\n",
    "    if indices_tqdm is None:\n",
    "        indices_tqdm = tqdm(total=len(indices), desc=\"Images\")\n",
    "    else:\n",
    "        indices_tqdm.reset(total=len(indices))\n",
    "\n",
    "    for i in indices:\n",
    "        res, ground_truth, img, fg, bg = get_result(model, dataloader, i, model_gets_targets=model_gets_targets)\n",
    "        res = split_model_result(res, model, dataloader, img)\n",
    "        res_prior = res.get(\"prior\", None)\n",
    "        res_pred = res[\"segmentation\"]\n",
    "        boxes = res.get(\"boxes\", None)\n",
    "        labels = res.get(\"labels\", None)\n",
    "\n",
    "        was_noise[i] = noisy_unaries_dict.get(i, None) is not None \n",
    "        ious[i] = miou(res_prior, res_pred)\n",
    "        indices_tqdm.update()\n",
    "\n",
    "    df.at[match_idx, \"noisy_unaries_overlap_ious\"] = ious.numpy()\n",
    "    df.at[match_idx, \"noisy_unaries_index_was_noise\"] = was_noise.numpy()\n",
    "    df.at[match_idx, \"noisy_unaries_overlap_mean_iou\"] = ious.mean().numpy()\n",
    "    return indices_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_tqdm = None\n",
    "for model in tqdm(models, desc=\"Computing noisy unaries overlap IoU\"):\n",
    "    indices_tqdm = compute_overlap_iou_for_model(model, df, indices_tqdm=indices_tqdm, map_location=torch.device(\"cpu\"))\n",
    "indices_tqdm.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25:09:24:18.618 WARNING  [functions.py:44] Error importing CRF module. CRF will not be available. Is pydensecrf installed?\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from awesome.util.path_tools import numerated_file_name\n",
    "path = \"./output/noisy_unaries_df.pkl\"\n",
    "def save_df(path, df):\n",
    "    path = numerated_file_name(path)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(df, f)\n",
    "    return path\n",
    "\n",
    "def load_df(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>eval/epoch/MeanForegroundBinaryMIOU_0</th>\n",
       "      <th>eval/epoch/MeanPixelAccuracy_0</th>\n",
       "      <th>eval/epoch/MeanPriorPixelAccuracy_0</th>\n",
       "      <th>eval/epoch/MeanPriorForegroundBinaryMIOU_0</th>\n",
       "      <th>joint</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>noise_percentage</th>\n",
       "      <th>prior</th>\n",
       "      <th>noisy_unaries_length</th>\n",
       "      <th>noisy_unaries_index</th>\n",
       "      <th>noisy_unaries_overlap_ious</th>\n",
       "      <th>noisy_unaries_index_was_noise</th>\n",
       "      <th>noisy_unaries_overlap_mean_iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#00_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.976329</td>\n",
       "      <td>0.613105</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.3</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>6</td>\n",
       "      <td>[7, 5, 9, 17, 4, 16]</td>\n",
       "      <td>[0.44331086, 0.7048556, 0.82425034, 0.68361485...</td>\n",
       "      <td>[False, False, False, False, True, True, False...</td>\n",
       "      <td>0.509002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#01_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.979260</td>\n",
       "      <td>0.693721</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.6</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>11</td>\n",
       "      <td>[7, 5, 9, 17, 4, 16, 2, 14, 3, 1, 6]</td>\n",
       "      <td>[0.7659068, 0.15190026, 0.08374349, 0.07879557...</td>\n",
       "      <td>[False, True, True, True, True, True, True, Tr...</td>\n",
       "      <td>0.343454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#02_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>10</td>\n",
       "      <td>[13, 16, 12, 5, 3, 2, 6, 10, 11, 15]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, True, True, False, True, True, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#03_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.985247</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.4</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 2, 6, 16, 12, 15, 9, 14]</td>\n",
       "      <td>[0.85892284, 0.13685334, 0.19525188, 0.5620234...</td>\n",
       "      <td>[False, True, True, False, False, False, True,...</td>\n",
       "      <td>0.500875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#04_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.977419</td>\n",
       "      <td>0.551204</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.4</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>8</td>\n",
       "      <td>[13, 16, 12, 5, 3, 2, 6, 10]</td>\n",
       "      <td>[0.7206597, 0.71501505, 0.268971, 0.59363806, ...</td>\n",
       "      <td>[False, False, True, True, False, True, True, ...</td>\n",
       "      <td>0.527550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#05_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.990259</td>\n",
       "      <td>0.823874</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 2, 6, 16, 12, 15]</td>\n",
       "      <td>[0.873004, 0.13800967, 0.19436826, 0.8034708, ...</td>\n",
       "      <td>[False, True, True, False, False, False, True,...</td>\n",
       "      <td>0.622830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#06_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.989506</td>\n",
       "      <td>0.843188</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.2</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>4</td>\n",
       "      <td>[13, 16, 12, 5]</td>\n",
       "      <td>[0.9456474, 0.9387551, 0.92808884, 0.93275124,...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>0.832793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#07_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.677422</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.4</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>8</td>\n",
       "      <td>[7, 5, 9, 17, 4, 16, 2, 14]</td>\n",
       "      <td>[0.734954, 0.8768719, 0.8202636, 0.76039326, 0...</td>\n",
       "      <td>[False, False, True, False, True, True, False,...</td>\n",
       "      <td>0.514166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#08_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.961171</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.5</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>10</td>\n",
       "      <td>[7, 5, 9, 17, 4, 16, 2, 14, 3, 1]</td>\n",
       "      <td>[0.7454195, 0.09768665, 0.09218179, 0.20142125...</td>\n",
       "      <td>[False, True, True, True, True, True, False, T...</td>\n",
       "      <td>0.120576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#09_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.988748</td>\n",
       "      <td>0.820842</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[0.8690517, 0.13842389, 0.09811182, 0.69073164...</td>\n",
       "      <td>[False, True, True, False, False, False, False...</td>\n",
       "      <td>0.719126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#10_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.988985</td>\n",
       "      <td>0.833373</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9093209, 0.9177644, 0.9088054, 0.9114853, 0...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.826424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#11_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.990981</td>\n",
       "      <td>0.862972</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.1</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>2</td>\n",
       "      <td>[13, 16]</td>\n",
       "      <td>[0.93634295, 0.9157398, 0.9160596, 0.9294508, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.829577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#13_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.988709</td>\n",
       "      <td>0.823411</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 6, 16]</td>\n",
       "      <td>[0.9130883, 0.11024405, 0.12124383, 0.83355075...</td>\n",
       "      <td>[False, True, True, False, False, False, True,...</td>\n",
       "      <td>0.722134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#14_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.990832</td>\n",
       "      <td>0.861738</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.92687136, 0.90682477, 0.8890727, 0.908284, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.828719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#15_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.838835</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.88769674, 0.88329124, 0.920738, 0.9229059, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.822212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#16_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.965319</td>\n",
       "      <td>0.337160</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.3</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>6</td>\n",
       "      <td>[13, 16, 12, 5, 3, 2]</td>\n",
       "      <td>[0.4021872, 0.7589688, 0.16641654, 0.49737966,...</td>\n",
       "      <td>[False, False, True, True, False, True, False,...</td>\n",
       "      <td>0.448397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#17_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.958443</td>\n",
       "      <td>0.379477</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>11</td>\n",
       "      <td>[1, 2, 6, 16, 12, 15, 9, 14, 3, 10, 17]</td>\n",
       "      <td>[0.8581683, 0.13034748, 0.20522025, 0.48033908...</td>\n",
       "      <td>[False, True, True, True, False, False, True, ...</td>\n",
       "      <td>0.223764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#18_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.971298</td>\n",
       "      <td>0.405996</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2, 6, 16, 12, 15, 9, 14, 3, 10]</td>\n",
       "      <td>[0.6992069, 0.35986653, 0.58281153, 0.61374295...</td>\n",
       "      <td>[False, True, True, True, False, False, True, ...</td>\n",
       "      <td>0.436271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#19_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>47</td>\n",
       "      <td>0.6</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>11</td>\n",
       "      <td>[13, 16, 12, 5, 3, 2, 6, 10, 11, 15, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, True, True, True, False, True, True, F...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#20_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.990827</td>\n",
       "      <td>0.855028</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.2</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 5, 9, 17]</td>\n",
       "      <td>[0.9090847, 0.9133987, 0.93958807, 0.94354147,...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>0.833355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#21_UNET+cars3+edge+diffeo+only_prior+realnvp+...</td>\n",
       "      <td>UNet</td>\n",
       "      <td>cars3</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.990465</td>\n",
       "      <td>0.853059</td>\n",
       "      <td>False</td>\n",
       "      <td>edge</td>\n",
       "      <td>131</td>\n",
       "      <td>0.1</td>\n",
       "      <td>diffeo+only_prior+spatio-temporal+noisy+realnvp</td>\n",
       "      <td>2</td>\n",
       "      <td>[7, 5]</td>\n",
       "      <td>[0.9452672, 0.9434002, 0.92546815, 0.9411788, ...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>0.847026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                index model_name dataset_name  \\\n",
       "0   #00_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "1   #01_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "2   #02_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "3   #03_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "4   #04_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "5   #05_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "6   #06_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "7   #07_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "8   #08_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "9   #09_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "10  #10_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "11  #11_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "12  #13_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "13  #14_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "14  #15_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "15  #16_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "16  #17_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "17  #18_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "18  #19_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "19  #20_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "20  #21_UNET+cars3+edge+diffeo+only_prior+realnvp+...       UNet        cars3   \n",
       "\n",
       "    eval/epoch/MeanForegroundBinaryMIOU_0  eval/epoch/MeanPixelAccuracy_0  \\\n",
       "0                                0.779106                        0.985758   \n",
       "1                                0.779106                        0.985758   \n",
       "2                                0.779106                        0.985758   \n",
       "3                                0.779106                        0.985758   \n",
       "4                                0.779106                        0.985758   \n",
       "5                                0.779106                        0.985758   \n",
       "6                                0.779106                        0.985758   \n",
       "7                                0.779106                        0.985758   \n",
       "8                                0.779106                        0.985758   \n",
       "9                                0.779106                        0.985758   \n",
       "10                               0.779106                        0.985758   \n",
       "11                               0.779106                        0.985758   \n",
       "12                               0.779106                        0.985758   \n",
       "13                               0.779106                        0.985758   \n",
       "14                               0.779106                        0.985758   \n",
       "15                               0.779106                        0.985758   \n",
       "16                               0.779106                        0.985758   \n",
       "17                               0.779106                        0.985758   \n",
       "18                               0.779106                        0.985758   \n",
       "19                               0.779106                        0.985758   \n",
       "20                               0.779106                        0.985758   \n",
       "\n",
       "    eval/epoch/MeanPriorPixelAccuracy_0  \\\n",
       "0                              0.976329   \n",
       "1                              0.979260   \n",
       "2                              0.942786   \n",
       "3                              0.985247   \n",
       "4                              0.977419   \n",
       "5                              0.990259   \n",
       "6                              0.989506   \n",
       "7                              0.981817   \n",
       "8                              0.961171   \n",
       "9                              0.988748   \n",
       "10                             0.988985   \n",
       "11                             0.990981   \n",
       "12                             0.988709   \n",
       "13                             0.990832   \n",
       "14                             0.988889   \n",
       "15                             0.965319   \n",
       "16                             0.958443   \n",
       "17                             0.971298   \n",
       "18                             0.942786   \n",
       "19                             0.990827   \n",
       "20                             0.990465   \n",
       "\n",
       "    eval/epoch/MeanPriorForegroundBinaryMIOU_0  joint feature_type  seed  \\\n",
       "0                                     0.613105  False         edge   131   \n",
       "1                                     0.693721  False         edge   131   \n",
       "2                                     0.000000  False         edge    47   \n",
       "3                                     0.737333  False         edge    42   \n",
       "4                                     0.551204  False         edge    47   \n",
       "5                                     0.823874  False         edge    42   \n",
       "6                                     0.843188  False         edge    47   \n",
       "7                                     0.677422  False         edge   131   \n",
       "8                                     0.396629  False         edge   131   \n",
       "9                                     0.820842  False         edge    42   \n",
       "10                                    0.833373  False         edge    42   \n",
       "11                                    0.862972  False         edge    47   \n",
       "12                                    0.823411  False         edge    42   \n",
       "13                                    0.861738  False         edge    47   \n",
       "14                                    0.838835  False         edge   131   \n",
       "15                                    0.337160  False         edge    47   \n",
       "16                                    0.379477  False         edge    42   \n",
       "17                                    0.405996  False         edge    42   \n",
       "18                                    0.000000  False         edge    47   \n",
       "19                                    0.855028  False         edge   131   \n",
       "20                                    0.853059  False         edge   131   \n",
       "\n",
       "    noise_percentage                                            prior  \\\n",
       "0                0.3  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "1                0.6  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "2                0.5  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "3                0.4  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "4                0.4  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "5                0.3  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "6                0.2  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "7                0.4  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "8                0.5  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "9                0.1  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "10               0.0  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "11               0.1  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "12               0.2  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "13               0.0  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "14               0.0  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "15               0.3  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "16               0.6  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "17               0.5  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "18               0.6  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "19               0.2  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "20               0.1  diffeo+only_prior+spatio-temporal+noisy+realnvp   \n",
       "\n",
       "    noisy_unaries_length                      noisy_unaries_index  \\\n",
       "0                      6                     [7, 5, 9, 17, 4, 16]   \n",
       "1                     11     [7, 5, 9, 17, 4, 16, 2, 14, 3, 1, 6]   \n",
       "2                     10     [13, 16, 12, 5, 3, 2, 6, 10, 11, 15]   \n",
       "3                      8             [1, 2, 6, 16, 12, 15, 9, 14]   \n",
       "4                      8             [13, 16, 12, 5, 3, 2, 6, 10]   \n",
       "5                      6                    [1, 2, 6, 16, 12, 15]   \n",
       "6                      4                          [13, 16, 12, 5]   \n",
       "7                      8              [7, 5, 9, 17, 4, 16, 2, 14]   \n",
       "8                     10        [7, 5, 9, 17, 4, 16, 2, 14, 3, 1]   \n",
       "9                      2                                   [1, 2]   \n",
       "10                     0                                       []   \n",
       "11                     2                                 [13, 16]   \n",
       "12                     4                            [1, 2, 6, 16]   \n",
       "13                     0                                       []   \n",
       "14                     0                                       []   \n",
       "15                     6                    [13, 16, 12, 5, 3, 2]   \n",
       "16                    11  [1, 2, 6, 16, 12, 15, 9, 14, 3, 10, 17]   \n",
       "17                    10      [1, 2, 6, 16, 12, 15, 9, 14, 3, 10]   \n",
       "18                    11  [13, 16, 12, 5, 3, 2, 6, 10, 11, 15, 1]   \n",
       "19                     4                            [7, 5, 9, 17]   \n",
       "20                     2                                   [7, 5]   \n",
       "\n",
       "                           noisy_unaries_overlap_ious  \\\n",
       "0   [0.44331086, 0.7048556, 0.82425034, 0.68361485...   \n",
       "1   [0.7659068, 0.15190026, 0.08374349, 0.07879557...   \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3   [0.85892284, 0.13685334, 0.19525188, 0.5620234...   \n",
       "4   [0.7206597, 0.71501505, 0.268971, 0.59363806, ...   \n",
       "5   [0.873004, 0.13800967, 0.19436826, 0.8034708, ...   \n",
       "6   [0.9456474, 0.9387551, 0.92808884, 0.93275124,...   \n",
       "7   [0.734954, 0.8768719, 0.8202636, 0.76039326, 0...   \n",
       "8   [0.7454195, 0.09768665, 0.09218179, 0.20142125...   \n",
       "9   [0.8690517, 0.13842389, 0.09811182, 0.69073164...   \n",
       "10  [0.9093209, 0.9177644, 0.9088054, 0.9114853, 0...   \n",
       "11  [0.93634295, 0.9157398, 0.9160596, 0.9294508, ...   \n",
       "12  [0.9130883, 0.11024405, 0.12124383, 0.83355075...   \n",
       "13  [0.92687136, 0.90682477, 0.8890727, 0.908284, ...   \n",
       "14  [0.88769674, 0.88329124, 0.920738, 0.9229059, ...   \n",
       "15  [0.4021872, 0.7589688, 0.16641654, 0.49737966,...   \n",
       "16  [0.8581683, 0.13034748, 0.20522025, 0.48033908...   \n",
       "17  [0.6992069, 0.35986653, 0.58281153, 0.61374295...   \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "19  [0.9090847, 0.9133987, 0.93958807, 0.94354147,...   \n",
       "20  [0.9452672, 0.9434002, 0.92546815, 0.9411788, ...   \n",
       "\n",
       "                        noisy_unaries_index_was_noise  \\\n",
       "0   [False, False, False, False, True, True, False...   \n",
       "1   [False, True, True, True, True, True, True, Tr...   \n",
       "2   [False, False, True, True, False, True, True, ...   \n",
       "3   [False, True, True, False, False, False, True,...   \n",
       "4   [False, False, True, True, False, True, True, ...   \n",
       "5   [False, True, True, False, False, False, True,...   \n",
       "6   [False, False, False, False, False, True, Fals...   \n",
       "7   [False, False, True, False, True, True, False,...   \n",
       "8   [False, True, True, True, True, True, False, T...   \n",
       "9   [False, True, True, False, False, False, False...   \n",
       "10  [False, False, False, False, False, False, Fal...   \n",
       "11  [False, False, False, False, False, False, Fal...   \n",
       "12  [False, True, True, False, False, False, True,...   \n",
       "13  [False, False, False, False, False, False, Fal...   \n",
       "14  [False, False, False, False, False, False, Fal...   \n",
       "15  [False, False, True, True, False, True, False,...   \n",
       "16  [False, True, True, True, False, False, True, ...   \n",
       "17  [False, True, True, True, False, False, True, ...   \n",
       "18  [False, True, True, True, False, True, True, F...   \n",
       "19  [False, False, False, False, False, True, Fals...   \n",
       "20  [False, False, False, False, False, True, Fals...   \n",
       "\n",
       "    noisy_unaries_overlap_mean_iou  \n",
       "0                         0.509002  \n",
       "1                         0.343454  \n",
       "2                         0.000000  \n",
       "3                         0.500875  \n",
       "4                         0.527550  \n",
       "5                         0.622830  \n",
       "6                         0.832793  \n",
       "7                         0.514166  \n",
       "8                         0.120576  \n",
       "9                         0.719126  \n",
       "10                        0.826424  \n",
       "11                        0.829577  \n",
       "12                        0.722134  \n",
       "13                        0.828719  \n",
       "14                        0.822212  \n",
       "15                        0.448397  \n",
       "16                        0.223764  \n",
       "17                        0.436271  \n",
       "18                        0.000000  \n",
       "19                        0.833355  \n",
       "20                        0.847026  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_df(\"./output/noisy_unaries_df_tower.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = \"./output/noisy_unaries_df.pkl\"\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['model_name', 'dataset_name', 'joint', 'feature_type', 'noise_percentage', \"prior\"]\n",
    "\n",
    "grouped = df.groupby(group_by)\n",
    "for k, v in grouped:\n",
    "    print(k)\n",
    "    display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_cols = list(set(df.columns) - set([\"noisy_unaries_index\", \"noisy_unaries_overlap_ious\", \"noisy_unaries_index_was_noise\"]))\n",
    "\n",
    "\n",
    "group_by = ['model_name', 'dataset_name', 'joint', 'feature_type', 'noise_percentage', \"prior\"]\n",
    "\n",
    "use_cols = group_by + [\"noisy_unaries_overlap_mean_iou\"] \n",
    "\n",
    "\n",
    "\n",
    "grouped = df[use_cols].groupby(group_by)\n",
    "for k, v in grouped:\n",
    "    print(k)\n",
    "    display(v)\n",
    "    break\n",
    "\n",
    "mean_vals = grouped.mean()\n",
    "min_vals = grouped.min()\n",
    "max_vals = grouped.max()\n",
    "std_vals = grouped.std()\n",
    "\n",
    "display(mean_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from awesome.util.matplotlib import saveable\n",
    "\n",
    "\n",
    "@saveable()\n",
    "def plot_noise_bar(df, \n",
    "                   column: str, \n",
    "                   bar_color: Optional[Any] = None,\n",
    "                   size: float = 7):\n",
    "\n",
    "        mean_vals = df.mean()\n",
    "        min_vals = df.min()\n",
    "        max_vals = df.max()\n",
    "        std_vals = df.std()\n",
    "\n",
    "        fig, ax = get_mpl_figure(1, 1, size=size)\n",
    "        percentages = [x[4] for x in list(mean_vals.index)]\n",
    "        min_max_err = np.stack([np.abs(min_vals[column].values - mean_vals[column].values), \n",
    "                                max_vals[column].values - mean_vals[column].values])\n",
    "        x = percentages\n",
    "        y = mean_vals[column]\n",
    "        ax.bar(x=x, \n",
    "               height=y, \n",
    "               color=bar_color,\n",
    "               width=0.05\n",
    "                )\n",
    "        ax.errorbar(x, y, yerr=min_max_err, label=\"Mean IoU\", fmt=\"\", linestyle='', color=\"black\",capthick=1)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(\"{:.0%}\".format)\n",
    "\n",
    "        ax.set_ylabel(\"IoU\")\n",
    "        #ax.xaxis.set_major_formatter(lambda x: \".2f\".format(x))\n",
    "\n",
    "        ax.set_xlabel(\"Label Noise\")\n",
    "        ax.grid(axis=\"y\", linestyle='-', linewidth=1)\n",
    "        return fig\n",
    "\n",
    "column = \"noisy_unaries_overlap_mean_iou\"\n",
    "\n",
    "path = \"output/noisy_spatio_temporal/bar_plot\"\n",
    "fig = plot_noise_bar(grouped, column, bar_color=plt.get_cmap(\"tab10\")(1), override=True, save=True, path=path, ext=[\"png\" , \"pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Noise</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 \\%</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 \\%</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20 \\%</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 \\%</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40 \\%</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 \\%</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60 \\%</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label Noise    IoU\n",
       "0        0 \\%  0.826\n",
       "1       10 \\%  0.799\n",
       "2       20 \\%  0.796\n",
       "3       30 \\%  0.527\n",
       "4       40 \\%  0.514\n",
       "5       50 \\%  0.186\n",
       "6       60 \\%  0.189"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      " & Label Noise & IoU \\\\\n",
      "\\midrule\n",
      "0 & 0 \\% & 0.826 \\\\\n",
      "1 & 10 \\% & 0.799 \\\\\n",
      "2 & 20 \\% & 0.796 \\\\\n",
      "3 & 30 \\% & 0.527 \\\\\n",
      "4 & 40 \\% & 0.514 \\\\\n",
      "5 & 50 \\% & 0.186 \\\\\n",
      "6 & 60 \\% & 0.189 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_grouped = grouped.mean()\n",
    "mgrp_df = mean_grouped.reset_index()\n",
    "mgrp_df=mgrp_df[[\"noise_percentage\", column]]\n",
    "\n",
    "mgrp_df[\"noise_percentage\"] = mgrp_df[\"noise_percentage\"].apply(\"{:.0%}\".format).apply(lambda x: x.replace(\"%\", \" \\%\"))\n",
    "mgrp_df[column] = mgrp_df[column].apply(lambda x: str(round(x, 3)))\n",
    "\n",
    "col_mapping = {\n",
    "    \"noise_percentage\": \"Label Noise\",\n",
    "    column: \"IoU\"\n",
    "}\n",
    "mgrp_df = mgrp_df.rename(columns=col_mapping)\n",
    "display(mgrp_df)\n",
    "\n",
    "print(mgrp_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import count_parameters\n",
    "\n",
    "def get_model_size(model: ResultModel) -> int:\n",
    "    runner = model.get_runner(0)\n",
    "    agent = runner.agent\n",
    "    model = agent._get_model()\n",
    "    segm = pd.DataFrame(count_parameters(model.segmentation_module))\n",
    "    prior = pd.DataFrame(count_parameters(model.prior_module))\n",
    "    return segm, prior\n",
    "\n",
    "get_model_size(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack([min_vals['noisy_unaries_overlap_mean_iou'].values - mean_vals['noisy_unaries_overlap_mean_iou'].values, max_vals['noisy_unaries_overlap_mean_iou'].values - mean_vals['noisy_unaries_overlap_mean_iou'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vals['noisy_unaries_overlap_mean_iou'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(result_model, indices):\n",
    "    runner = result_model.get_runner(0)\n",
    "    model = runner.agent._get_model()\n",
    "    dataloader = runner.agent.training_dataset\n",
    "    model_gets_targets = runner.agent.model_gets_targets\n",
    "    noisy_unaries_dict = result_model.get_noisy_unaries_dict()\n",
    "\n",
    "    for i in indices:\n",
    "        res, ground_truth, img, fg, bg = get_result(model, dataloader, i, model_gets_targets=model_gets_targets)\n",
    "        res = split_model_result(res, model, dataloader, img)\n",
    "        res_prior = res.get(\"prior\", None)\n",
    "        res_pred = res[\"segmentation\"]\n",
    "        boxes = res.get(\"boxes\", None)\n",
    "        labels = res.get(\"labels\", None)\n",
    "\n",
    "        fig = plot_image_scribbles(image=img, inference_result=res_pred, foreground_mask=fg, background_mask=bg, \n",
    "                                   prior_result=res_prior)\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "plot_result(models[1], range(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['model_name', 'dataset_name', 'joint', 'feature_type', 'noise_percentage', \"prior\"]\n",
    "\n",
    "grouped = df.groupby(group_by)\n",
    "for k, v in grouped:\n",
    "    print(k)\n",
    "    display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from awesome.run.functions import get_mpl_figure, get_result, split_model_result\n",
    "from awesome.model.path_connected_net import PathConnectedNet\n",
    "from typing import Any\n",
    "plt.close(\"all\")\n",
    "\n",
    "grid_shapes = dict()\n",
    "model = runner.agent._get_model()\n",
    "dataloader = runner.dataloader\n",
    "\n",
    "\n",
    "index = list(range(0, len(dataloader), 1))\n",
    "\n",
    "t_n = len(index)\n",
    "t_max = len(dataloader) - 1\n",
    "\n",
    "images = []\n",
    "segmentations = []\n",
    "priors_no_sig = []\n",
    "\n",
    "\n",
    "with TemporaryProperty(model, use_prior_sigmoid=False), TemporaryProperty(dataloader, do_image_blurring=False):\n",
    "    for i in index:\n",
    "        res_no_sig, ground_truth, img, _, _ = get_result(model, dataloader, i, False)\n",
    "        res_no_sig = split_model_result(res_no_sig, model, dataloader, img)\n",
    "\n",
    "        priors_no_sig.append(res_no_sig.get(\"prior_raw\", None))\n",
    "\n",
    "        res_pred = res_no_sig[\"segmentation\"]\n",
    "\n",
    "        images.append(img)\n",
    "        segmentations.append(res_pred)\n",
    "\n",
    "images = torch.stack(images)\n",
    "segmentations = torch.stack(segmentations)\n",
    "priors_no_sig = torch.stack(priors_no_sig)\n",
    "\n",
    "shp = priors_no_sig.shape[-2:]\n",
    "if shp not in grid_shapes:\n",
    "    grid_shapes[shp] = PathConnectedNet.create_normalized_grid(shp).cpu().numpy()\n",
    "grid = grid_shapes[priors_no_sig.shape[-2:]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Stack time \n",
    "pred = priors_no_sig # B x C x H x W\n",
    "# Spatio temporal grid\n",
    "t_grid = torch.stack([torch.cat([torch.tensor(grid[0]), torch.full((1, *pred.shape[-2:]), t / t_max)], dim=0) for t in index])\n",
    "\n",
    "\n",
    "def plot_spatio_temporal_object(grid: Any, unaries: Any, size: float = 5):\n",
    "    \n",
    "    if isinstance(grid, torch.Tensor):\n",
    "        grid = grid.cpu().numpy()\n",
    "    if isinstance(unaries, torch.Tensor):\n",
    "        unaries = unaries.cpu().numpy()\n",
    "    \n",
    "    if len(grid.shape) < 4:\n",
    "        grid = grid[None]\n",
    "    if len(unaries.shape) < 4:\n",
    "        unaries = unaries[None]\n",
    "    \n",
    "\n",
    "    fig, ax = get_mpl_figure(subplot_kw=dict(projection='3d'))\n",
    "\n",
    "    for i in range(grid.shape[0]):\n",
    "        g = grid[i]\n",
    "        u = unaries[i][0]\n",
    "\n",
    "        z = u\n",
    "        y = g[1]\n",
    "        x = g[0]\n",
    "        offset = g[2].max() # Offset is the time\n",
    "        ax.contour(x, y, z, levels=[0.5], colors=\"red\", offset=offset, linewidths=2)\n",
    "\n",
    "    x_left, x_right = ax.get_xlim()\n",
    "    y_low, y_high = ax.get_ylim()\n",
    "\n",
    "    zoom= 1\n",
    "    elevation = 130\n",
    "    azimuth = 90\n",
    "    roll = 0\n",
    "\n",
    "    ax.set_box_aspect(aspect=((x_right-x_left)/(y_low-y_high), 1, 1), zoom=zoom)\n",
    "    ax.view_init(elev=elevation, azim=azimuth, roll=roll)\n",
    "\n",
    "    ax.invert_zaxis()\n",
    "\n",
    "    #ax.set_axis_off()\n",
    "    return fig\n",
    "\n",
    "#fig = plot_spatio_temporal_object(t_grid, pred)\n",
    "#fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import plot_3d_tubes\n",
    "import itertools\n",
    "\n",
    "subsamplings = [3, 4, 6]\n",
    "top_image_alphas = [0, 0.2]\n",
    "\n",
    "\n",
    "for subsampling, top_image_alpha in itertools.product(subsamplings, top_image_alphas):\n",
    "    path = f\"./output/spatio_temporal/tubes_{runner.dataloader.__dataset__.dataset_name}_subs_{subsampling}_alpha_{str(top_image_alpha).replace('.', '_')}\"\n",
    "    fig = plot_3d_tubes(priors_no_sig, images, \n",
    "                        top_image_alpha=top_image_alpha,\n",
    "                        subsample_factor=subsampling,\n",
    "                        subsample_image_mode=\"grid_sample\",\n",
    "                        grid_sample_mode=\"nearest\",\n",
    "                        transparent=True,\n",
    "                        path=path, save=True, ext=[\"png\", \"pdf\"], override=True)\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.run.functions import plot_3d_tubes\n",
    "\n",
    "path = f\"./notebooks/output/spatio_temporal/tubes_no_sub_{runner.dataloader.__dataset__.dataset_name}\"\n",
    "fig = plot_3d_tubes(priors_no_sig, images, subsample_x=1, subsample_y=1, path=path, save=True, ext=[\"png\", \"pdf\"], override=True)\n",
    "display(fig)\n",
    "\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.colors import to_rgba\n",
    "from skimage import measure\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "\n",
    "subsample_x = 6\n",
    "subsample_y = 6\n",
    "\n",
    "\n",
    "def plot_3d_tubes(logits, images, subsample_x = 6, subsample_y = 6):\n",
    "    vol = priors_no_sig[:, 0, ::subsample_y, ::subsample_x].cpu().numpy()\n",
    "\n",
    "    # Use marching cubes to obtain the surface mesh of these ellipsoids\n",
    "    verts, faces, normals, values = measure.marching_cubes(vol.T, 0)\n",
    "\n",
    "    # Display resulting triangular mesh using Matplotlib. This can also be done\n",
    "    # with mayavi (see skimage.measure.marching_cubes docstring).\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    image_index = 18\n",
    "    rgb_img = images[image_index, :, ::subsample_y, ::subsample_x].permute(1, 2, 0).numpy()\n",
    "\n",
    "    x = np.arange(0, rgb_img.shape[-2], 1)\n",
    "    y = np.arange(0, rgb_img.shape[-3], 1)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "    facecolor = plt.get_cmap(\"tab10\")(1)\n",
    "    edgecolor = None\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], shade=True, facecolors=facecolor, edgecolor='none', linewidth=0, antialiased=False,)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "\n",
    "    def create_grid_verticies(grid, z_loc):\n",
    "        indices = np.argwhere(grid.T >= 0)\n",
    "        repeated = indices[:, None, :].repeat(4, axis=1)\n",
    "        repeated[:, 1, 1] += 1 # Added one to x\n",
    "        repeated[:, 2, :] += 1 # Added one to x and y\n",
    "        repeated[:, 3, 0] += 1 # Added one to y\n",
    "        # Add constant z\n",
    "        zz = np.zeros_like(repeated[:, :, 0])[..., None]\n",
    "        zz.fill(z_loc)\n",
    "        vertices_img = np.concatenate([repeated, zz], axis=-1)\n",
    "        return vertices_img\n",
    "\n",
    "\n",
    "    fcol = rgb_img.reshape((math.prod(rgb_img.shape[:-1]), 3), order=\"F\")\n",
    "    secmesh = Poly3DCollection(create_grid_verticies(xx, image_index), shade=True, facecolors=fcol, edgecolor='none', linewidth=0, antialiased=False)\n",
    "    ax.add_collection3d(secmesh)\n",
    "\n",
    "    front_index = 0\n",
    "    front_img = images[front_index, :, ::subsample_y, ::subsample_x].permute(1, 2, 0).numpy()\n",
    "\n",
    "    fcol_front = front_img.reshape((math.prod(front_img.shape[:-1]), 3), order=\"F\")\n",
    "    # Stack alpha\n",
    "    fcol_front = np.concatenate([fcol_front, np.zeros_like(fcol_front[:, 0])[..., None]], axis=-1)\n",
    "\n",
    "    # Set alpha to 0 for all pixels that are not in the foreground\n",
    "    subsample_df_prior = priors_no_sig[front_index, :, ::subsample_y, ::subsample_x][0].numpy()\n",
    "    fg = (subsample_df_prior <= 0).reshape((math.prod(subsample_df_prior.shape), 1), order=\"F\")\n",
    "    fcol_front[fg[:, 0], 3] = 1\n",
    "\n",
    "    thirdmesh = Poly3DCollection(create_grid_verticies(xx, front_index), shade=True, facecolors=fcol_front, edgecolor='none', linewidth=0, antialiased=False)\n",
    "    ax.add_collection3d(thirdmesh)\n",
    "\n",
    "\n",
    "    #ax.plot_surface(xx, yy, np.zeros_like(xx), facecolors=rgb_img, rcount=rgb_img.shape[-2], ccount=rgb_img.shape[-3], zorder=0)\n",
    "\n",
    "\n",
    "    #secmesh = Poly3DCollection(verts[faces] + np.array([[0, 0, 10]]), shade=True, facecolors=facecolor, edgecolor=edgecolor, zorder=1)\n",
    "    #ax.add_collection3d(secmesh)\n",
    "\n",
    "\n",
    "    #y_max, x_max = xx.shape\n",
    "\n",
    "    # # Create axis like arrows for x, y and z\n",
    "    # vec_len = 5\n",
    "    # x_arrow = np.array([[0, y_max, 0], [vec_len, 0, 0]])\n",
    "    # y_arrow = np.array([[0, y_max, 0], [0, -vec_len, 0]])\n",
    "    # z_arrow = np.array([[0, y_max, 0], [0, 0, vec_len]])\n",
    "\n",
    "    # arrow_starts = np.stack([x_arrow[0], \n",
    "    #                     y_arrow[0],\n",
    "    #                     z_arrow[0]])\n",
    "    # arrow_directions = np.stack([\n",
    "    #                     x_arrow[1],\n",
    "    #                     y_arrow[1],\n",
    "    #                     z_arrow[1]])\n",
    "\n",
    "    # base_length_ratio = (len(images) - 1) * 0.1\n",
    "\n",
    "    # for i in range(len(arrow_starts)):\n",
    "    #     len_vec = np.linalg.norm(arrow_directions[i])\n",
    "    #     ax.quiver(arrow_starts[i, 0], arrow_starts[i, 1], arrow_starts[i, 2], \n",
    "    #             arrow_directions[i, 0], arrow_directions[i, 1], arrow_directions[i, 2], color=\"black\", zorder=10, \n",
    "    #             normalize=True,\n",
    "    #              linewidths=2)\n",
    "\n",
    "\n",
    "\n",
    "    #light_source = mpl.colors.LightSource(azdeg=315, altdeg=10)\n",
    "\n",
    "\n",
    "    ax.set_xlim(0, vol.shape[-1])  \n",
    "    ax.set_ylim(0, vol.shape[-2]) \n",
    "    ax.set_zlim(0, vol.shape[-3])  \n",
    "\n",
    "    #ax.set_xlabel('X')\n",
    "    #ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Time [t]')\n",
    "\n",
    "    ax.view_init(elev=40, azim=90, roll=0)\n",
    "\n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_zaxis()\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.line.set_lw(0.)\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    ax.yaxis.line.set_lw(0.)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    t = np.arange(0, len(images), 1)[::5]\n",
    "    ax.set_zticks(t, labels=t.astype(int))\n",
    "\n",
    "    ax.set_aspect('equalxy')\n",
    "\n",
    "    return fig\n",
    "#ax.set_axis_off()\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax.get_zticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.moveaxis(rgb_img, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts[faces[0][None,]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(xx[:-1, :-1] >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(xx[:-1, :-1] >= 0)\n",
    "repeated = indices[:, None, :].repeat(4, axis=1)\n",
    "repeated[:, 1, 1] += 1 # Added one to x\n",
    "repeated[:, 2, :] += 1 # Added one to x and y\n",
    "repeated[:, 3, 0] += 1 # Added one to y\n",
    "\n",
    "# Add constant z\n",
    "zz = np.zeros_like(repeated[:, :, 0])[..., None]\n",
    "vertices_img = np.concatenate([repeated, zz], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellip_double.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.argwhere(vol == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "#vol = ellip_double\n",
    "#vol = 1 - pred[:, 0, ::6, ::6].cpu()\n",
    "ax.voxels(vol <= 0, facecolors=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellip_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from awesome.run.functions import plot_as_image\n",
    "\n",
    "\n",
    "p = pred[0][0]\n",
    "\n",
    "all_contours = []\n",
    "all_hierarchy = []\n",
    "\n",
    "times = [t / t_max for t in index]\n",
    "\n",
    "for i in range(0, len(pred)):\n",
    "    p = pred[i][0]\n",
    "    t = times[i]\n",
    "    ret, thresh = cv.threshold(((1 - p.numpy()) * 255).astype(np.uint8), 123, 1, cv.THRESH_BINARY)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # We are loosing some information here, eg. holes in the object are not represented\n",
    "    # This is because we are only using the contour of the object\n",
    "\n",
    "    local_contours = [np.concatenate([c[:, 0, :] / (torch.tensor(p.shape[-2:]).numpy() - 1), np.full((c.shape[0], 1), t)], axis=1) for c in contours]\n",
    "    all_contours.append(local_contours)\n",
    "    all_hierarchy.append(hierarchy)\n",
    "\n",
    "#points = np.concatenate(all_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triangles = []\n",
    "\n",
    "for idx_time_frame in range(len(all_contours)):\n",
    "    last_contour_frame = None\n",
    "    if idx_time_frame > 0:\n",
    "        last_contour_data = all_contours[idx_time_frame - 1]\n",
    "    else:\n",
    "        last_contour_data = None\n",
    "    current_contour_data = all_contours[idx_time_frame]\n",
    "\n",
    "    if last_contour_data is None:\n",
    "        # First frame, leave it nonclosed\n",
    "        continue\n",
    "\n",
    "    for idx_contour in range(len(current_contour_data)):\n",
    "        current_contour = current_contour_data[idx_contour]\n",
    "        # Find the closest point distance between the current contour and one of the last contours\n",
    "        min_contour_idx = None\n",
    "        min_contour_dist = np.inf\n",
    "        min_dot_current = None\n",
    "        min_dot_last = None\n",
    "        for idx_last_contour in range(len(last_contour_data)):\n",
    "            last_contour = last_contour_data[idx_last_contour]\n",
    "\n",
    "            min_mat = np.linalg.norm(current_contour[:, None, :] - last_contour[None, :, :], axis=-1)\n",
    "            arg_idx = np.argmin(min_mat)\n",
    "            dist = min_mat[arg_idx]\n",
    "\n",
    "            if dist < min_contour_dist:\n",
    "                min_contour_dist = dist\n",
    "                min_contour_idx = idx_last_contour\n",
    "                min_dot_current = arg_idx[0]\n",
    "                min_dot_last = arg_idx[1]\n",
    "        \n",
    "        if min_contour_idx is None:\n",
    "            # No contour found\n",
    "            continue\n",
    "        \n",
    "        # We found a contour which is closest, now we need to triangulate\n",
    "        last_contour = last_contour_data[min_contour_idx]\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x_offset = 0.1\n",
    "\n",
    "test_points = np.array([\n",
    "    [0 + x_offset, 0, 0],\n",
    "    [1 + x_offset, 1, 0],\n",
    "    [0.5 + x_offset, 0, 0],\n",
    "])\n",
    "\n",
    "# Plot the surface\n",
    "ax.plot_trisurf(test_points[:, 0], test_points[:, 1], test_points[:, 2])\n",
    "\n",
    "# Set an equal aspect ratio\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay, ConvexHull\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "\n",
    "tri = None\n",
    "\n",
    "ctr = []\n",
    "\n",
    "simplices_list = []\n",
    "\n",
    "for i in range(1, len(all_contours)):\n",
    "    sublist = all_contours[i]\n",
    "    for item in sublist:\n",
    "        if tri is None:\n",
    "            # Get all points from the first frame\n",
    "            pts = []\n",
    "            for j in range(0, len(all_contours[i-1])):\n",
    "                pts.append(all_contours[i-1][j])\n",
    "            pts.append(item)\n",
    "            first_set = np.concatenate(pts)\n",
    "            tri = Delaunay(first_set, incremental=True)\n",
    "            #tri = \"test\"\n",
    "            ctr.append(first_set)\n",
    "        else:\n",
    "            tri.add_points(item)\n",
    "            ctr.append(item)\n",
    "    # Save the simplices\n",
    "    simplices_list.append(tri.simplices)\n",
    "    # reset tri\n",
    "    tri = None\n",
    "\n",
    "points = np.concatenate(ctr)\n",
    "\n",
    "simplices = np.concatenate(simplices_list)\n",
    "#ax.plot_trisurf(points[:,0], points[:,1], points[:,2], triangles=simplices)\n",
    "#for points, triangles in zip(ctr, simplices_list):\n",
    "#    ax.plot_trisurf(points[:,0], points[:,1], points[:,2], triangles=triangles)\n",
    "\n",
    "for i, points in enumerate(ctr):\n",
    "    ax.plot(points[:,0], points[:,1], points[:,2], 'o', label='frame {}'.format(i))\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.data.BunnyMesh()\n",
    "print(pcd)\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.664,\n",
    "                                  front=[-0.4761, -0.4698, -0.7434],\n",
    "                                  lookat=[1.8900, 3.2596, 0.9284],\n",
    "                                  up=[0.2304, -0.8825, 0.4101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(o3d.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Make data\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "x = 10 * np.outer(np.cos(u), np.sin(v))\n",
    "y = 10 * np.outer(np.sin(u), np.sin(v))\n",
    "z = 10 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "# Plot the surface\n",
    "ax.plot_surface(x, y, z)\n",
    "\n",
    "# Set an equal aspect ratio\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_as_image(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "ctr = []\n",
    "\n",
    "for sublist in all_contours:\n",
    "    for item in sublist:\n",
    "        ctr.append(item)\n",
    "\n",
    "points = np.concatenate(ctr)\n",
    "cloud = pv.PolyData(points)\n",
    "cloud.plot()\n",
    "\n",
    "volume = cloud.delaunay_3d(alpha=[0.01, 0.01, 0.1])\n",
    "shell = volume.extract_geometry()\n",
    "\n",
    "#axes = pv.Axes()\n",
    "#display(axes.show_actor())\n",
    "\n",
    "shell.plot(show_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install trame-vuetify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = get_mpl_figure()\n",
    "\n",
    "x = contours[1].squeeze()[:, 0]\n",
    "y = contours[1].squeeze()[:, 1]\n",
    "ax.plot(x, y, color=\"red\", linewidth=2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours[0].squeeze()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, 5)\n",
    "torch.cat([res, torch.full(t)], dim=0) for t in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Experiments with glow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xytype = \"edge\"\n",
    "dataset_kind = \"train\"\n",
    "dataset = \"bear01\"\n",
    "all_frames = True\n",
    "subset = None #slice(0, 5)\n",
    "segmentation_model_switch: Literal[\"original\", \"retrain\", \"retrain_xy\"] = \"original\"\n",
    "\n",
    "\n",
    "segmentation_model_state_dict_path = None\n",
    "if segmentation_model_switch == \"original\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/labels_with_uncertainty_flownet2_based/model_{dataset}_unet.pth\"\n",
    "elif segmentation_model_switch == \"retrain\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/refit_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "elif segmentation_model_switch == \"retrain_xy\":\n",
    "    segmentation_model_state_dict_path = f\"./data/checkpoints/refit_spatial_unet_uncertainty/23_11_13/model_{dataset}_unet.pth\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown segmentation_model_switch: {segmentation_model_switch}\")\n",
    "image_channel_format = \"bgr\" if segmentation_model_switch == \"original\" else \"rgb\"\n",
    "\n",
    "prior_criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "data_path = f\"./data/local_datasets/FBMS-59/{dataset_kind}/{dataset}\"\n",
    "\n",
    "real_dataset = FBMSSequenceDataset(\n",
    "                    dataset_path=data_path,\n",
    "                    weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based\",\n",
    "                    processed_weak_labels_dir = \"weak_labels/labels_with_uncertainty_flownet2_based/processed\",\n",
    "                    confidence_dir= \"weak_labels/labels_with_uncertainty_flownet2_based/\",\n",
    "                    do_weak_label_preprocessing=True,\n",
    "                    do_uncertainty_label_flip=True,\n",
    "                    test_weak_label_integrity=False,\n",
    "                    all_frames=True,\n",
    "                )\n",
    "dataset = AwesomeDataset(\n",
    "    **{\n",
    "        \"dataset\": real_dataset,\n",
    "        \"xytype\": xytype,\n",
    "        \"feature_dir\": f\"{data_path}/Feat\",\n",
    "        \"dimension\": \"3d\", # 2d for fcnet\n",
    "        \"mode\": \"model_input\",\n",
    "        \"model_input_requires_grad\": False,\n",
    "        \"batch_size\": 1,\n",
    "        \"split_ratio\": 1,\n",
    "        \"shuffle_in_dataloader\": False,\n",
    "        \"image_channel_format\": image_channel_format,\n",
    "        \"do_image_blurring\": True,\n",
    "        \"model_input_requires_grad\": True,\n",
    "        \"subset\": subset,\n",
    "        \"spatio_temporal\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "segmentation_model = UNet(4, 1)\n",
    "segmentation_model.load_state_dict(torch.load(segmentation_model_state_dict_path))\n",
    "\n",
    "\n",
    "def init_glow(channels: int, \n",
    "              hidden_channels: int,\n",
    "              n_flows: int,\n",
    "              height: int, \n",
    "              width: int,\n",
    "              scale: bool = True,\n",
    "              scale_map: Literal[\"sigmoid\", \"exp\"] = \"sigmoid\",\n",
    "              ) -> nf.NormalizingFlow:\n",
    "    # Define flows\n",
    "\n",
    "    input_shape = (channels, height, width)\n",
    "\n",
    "    # Set up flows, distributions and merge operations\n",
    "    q0 = nf.distributions.base.Uniform(input_shape, 0, 1)\n",
    "    flows = []\n",
    "    \n",
    "    for j in range(n_flows):\n",
    "        flows += [nf.flows.GlowBlock(channels, hidden_channels,\n",
    "                                    split_mode='channel', \n",
    "                                    scale_map=scale_map, leaky=0.01,\n",
    "                                    scale=scale, net_actnorm=False)]\n",
    "\n",
    "    # Construct flow model with the multiscale architecture\n",
    "    model = nf.NormalizingFlow(q0, \n",
    "                               flows, \n",
    "                               q0)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from awesome.agent.torch_agent import TorchAgent\n",
    "from awesome.dataset.prior_dataset import PriorManager\n",
    "from awesome.measures.unaries_weighted_loss import UnariesWeightedLoss\n",
    "from awesome.model.wrapper_module import WrapperModule\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.model.path_connected_net import PathConnectedNet\n",
    "from awesome.model.convex_net import ConvexNextNet\n",
    "from normflows import NormalizingFlow\n",
    "from normflows.flows import GlowBlock\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from awesome.util.torch import TensorUtil\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "channels = 2\n",
    "\n",
    "image_shape = dataset[0][0][0].shape[1:]\n",
    "\n",
    "flow_model = init_glow(channels=channels, hidden_channels=256, n_flows=3, \n",
    "                       height=image_shape[0], \n",
    "                       width=image_shape[1],\n",
    "                       scale=True)\n",
    "convex_model = ConvexNextNet(n_hidden=130, \n",
    "                             n_hidden_layers=2,\n",
    "                             in_features=channels)\n",
    "\n",
    "path_connected_model = PathConnectedNet(convex_model, flow_model)\n",
    "\n",
    "wrapper_module = WrapperModule(\n",
    "    segmentation_module=segmentation_model,\n",
    "    prior_module=path_connected_model,\n",
    "    prior_arg_mode=\"param_clean_grid\"\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-7\n",
    "\n",
    "previous_state = None\n",
    "previous_center_of_mass = None\n",
    "\n",
    "prior_module = wrapper_module.prior_module\n",
    "\n",
    "\n",
    "use_prior_sigmoid = True\n",
    "use_logger = False\n",
    "use_step_logger = False\n",
    "batch_progress_bar = None\n",
    "\n",
    "criterion = UnariesConversionLoss(SE(reduction=\"mean\"))\n",
    "\n",
    "TensorUtil.to(wrapper_module, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels, indices, prior_state = TorchAgent.decompose_training_item(dataset[0], training_dataset=dataset)\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "loss_hist = np.array([])\n",
    "\n",
    "grid = inputs[2]\n",
    "\n",
    "prior_module = wrapper_module.prior_module\n",
    "model = prior_module.flow_net\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "inputs, labels, indices, prior_state = TorchAgent.decompose_training_item(dataset[0], training_dataset=dataset)\n",
    "\n",
    "grid = inputs[2]\n",
    "\n",
    "grid = grid.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "grid = grid[None,...]\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in tqdm(range(max_iter)):\n",
    "    \n",
    "    x, y = grid, grid\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model.forward_kld(x.to(device))\n",
    "        \n",
    "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_hist = np.append(loss_hist, loss.detach().to('cpu').numpy())\n",
    "    del(x, y, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "it = data_loader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_progress_bar = True\n",
    "\n",
    "if use_progress_bar:\n",
    "    it = tqdm(it, desc=\"Pretraining images\")\n",
    "\n",
    "for i, item in enumerate(it):\n",
    "    inputs, labels, indices, prior_state = TorchAgent.decompose_training_item(item, training_dataset=dataset)\n",
    "    device_inputs: torch.Tensor = TensorUtil.to(\n",
    "        inputs, device=device)\n",
    "    # device_labels: torch.Tensor = TensorUtil.to(labels, device=device)\n",
    "\n",
    "    # Evaluate model to get unaries\n",
    "    # Switch prior weights if needed, using context manager\n",
    "    with PriorManager(wrapper_module,\n",
    "                        prior_state=prior_state,\n",
    "                        prior_cache=dataset.__prior_cache__,\n",
    "                        model_device=device,\n",
    "                        training=True\n",
    "                        ):\n",
    "        \n",
    "        unaries = None\n",
    "        has_proper_prior_fit = False\n",
    "        loaded_current_from_checkpoint = False\n",
    "\n",
    "        # Get the unaries\n",
    "        # Disable prior evaluation to just get the unaries\n",
    "        with torch.no_grad(), TemporaryProperty(wrapper_module, evaluate_prior=False):\n",
    "            if isinstance(device_inputs, list):\n",
    "                unaries = wrapper_module(*device_inputs)\n",
    "            else:\n",
    "                unaries = wrapper_module(device_inputs)\n",
    "\n",
    "\n",
    "        # Getting inputs for prior\n",
    "        prior_args, prior_kwargs = wrapper_module.get_prior_args(device_inputs[0],\n",
    "                                                                    *device_inputs[1:],\n",
    "                                                                    segm=unaries[0, ...],\n",
    "                                                                    )\n",
    "        _input = prior_args[0]\n",
    "        actual_input = _input.detach().clone()\n",
    "\n",
    "        _unique_vals = torch.unique(unaries >= 0.5)\n",
    "        # Check if unaries output contains at least some foreground\n",
    "        if len(_unique_vals) == 1:\n",
    "            # No foreground / background predicted. Skip this image\n",
    "            # We will keep the state of the prior if reuse_state is True\n",
    "            # If there was a pre existing state, we will use it again\n",
    "            logging.warning(f\"Unaries of segmentation model contain no foreground. Skipping image. {i}\")\n",
    "            continue\n",
    "        \n",
    "        # Determine number of epochs\n",
    "        epochs = num_epochs\n",
    "        \n",
    "        # Train n iterations\n",
    "        it = range(epochs)\n",
    "        if use_progress_bar:\n",
    "            desc = f'Image {i + 1}: Pretraining'\n",
    "            if batch_progress_bar is None:\n",
    "                batch_progress_bar = tqdm(\n",
    "                    total=epochs,\n",
    "                    desc=desc,\n",
    "                    leave=True)\n",
    "            else:\n",
    "                batch_progress_bar.reset(total=epochs)\n",
    "                batch_progress_bar.set_description(desc)\n",
    "\n",
    "        groups = []\n",
    "        groups += [dict(params=prior_module.flow_net.parameters(), weight_decay=weight_decay)]\n",
    "        groups += [dict(params=prior_module.convex_net.parameters())]\n",
    "        \n",
    "        optimizer = torch.optim.Adam(groups, lr=lr)\n",
    "\n",
    "        device_prior_output = None\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # Train n iterations\n",
    "            for step in it:\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                device_prior_output = prior_module(actual_input, *prior_args[1:], **prior_kwargs)\n",
    "                device_prior_output = wrapper_module.process_prior_output(\n",
    "                    device_prior_output, use_sigmoid=use_prior_sigmoid)[None, ...]  # Add batch dim again\n",
    "\n",
    "                loss: torch.Tensor = criterion(\n",
    "                    device_prior_output, unaries)\n",
    "\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    logging.warning(\n",
    "                        f\"Loss is nan or inf. Skipping step {step} of image {i}\")\n",
    "                    break\n",
    "\n",
    "                if use_logger and use_step_logger:\n",
    "                    logger.log_value(\n",
    "                        loss.item(), f\"PretrainingLoss/Image_{i}\", step=step)\n",
    "\n",
    "                prior_module.enforce_convexity()\n",
    "                if batch_progress_bar is not None:\n",
    "                    batch_progress_bar.set_postfix(\n",
    "                        loss=loss.item(), refresh=False)\n",
    "                    batch_progress_bar.update()\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = inputs[2]\n",
    "\n",
    "prior_module = wrapper_module.prior_module\n",
    "norm_flow = prior_module.flow_net\n",
    "\n",
    "with torch.no_grad():\n",
    "    norm_flow.eval()\n",
    "    grid = grid.to(device)\n",
    "    grid = grid[None, ...]\n",
    "    out_grid = norm_flow(grid)\n",
    "\n",
    "\n",
    "out_grid.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, ground_truth, img, fg, bg = get_result(wrapper_module, dataset, 0, model_gets_targets=False)\n",
    "res = split_model_result(res, wrapper_module, dataset, img, compute_crf=False)\n",
    "res_prior = res.get(\"prior\", None)\n",
    "res_pred = res[\"segmentation\"]\n",
    "fig = plot_image_scribbles(img, res_pred, fg, bg, res_prior, save=True, size=5, tight_layout=True, title=\"Epoch: \" + str(step),\n",
    "                                        legend=False)\n",
    "fig                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome-dC4phDSK-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from awesome.model.unet import UNet\n",
    "from awesome.dataset.awesome_dataset import AwesomeDataset\n",
    "from awesome.dataset.fbms_sequence_dataset import FBMSSequenceDataset\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "import os\n",
    "from awesome.run.functions import plot_as_image, channel_masks_to_value_mask, transparent_added_listed_colormap, get_mpl_figure, plot_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from awesome.analytics.result_model import ResultModel\n",
    "os.chdir(get_project_root_path())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW-TO: Read Results\n",
    "\n",
    "This Notebook should help you to read the results of the runs and experiments.\n",
    "\n",
    "We provide a dedictated ResultModel class which can parse and read all results from an experiment run and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have performed an Path-Connectedness Training run\n",
    "# and the runs output is stored in the following path\n",
    "\n",
    "path = \"runs/fbms_local/unet/UNET+cars3+edge+diffeo+original+joint_24_07_05_10_03_06\"\n",
    "\n",
    "# With this we can load a result model\n",
    "\n",
    "result_model = ResultModel.from_path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result model contains everything you need to know about the results of a run or even to restart the run from the results.\n",
    "It contains also the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model.get_tracked_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tracker stores the metrics for each epoch / batch. We can get the tracker from a saved checkpoint (-1) is the last checkpoint.\n",
    "tracker = result_model.get_tracker(-1)\n",
    "metrics = tracker.metrics\n",
    "for metric in [m for m in metrics.keys() if \"miou\" in m.lower()]:\n",
    "    print(metric)\n",
    "    display(metrics[metric].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, multiple runs can easily be compared, with the result comparison model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.analytics.result_comparison import ResultComparison\n",
    "\n",
    "\n",
    "comp = ResultComparison([result_model]) # Usually one would compare different models, we just provied one for demonstration purposes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some default functions for plotting as line or bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = comp.plot_metric(list(metrics.keys())[0])\n",
    "display(fig)\n",
    "\n",
    "fig = comp.plot_metric_bar(list(metrics.keys())[0])\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or compared side by side as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = comp.metric_table(list(metrics.keys()))\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more usage and examples, see [unireps_evaluation.ipynb](../unireps_evaluation.ipynb) or [fbms_eval_icml.ipynb](../fbms_eval_icml.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome-dl0Fwmhq-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  try:\n",
    "    import awesome\n",
    "  except (ModuleNotFoundError, ImportError):\n",
    "    !pip install -r https://raw.githubusercontent.com/jp-schneider/awesome/main/requirements.slim.txt\n",
    "    !pip install git+https://github.com/jp-schneider/awesome.git --no-deps\n",
    "\n",
    "  # Load data\n",
    "  if not os.path.exists(\"notebooks/how_to/data/cocktail-tomatoes.jpg\"):\n",
    "    os.makedirs(\"notebooks/how_to/data\", exist_ok=True)\n",
    "    !wget https://raw.githubusercontent.com/jp-schneider/awesome/main/notebooks/how_to/data/cocktail-tomatoes.jpg --output-document=notebooks/how_to/data/cocktail-tomatoes.jpg\n",
    "\n",
    "  try:\n",
    "    import torch\n",
    "  except (ModuleNotFoundError, ImportError) as err:\n",
    "    !pip install torch torchvision torchaudio\n",
    "\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "from awesome.run.functions import plot_as_image, get_mpl_figure, plot_mask\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from awesome.model.zoo import Zoo\n",
    "from awesome.model.convex_net import ConvexNextNet\n",
    "from awesome.run.runner import seed_all\n",
    "from awesome.util.torch import tensorify\n",
    "import torch\n",
    "from matplotlib.colors import get_named_colors_mapping\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "zoo = Zoo()\n",
    "\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "  os.chdir(get_project_root_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To: Convexity\n",
    "\n",
    "This is a simple demonstration, how to use our convexity prior to get a convex segmentation of some unaries.\n",
    "We used the \"sequential\" fit as terminology in our manuscript, one can also discribe it as post-processing to some initial segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the following example:\n",
    "\n",
    "One tries to get a segmentation of a tomato, to calculate e.g. its volume, so occlusions should be included in the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=\"notebooks/how_to/data/cocktail-tomatoes.jpg\"\n",
    "\n",
    "def load_image(path: str, down_scale: int = 1) -> np.ndarray:\n",
    "    img_pil=Image.open(path)\n",
    "    width, height = img_pil.size \n",
    "    newsize = (int(width/down_scale), int(height/down_scale))\n",
    "    img_pil = img_pil.resize(newsize)\n",
    "\n",
    "    img= np.array(img_pil, dtype='float')/255.0\n",
    "    img = img[:,:,0:3]\n",
    "    nx,ny,nc = img.shape\n",
    "    return img\n",
    "\n",
    "img = load_image(img_dir, down_scale=2)\n",
    "\n",
    "fig = plot_as_image(img, variable_name=\"Tomato\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets try to get a ruff segmentation, like with a simple thresholding, of course, one can also use any other segmentation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = img[:,:,0]-img[:,:,1]-img[:,:,2] - 0.5\n",
    "\n",
    "likelihood = torch.sigmoid(torch.tensor(1-likelihood).float())\n",
    "likelihood = likelihood - torch.min(likelihood)\n",
    "likelihood = likelihood / torch.max(likelihood)\n",
    "likelihood = (likelihood<0.5).float()\n",
    "\n",
    "fig = plot_mask(img, likelihood, filled_contours=False, lined_contours=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation covers the tomato, quite well, but the leafs block some parts.\n",
    "\n",
    "So, lets define a convexity prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_cuda = True\n",
    "# Use cuda if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "height, width = likelihood.shape[-2:]\n",
    "\n",
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "\n",
    "# We need a coordinate grid, which we use to query our implicit representation.\n",
    "def create_grid(image_shape, device: torch.device):\n",
    "    ny, nx = image_shape\n",
    "    x = torch.arange(0, nx, device=device)\n",
    "    y = torch.arange(0, ny, device=device)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing='xy')\n",
    "    grid = torch.stack((xx, yy), dim=0)\n",
    "    batched_input = grid.unsqueeze(0).float() / torch.tensor([nx, ny], device=device).float().unsqueeze(-1).unsqueeze(-1)\n",
    "    return batched_input\n",
    "x = create_grid((height, width), device)\n",
    "\n",
    "# We define the FG as 0, so we need to invert the mask\n",
    "unaries = 1 - likelihood.to(device)\n",
    "\n",
    "seed_all(0)\n",
    "\n",
    "model = ConvexNextNet(n_hidden_layers=1)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def plot_loss(loss: torch.Tensor):\n",
    "    fig, ax = get_mpl_figure(1, 1)\n",
    "    ax.plot(loss.detach().cpu().numpy())\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Training Loss\")\n",
    "    return fig\n",
    "\n",
    "# Using Adamax as optimizer for the flow net was giving us slightly better results than Adam, but feel free to experiment.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)  \n",
    "num_epochs = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model to the data. This will take a while, so we will only train for 2000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from awesome.measures.se import SE\n",
    "\n",
    "\n",
    "def train(\n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        model: ConvexNextNet, \n",
    "        unaries: torch.Tensor, \n",
    "        num_epochs: int, \n",
    "        fg_weight: float = 0.66,\n",
    "        ):\n",
    "    # Train the model\n",
    "    loss_full = torch.zeros(num_epochs, dtype=torch.float32)\n",
    "    model.train()\n",
    "\n",
    "    criterion = SE(reduction='none')\n",
    "\n",
    "    batched_input = create_grid(unaries.shape[-2:], unaries.device)\n",
    "    it = tqdm(range(num_epochs), total=num_epochs, desc=f\"Training\")\n",
    "    batched_unaries = unaries.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    background_mask = batched_unaries == 1.\n",
    "    foreground_mask = ~background_mask\n",
    "\n",
    "    bg_length = background_mask.sum()\n",
    "    fg_length = foreground_mask.sum()\n",
    "\n",
    "    fg_weight = tensorify(fg_weight, device=unaries.device)\n",
    "\n",
    "    for epoch in it:\n",
    "        \n",
    "        out = torch.sigmoid(model(batched_input))\n",
    "        if torch.isnan(out).any():\n",
    "            raise ValueError(\"Output is nan\")\n",
    "\n",
    "        fg_loss = criterion(out[foreground_mask], batched_unaries[foreground_mask])\n",
    "        bg_loss = criterion(out[background_mask], batched_unaries[background_mask])\n",
    "\n",
    "        # We are weighting the fg and bg differently to get proper tomato segmentation\n",
    "        loss = (1 - fg_weight) * (bg_loss.sum() / bg_length) + (fg_weight * (fg_loss.sum() / fg_length))\n",
    "\n",
    "        loss_full[epoch] = loss.detach().cpu()\n",
    "            \n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # After Each epoch we enforce the convexity of the convex net to ensure the convexity of the model => Weights should be positive\n",
    "        model.enforce_convexity()\n",
    "\n",
    "        if (epoch+1) % 50 == 0 or epoch == 0:\n",
    "            it.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "    return model, loss_full\n",
    "\n",
    "tm, loss = train(optimizer, model, unaries, num_epochs, fg_weight=0.4)\n",
    "fig = plot_loss(loss)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model, we can now inference and get the segmentation of the tomato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # We query the model with a grid of coordinates. The model will return the likelihood of each pixel being foreground.\n",
    "    # We can also create a super resolution grid to get a higher resolution output.\n",
    "    in_ = create_grid(unaries.shape[-2:], unaries.device).to(get_model_device(model))\n",
    "    path_connected_likelihood = model(in_).squeeze().cpu()\n",
    "\n",
    "# We can now threshold the output to get a binary mask.\n",
    "path_connected_likelihood_mask = torch.sigmoid(path_connected_likelihood) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voila! We have a *provable* convex segmentation of the tomato!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = get_named_colors_mapping().get(\"tab:orange\")\n",
    "plot_mask(img, path_connected_likelihood_mask, color=color, variable_name=\"Output of the model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

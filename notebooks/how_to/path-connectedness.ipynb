{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  try:\n",
    "    import awesome\n",
    "  except (ModuleNotFoundError, ImportError):\n",
    "    !pip install -r https://raw.githubusercontent.com/jp-schneider/awesome/main/requirements.slim.txt\n",
    "    !pip install git+https://github.com/jp-schneider/awesome.git --no-deps\n",
    "\n",
    "  # Load data\n",
    "  if not os.path.exists(\"notebooks/how_to/data/cat_scribbled.jpg\"):\n",
    "    os.makedirs(\"notebooks/how_to/data\", exist_ok=True)\n",
    "    !wget https://raw.githubusercontent.com/jp-schneider/awesome/main/notebooks/how_to/data/cat_scribbled.jpg --output-document=notebooks/how_to/data/cat_scribbled.jpg\n",
    "    !wget https://raw.githubusercontent.com/jp-schneider/awesome/main/notebooks/how_to/data/cat.jpg --output-document=notebooks/how_to/data/cat.jpg\n",
    "\n",
    "  try:\n",
    "    import torch\n",
    "  except (ModuleNotFoundError, ImportError) as err:\n",
    "    !pip install torch torchvision torchaudio\n",
    "\n",
    "from awesome.model.path_connected_net import PathConnectedNet\n",
    "from awesome.util.path_tools import get_project_root_path\n",
    "from awesome.run.functions import plot_as_image, get_mpl_figure, plot_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from awesome.model.convex_net import ConvexNextNet\n",
    "from awesome.model.net_factory import get_norm, init_realnvp\n",
    "from awesome.model.norm_net import NormNet\n",
    "from awesome.model.pixelize_net import PixelizeNet\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from awesome.run.runner import seed_all\n",
    "from matplotlib.colors import get_named_colors_mapping\n",
    "from awesome.util.torch import tensorify\n",
    "\n",
    "from awesome.model.zoo import Zoo\n",
    "zoo = Zoo()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ioff()\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "  os.chdir(get_project_root_path())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To: Path-Connectedness\n",
    "\n",
    "This is a simple demonstration, how to use our path-connectedness prior to get a path connected segmentation of some unaries.\n",
    "We used the \"sequential\" fit as terminology in our manuscript, one can also discribe it as post-processing to some initial segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the following example:\n",
    "\n",
    "One tries to get a path-connected segmentation of the cat, and the image was scribbled with some foreground scribbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=\"notebooks/how_to/data/cat_scribbled.jpg\"\n",
    "img_orig_dir=\"notebooks/how_to/data/cat.jpg\"\n",
    "\n",
    "def load_image(path: str, down_scale: int = 1) -> np.ndarray:\n",
    "    img_pil=Image.open(path)\n",
    "    width, height = img_pil.size \n",
    "    newsize = (int(width/down_scale), int(height/down_scale))\n",
    "    img_pil = img_pil.resize(newsize)\n",
    "\n",
    "    img= np.array(img_pil, dtype='float')/255.0\n",
    "    img = img[:,:,0:3]\n",
    "    nx,ny,nc = img.shape\n",
    "    return img\n",
    "\n",
    "img = load_image(img_dir, down_scale=2)\n",
    "img_orig = load_image(img_orig_dir, down_scale=2)\n",
    "\n",
    "fig, axes = get_mpl_figure(1, 2, ratio_or_img=img)\n",
    "plot_as_image(img, variable_name=\"A scribbled cat\", axes=axes[0])\n",
    "plot_as_image(img_orig, variable_name=\"Original cat\", axes=axes[1])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets try to get the scribble from the image to use them as unaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = torch.tensor((img[:,:,0]-img[:,:,1])>0.7).float()\n",
    "fig = plot_mask(None, likelihood, filled_contours=True, lined_contours=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use the path-connectedness prior to get a path-connected segmentation of the cat.\n",
    "Lets init the model for this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_cuda = True\n",
    "# Use cuda if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "height, width = likelihood.shape[-2:]\n",
    "\n",
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "\n",
    "# We need a coordinate grid, which we use to query our implicit representation.\n",
    "def create_grid(image_shape, device: torch.device):\n",
    "    ny, nx = image_shape\n",
    "    x = torch.arange(0, nx, device=device)\n",
    "    y = torch.arange(0, ny, device=device)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing='xy')\n",
    "    grid = torch.stack((xx, yy), dim=0)\n",
    "    batched_input = grid.unsqueeze(0).float() / torch.tensor([nx, ny], device=device).float().unsqueeze(-1).unsqueeze(-1)\n",
    "    return batched_input\n",
    "\n",
    "# We define the FG as 0, so we need to invert the mask\n",
    "unaries = 1 - likelihood.to(device)\n",
    "\n",
    "seed_all(0)\n",
    "\n",
    "# We use a factory function here to generate some Normalizing Flows, which we use to model the diffeomorphism.\n",
    "flow_net = init_realnvp(\n",
    "                        channels=2, \n",
    "                        n_flows=10,\n",
    "                        height=height, \n",
    "                        width=width,\n",
    "                        output_fn=\"tanh\"\n",
    "                        )\n",
    "\n",
    "# The realnvp takes in a 2d input (B, C, H, W), while the convex net takes in a 1d input (B*H*W, C).\n",
    "# To accompansate, we use the PixelizeNet to flatten the input.\n",
    "flow = PixelizeNet(flow_net)\n",
    "\n",
    "\n",
    "norm = get_norm(\"minmax\", dim=(0, 2, 3)) # Channel wise normalization\n",
    "norm.fit(create_grid(unaries.shape[-2:], device=torch.device(\"cpu\")))\n",
    "norm_flow = NormNet(net=flow, norm=norm)\n",
    "\n",
    "model = PathConnectedNet(convex_net=ConvexNextNet(n_hidden_layers=2), flow_net=norm_flow)\n",
    "model.to(device)\n",
    "\n",
    "# Before learning the Diffeo and Convex in Path connected net, it is usally helpful to learn the flow identity first. This will give the convex net some time to adjust.\n",
    "# We using a simple model zoo, so we dont have to train the flow identity from scratch if its trained once with a destinct parameter set.\n",
    "x = create_grid(unaries.shape[-2:], unaries.device)\n",
    "model.learn_flow_identity(x, zoo=zoo)\n",
    "\n",
    "# To accompensate for potential exploding weights, we use weight decay on the flow net.\n",
    "groups = []\n",
    "groups.append(dict(params=model.flow_net.parameters(), weight_decay=1e-5, lr=2e-3))\n",
    "groups.append(dict(params=model.convex_net.parameters()))\n",
    "groups.append(dict(params=model.linear.parameters()))\n",
    "\n",
    "def plot_loss(loss: torch.Tensor):\n",
    "    fig, ax = get_mpl_figure(1, 1)\n",
    "    ax.plot(loss.detach().cpu().numpy())\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Training Loss\")\n",
    "    return fig\n",
    "\n",
    "# Using Adamax as optimizer for the flow net was giving us slightly better results than Adam, but feel free to experiment.\n",
    "optimizer = torch.optim.Adamax(groups, lr=1e-3)  \n",
    "num_epochs = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model to the data. This will take a while, so we will only train for 2000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        model: PathConnectedNet, \n",
    "        unaries: torch.Tensor, \n",
    "        num_epochs: int, \n",
    "        fg_weight: float = 0.66,\n",
    "        ):\n",
    "    # Train the model\n",
    "    loss_full = torch.zeros(num_epochs, dtype=torch.float32, device=unaries.device)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    criterion = BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    batched_input = create_grid(unaries.shape[-2:], unaries.device)\n",
    "    it = tqdm(range(num_epochs), total=num_epochs, desc=f\"Training\")\n",
    "    batched_unaries = unaries.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    background_mask = batched_unaries == 1.\n",
    "    foreground_mask = ~background_mask\n",
    "\n",
    "    bg_length = background_mask.sum()\n",
    "    fg_length = foreground_mask.sum()\n",
    "\n",
    "    fg_weight = tensorify(fg_weight, device=unaries.device)\n",
    "\n",
    "    for epoch in it:\n",
    "        \n",
    "        out = model(batched_input)\n",
    "        if torch.isnan(out).any():\n",
    "            raise ValueError(\"Output is nan\")\n",
    "\n",
    "        fg_loss = criterion(out[foreground_mask], batched_unaries[foreground_mask])\n",
    "        bg_loss = criterion(out[background_mask], batched_unaries[background_mask])\n",
    "\n",
    "        # As we take a BCE loss, we must adjust the weighting to account for the log => 0 problem.\n",
    "        # Other loss functions might not need this adjustment. \n",
    "        loss = ((((1 - fg_weight) * (bg_loss)).sum() / bg_length) + ((fg_weight * fg_loss).sum() / fg_length))\n",
    "\n",
    "        loss_full[epoch] = loss.detach().cpu()\n",
    "            \n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # After Each epoch we enforce the convexity of the convex net to ensure the convexity of the model => Weights should be positive\n",
    "        model.enforce_convexity()\n",
    "\n",
    "        if (epoch+1) % 50 == 0 or epoch == 0:\n",
    "            it.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "    return model, loss_full\n",
    "\n",
    "tm, loss = train(optimizer, model, unaries, num_epochs, fg_weight=0.3)\n",
    "fig = plot_loss(loss)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model, we can now inference the segmentation of the cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # We query the model with a grid of coordinates. The model will return the likelihood of each pixel being foreground.\n",
    "    # We can also create a super resolution grid to get a higher resolution output.\n",
    "    in_ = create_grid(unaries.shape[-2:], unaries.device).to(get_model_device(model))\n",
    "    path_connected_likelihood = model(in_).squeeze().cpu()\n",
    "\n",
    "# We can now threshold the output to get a binary mask.\n",
    "path_connected_likelihood_mask = torch.sigmoid(path_connected_likelihood) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voila! We have a path-connected segmentation of the cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = get_named_colors_mapping().get(\"tab:orange\")\n",
    "plot_mask(img_orig, path_connected_likelihood_mask, color=color, variable_name=\"Output of the model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

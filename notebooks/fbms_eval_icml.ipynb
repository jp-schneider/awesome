{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from awesome.run.awesome_config import AwesomeConfig\n",
    "from awesome.run.awesome_runner import AwesomeRunner\n",
    "from awesome.util.reflection import class_name\n",
    "from awesome.analytics.result_model import ResultModel\n",
    "from awesome.util.path_tools import get_project_root_path, get_package_root_path\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from awesome.util.format import latex_postprocessor\n",
    "import pandas as pd\n",
    "from typing import Any, Dict\n",
    "os.chdir(get_project_root_path()) # Beeing in the root directory of the project is important for the relative paths to work consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awesome.analytics.result_comparison import ResultComparison\n",
    "\n",
    "paths = [\n",
    "         \"./runs/fbms_local/eval/unet/joint_realnvp/2024-01-11\",\n",
    "         \"./runs/fbms_local/eval/unet/joint_realnvp/2024-01-11-seed\"\n",
    "         ]\n",
    "models = []\n",
    "\n",
    "for path in paths:\n",
    "    for folder in os.listdir(path):\n",
    "        if folder.startswith(\"old\") or folder.startswith(\"log\"):\n",
    "            continue\n",
    "        model = ResultModel.from_path(os.path.join(path, folder))\n",
    "        models.append(model)\n",
    "\n",
    "import re\n",
    "p = r\"#?(?P<cfg_num>\\d+)?_?(?P<net>[A-z0-9]+)_?(?P<feat>(\\+\\w+)*)\\_(?P<date>\\d{2}_\\d{2}_\\d{2})\\_(?P<time>\\d{2}_\\d{2}_\\d{2})\"\n",
    "pattern = re.compile(p)\n",
    "\n",
    "for model in models:\n",
    "    match = pattern.match(model.name)\n",
    "    model_name = None\n",
    "    feat = []\n",
    "    if match:\n",
    "        model_name = match.group('net').strip(\"_\")\n",
    "        features = match.group('feat')\n",
    "        if features is not None and features != \"\":\n",
    "            feat = features.strip(\"+\").split(\"+\")\n",
    "            if not any([\"seed\" in x for x in feat]):\n",
    "                feat.append(\"seed42\")\n",
    "    else:\n",
    "        print('No match for', model.name)\n",
    "    model_name = model_name.replace(\"NET\", \"Net\")\n",
    "    model.display_name = model_name + \" \" + \" \".join(feat)\n",
    "    model.features = list(feat)\n",
    "    model.config.result_directory = \"final_mask\"\n",
    "    model.save_config()\n",
    "\n",
    "\n",
    "# Resort the models by name to get a meaningful table order\n",
    "\n",
    "_order = []\n",
    "\n",
    "models = sorted(models, key=lambda m: _order.index(m.name) if m.name in _order else 0)\n",
    "\n",
    "comparison = ResultComparison(models)\n",
    "comparison.assign_numbers(force=True)\n",
    "\n",
    "os.environ['PLOT_OUTPUT_DIR'] = comparison.output_folder\n",
    "\n",
    "save_args = dict(transparent=False, save=True, dpi=300, ext=[\"png\", \"pdf\"])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "metrics = [\n",
    "    \"eval/epoch/MeanForegroundBinaryMIOU\" ,\n",
    "    \"eval/epoch/MeanPriorForegroundBinaryMIOU\",\n",
    "    \"eval/epoch/MeanPixelAccuracy\",\n",
    "    \"eval/epoch/MeanPriorPixelAccuracy\",\n",
    "    \"eval/epoch/MeanCRFForegroundBinaryMIOU\",\n",
    "    \"eval/epoch/MeanCRFPixelAccuracy\",\n",
    "]\n",
    "\n",
    "col_mapping = {\n",
    "    \"eval/epoch/MeanForegroundBinaryMIOU\": \"IoU\",\n",
    "    \"eval/epoch/MeanCRFForegroundBinaryMIOU\": \"CRF IoU\",\n",
    "    \"eval/epoch/MeanPixelAccuracy\": \"Acc.\",\n",
    "    \"eval/epoch/MeanCRFPixelAccuracy\": \"CRF Acc.\",\n",
    "    \"eval/epoch/MeanPriorPixelAccuracy\" : \"Prior Acc.\",\n",
    "    \"eval/epoch/MeanPriorForegroundBinaryMIOU\": \"Prior IoU\" \n",
    "}\n",
    "\n",
    "index_mapping = {\n",
    "    0: \"Baseline\",\n",
    "    15: \"Joint\"\n",
    "}\n",
    "\n",
    "new_colmapping = {}\n",
    "for k, v in dict(col_mapping).items():\n",
    "    for k_i, v_i in dict(index_mapping).items():\n",
    "        new_colmapping[k + \"_\" + str(k_i)] = v + \" \" + v_i\n",
    "\n",
    "col_mapping = new_colmapping\n",
    "\n",
    "def extract_features(model: ResultModel) -> Dict[str, Any]:\n",
    "    res = dict()\n",
    "    \n",
    "    res['joint'] = \"joint\" in model.features\n",
    "    \n",
    "    res['model_name'] = model.config.name.split(\" \")[0]\n",
    "    model_features = list(model.features)\n",
    "    \n",
    "    if res['joint']:\n",
    "        model_features.remove(\"joint\")\n",
    "    \n",
    "    seed = next((x for x in model_features if \"seed\" in x), None)\n",
    "    if seed is None:\n",
    "        seed = model.run_config.seed\n",
    "        res['seed'] = seed\n",
    "    else:\n",
    "        model_features.remove(seed)\n",
    "        res['seed'] = int(seed.replace(\"seed\", \"\"))\n",
    "\n",
    "    if \"REFIT\" in model_features:\n",
    "        model_features.remove(\"REFIT\")\n",
    "        res['prior'] = \"refit\"\n",
    "\n",
    "    if \"original\" in model_features:\n",
    "        model_features.remove(\"original\")\n",
    "        res['prior'] = \"original\"\n",
    "    if \"retrain\" in model_features:\n",
    "        model_features.remove(\"retrain\")\n",
    "        res['prior'] = \"refit\"\n",
    "    if \"retrain_xy\" in model_features:\n",
    "        model_features.remove(\"retrain_xy\")\n",
    "        res['prior'] = \"refit\"\n",
    "\n",
    "    elif \"convex\" in model_features:\n",
    "        model_features.remove(\"convex\")\n",
    "        res['prior'] = \"convex\"\n",
    "    elif \"diffeo\" in model_features:\n",
    "        model_features.remove(\"diffeo\")\n",
    "        res['prior'] = \"diffeo\"\n",
    "    else:\n",
    "        res['prior'] = \"none\"\n",
    "\n",
    "    if \"only_prior\" in model_features:\n",
    "        model_features.remove(\"only_prior\")\n",
    "        res['prior'] = res['prior'] + \"+only_prior\"\n",
    "\n",
    "    if \"all_frames\" in model_features:\n",
    "        model_features.remove(\"all_frames\")\n",
    "        res['prior'] = res['prior'] + \"+all_frames\"\n",
    "    if \"deeper\" in model_features:\n",
    "        model_features.remove(\"deeper\")\n",
    "        res['prior'] = res['prior'] + \"+deeper\"\n",
    "\n",
    "    dataset_name = model_features.pop(0)\n",
    "    res['dataset_name'] = dataset_name\n",
    "\n",
    "    assert len(model_features) == 1, f\"Multiple features {model_features} in model {model.output_path}\"\n",
    "    res['feature_type'] = model_features[0]\n",
    "\n",
    "    return res\n",
    "\n",
    "df = comparison.metric_table(metrics, \n",
    "                             ref=\"all\", \n",
    "                             mode=\"max\",\n",
    "                        formatting=False)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "def extract_ft_row(row: pd.Series) -> Tuple[str, bool, str, int]:\n",
    "    name = row['index']\n",
    "    model = [m for m in models if m.name == name][0]\n",
    "    res = extract_features(model)\n",
    "    return (res['model_name'], res['joint'], res['feature_type'], res['seed'], res['dataset_name'], res['prior'])\n",
    "\n",
    "df[['model_name', 'joint', 'feature_type', 'seed', 'dataset_name', \"prior\"]] = df.apply(extract_ft_row, axis=1, result_type=\"expand\")\n",
    "\n",
    "df = df[['model_name', 'dataset_name'] + list(col_mapping.keys()) + ['joint', 'feature_type', 'seed', \"prior\"]]\n",
    "\n",
    "grouped = df.groupby(['model_name', 'joint', 'feature_type'])\n",
    "\n",
    "display_df = df.rename(columns=col_mapping)\n",
    "display(display_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['model_name', 'dataset_name', 'joint', 'feature_type', \"prior\"]\n",
    "\n",
    "grouped = display_df.groupby(group_by)\n",
    "display_df = grouped.mean().reset_index()\n",
    "display(display_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarized Results of Path Connectedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_columns = [\"IoU Baseline\", \"IoU Joint\", \"Prior IoU Baseline\", \"Prior IoU Joint\", \"Acc. Baseline\", \"Acc. Joint\", \"Prior Acc. Baseline\", \"Prior Acc. Joint\"]\n",
    "\n",
    "numbers = display_df[display_columns].describe().loc[\"mean\"].to_frame().T\n",
    "\n",
    "def subst(x):\n",
    "    x = re.sub(\"(?P<name>.*) Baseline\", \"Baseline \\g<1>\", x)\n",
    "    x = re.sub(\"(?P<name>.*) Joint\", \"Joint \\g<1>\", x)\n",
    "    return x\n",
    "\n",
    "def subs_stubs(x):\n",
    "    return x.replace(\"Joint \", \"\").replace(\"Baseline \", \"\")\n",
    "new_col = [subst(x) for x in display_columns]\n",
    "# Group joint metrics\n",
    "\n",
    "new_numbers = pd.DataFrame(index=numbers.index, columns=new_col)\n",
    "new_numbers[new_col] = numbers[display_columns]\n",
    "\n",
    "new_numbers = new_numbers.rename(index=dict(mean=\"Sequential\"))\n",
    "\n",
    "joints_cols = [x for x in new_numbers.columns if \"Joint\" in x]\n",
    "base_line_columns = [x for x in new_numbers.columns if \"Baseline\" in x]\n",
    "\n",
    "joint_metrics = {subs_stubs(k): v for k, v in new_numbers[joints_cols].iloc[0].to_dict().items()}\n",
    "sequential_metrics = {subs_stubs(k): v for k, v in  new_numbers[base_line_columns].iloc[0].to_dict().items()}\n",
    "\n",
    "order = [\"IoU\", \"Prior IoU\", \"Acc.\", \"Prior Acc.\"]\n",
    "\n",
    "metric_df = pd.DataFrame(columns=order, index=[\"Sequential\", \"Joint\"])\n",
    "metric_df.loc[\"Sequential\"] = [sequential_metrics[x] for x in order]\n",
    "metric_df.loc[\"Joint\"] = [joint_metrics[x] for x in order]\n",
    "\n",
    "\n",
    "wide_numbers = pd.wide_to_long(new_numbers.reset_index(), stubnames=[\"Joint\", \"Baseline\"], i=\"index\", j=\"model\", sep=\" \").reset_index()\n",
    "\n",
    "display(metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended version for appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_columns = [\"dataset_name\", \"IoU Baseline\", \"Prior IoU Baseline\", \"Acc. Baseline\", \"Prior Acc. Baseline\", \"IoU Joint\", \"Prior IoU Joint\", \"Acc. Joint\", \"Prior Acc. Joint\"]\n",
    "\n",
    "def fnc(label):\n",
    "    approach = None\n",
    "    network = None\n",
    "    s = label\n",
    "    if \"Baseline\" in label:\n",
    "        approach = \"Sequential\"\n",
    "        s = s.replace(\"Baseline\", \"\")\n",
    "    else:\n",
    "        approach = \"Joint\"\n",
    "        s = s.replace(\"Joint\", \"\")\n",
    "    if \"Prior\" in label:\n",
    "        network = \"Prior\"\n",
    "        s = s.replace(\"Prior\", \"\")\n",
    "    else:\n",
    "        network = \"UNet\"\n",
    "\n",
    "    return approach, s.strip(), network\n",
    "\n",
    "tuple_cols_mapping = {x: fnc(x) for x in extended_columns[1:]}\n",
    "tuple_cols_mapping_inverted = {v: k for k, v in tuple_cols_mapping.items()}\n",
    "\n",
    "extended_df = display_df[extended_columns]\n",
    "\n",
    "data_cols = pd.MultiIndex.from_tuples(tuple_cols_mapping.values(), names=[\"Approach\", \"Metric\", \"Network\"])\n",
    "\n",
    "index_order = list(data_cols)\n",
    "index_order_old = [\"dataset_name\"] + [tuple_cols_mapping_inverted.get(k, k) for k in index_order]\n",
    "\n",
    "df_joint_mi_cols = extended_df[index_order_old].copy()\n",
    "df_joint_mi_cols.set_index(\"dataset_name\", inplace=True)\n",
    "\n",
    "df_joint_mi_cols.index.name = \"Sequence\"\n",
    "\n",
    "df_joint_mi_cols.sort_index(inplace=True)\n",
    "\n",
    "df_joint_mi_cols.columns = data_cols\n",
    "df_joint_mi_cols = df_joint_mi_cols.round(decimals=3)\n",
    "df_joint_mi_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_joint_mi_cols.to_latex(float_format=\"{:0.3f}\".format))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome-dC4phDSK-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
